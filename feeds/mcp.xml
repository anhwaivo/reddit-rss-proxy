<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/mcp/.rss</id>
  <title>Model Context Protocol (MCP)</title>
  <updated>2025-07-20T13:14:40+00:00</updated>
  <link href="https://old.reddit.com/r/mcp/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools</subtitle>
  <entry>
    <id>t3_1m3zanv</id>
    <title>Naviq - A gateway for discovery, authorization and execution of tools.</title>
    <updated>2025-07-19T15:41:17+00:00</updated>
    <author>
      <name>/u/CowOdd8844</name>
      <uri>https://old.reddit.com/user/CowOdd8844</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m3zanv/naviq_a_gateway_for_discovery_authorization_and/"&gt; &lt;img alt="Naviq - A gateway for discovery, authorization and execution of tools." src="https://external-preview.redd.it/OHdicnlpbGxtdWRmMWwXB78B7NdUukaZnRuH030_z6TQkU3fRzxnl-b3QSCF.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=68d626118cac178865fd4fcebbeb0ff3fbd26dfc" title="Naviq - A gateway for discovery, authorization and execution of tools." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A while ago I wrote a post introducing &lt;a href="https://docs.yafai.in/specifications/skills/Internals"&gt;Yafai-Skills&lt;/a&gt;, An open source, performant, single-binary alternative to an MCP server. It‚Äôs a lightweight tools and integration server for agents ‚Äî built in Go, designed for portability and performance. Single service &lt;/p&gt; &lt;p&gt;What I wanted to share today is something I‚Äôve been working on to complement it: &lt;strong&gt;Naviq&lt;/strong&gt; ‚Äî an open source &lt;strong&gt;discovery and authentication gateway&lt;/strong&gt; for Yafai-skill servers.&lt;/p&gt; &lt;p&gt;It acts as a control layer for agents:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Handles skill &lt;strong&gt;discovery and registry.&lt;/strong&gt; &lt;/li&gt; &lt;li&gt;&lt;strong&gt;OAuth compliant.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Single gateway for all your integrations.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Ready for multi user, multli thread and multi workspace scenarios.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Secures execution via &lt;strong&gt;mutual TLS.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Keeps things lightweight and infra-friendly.&lt;/li&gt; &lt;li&gt;Integrates cleanly with agent orchestration (built for yafai-core and modular for other integrations as well.)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Still early days, but it‚Äôs already solved a lot of friction I was seeing with distributed agent setups.&lt;/p&gt; &lt;p&gt;Curious how others are handling skill/tool discovery and secure execution in agent-heavy environments. Also interested in any emerging patterns you‚Äôre seeing at that layer.&lt;/p&gt; &lt;p&gt;Brewing on homebrew and docker, coming soon.&lt;/p&gt; &lt;p&gt;&lt;a href="http://docs.yafai.in"&gt;Yafai-hub&lt;/a&gt; is an open source project, licensed under Apache 2.0. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/CowOdd8844"&gt; /u/CowOdd8844 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/3cjmtxllmudf1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m3zanv/naviq_a_gateway_for_discovery_authorization_and/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m3zanv/naviq_a_gateway_for_discovery_authorization_and/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T15:41:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1m47uke</id>
    <title>[Discussion] Has anyone else tried ‚Äúhint_for_llm‚Äù or similar meta-guidance in MCP tool responses?</title>
    <updated>2025-07-19T21:41:05+00:00</updated>
    <author>
      <name>/u/Acceptable-Lead9236</name>
      <uri>https://old.reddit.com/user/Acceptable-Lead9236</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt; &lt;p&gt;I‚Äôm back with a quick question for the community.&lt;br /&gt; While working on my MCP Documentation Server, I started experimenting with a pattern where my MCP tools don‚Äôt just return data ‚Äî they also return a field like &lt;code&gt;hint_for_llm&lt;/code&gt; that gives the LLM explicit next-step guidance on how to proceed (e.g., ‚ÄúNow call get_context_window for more context around each chunk‚Äù).&lt;/p&gt; &lt;p&gt;Basically:&lt;br /&gt; Instead of just answering, the tool ‚Äúteaches‚Äù the LLM how to chain actions for more complex workflows, right in the response payload.&lt;/p&gt; &lt;p&gt;I‚Äôve seen a big boost in agent performance and reliability using this.&lt;br /&gt; But I haven‚Äôt found any other open implementations or public repos that use this exact approach (not just tool descriptions, but dynamic meta-guidance in the tool output).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Has anyone here tried something similar?&lt;/strong&gt;&lt;br /&gt; - Do you know of any projects that use this sort of in-band tool-to-LLM guidance? - Any gotchas or best practices from your experience? - Do you see any downsides or edge cases to watch out for?&lt;/p&gt; &lt;p&gt;Here‚Äôs an example of what I mean:&lt;/p&gt; &lt;p&gt;&lt;code&gt;json { &amp;quot;hint_for_llm&amp;quot;: &amp;quot;After identifying the relevant chunks, use the get_context_window tool to retrieve additional context around each chunk of interest. You can call get_context_window multiple times until you have gathered enough context to answer the question.&amp;quot;, &amp;quot;results&amp;quot;: [...] } &lt;/code&gt;&lt;/p&gt; &lt;p&gt;If you‚Äôre curious, you can see the code here:&lt;br /&gt; &lt;a href="https://github.com/andrea9293/mcp-documentation-server"&gt;https://github.com/andrea9293/mcp-documentation-server&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Would love to hear your thoughts, links to similar work, or any suggestions!&lt;br /&gt; Thanks üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Acceptable-Lead9236"&gt; /u/Acceptable-Lead9236 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m47uke/discussion_has_anyone_else_tried_hint_for_llm_or/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m47uke/discussion_has_anyone_else_tried_hint_for_llm_or/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m47uke/discussion_has_anyone_else_tried_hint_for_llm_or/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T21:41:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1m49i4z</id>
    <title>Ruby on Rails for MCP - Memory, Interface, Verifier, Client</title>
    <updated>2025-07-19T22:56:27+00:00</updated>
    <author>
      <name>/u/vaibhavgeek</name>
      <uri>https://old.reddit.com/user/vaibhavgeek</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;h1&gt;MIVC - Memory, Interface, Verifier, Client -- A MCP Server Design Framework&lt;/h1&gt; &lt;h1&gt;Memory MCP Servers&lt;/h1&gt; &lt;p&gt;An MCP server requires fetching very specific information with the right context. We have already seen multiple memory fetching implementations in order to serve the current context length limitations. Even if context length is increased (Gemini 2.5 Pro), the ability to serve intelligently on vast data decreases. Thus, there seems to be a clear need for intelligent fetching systems for blobs of information. Multiple methods for the same have emerged:&lt;/p&gt; &lt;h1&gt;1. LLM Schema Generation + Database Record Creation&lt;/h1&gt; &lt;p&gt;In this technique, the information blob is understood and a schema is created. Then with this format, the information is stored in the database. Once the database is populated, the schema is conveyed to the LLM for writing queries on the database to fetch required information.&lt;/p&gt; &lt;h1&gt;2. (1.) + Vector Columns&lt;/h1&gt; &lt;p&gt;A lot of times LLMs need to understand the relational context for different records. The idea here is not direct inference (SQL) but contextual inference (vectorized words). This requires some columns to be vectorized.&lt;/p&gt; &lt;h1&gt;3. Cyclic Knowledge Graphs&lt;/h1&gt; &lt;p&gt;This is where LLMs generate knowledge graphs which are connected to each other in a cyclic pattern where edges denote relationships and nodes store specific information.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;YADA YADA YADA.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Designing a memory layer should be able to encompass these use cases for information retrieval and any future implementations as well.&lt;/p&gt; &lt;h1&gt;Example Code&lt;/h1&gt; &lt;p&gt;Example code could look something like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;fetch_gmail = MemoryClass(desc=&amp;quot;fetch gmail email information via Vector Columns&amp;quot;) res = fetch_gmail.lookup(summary=&amp;quot;flight tickets from india to new york&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The MemoryClass itself would look like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Schema Id = email id Subject = string Summary = Vector DB def lookup(input): return model.summary.find(input) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This could also be cyclic knowledge graphs or Retrieval Augmented code.&lt;/p&gt; &lt;p&gt;Now one could load a compatible Vector Database from it like Pinecone, Milvus, or MongoDB. More thought needs to be put into how the actual code would look like. I'm happy to take feedback on the same. Right now this is akin to how models work in MVC architecture in Ruby on Rails.&lt;/p&gt; &lt;h1&gt;Interface MCP Servers&lt;/h1&gt; &lt;p&gt;Often these LLMs are required to act upon specific interfaces - e.g., Browsers, Software, Blender, Linux Terminals, Operating Systems. There are a limited number of interfaces where these LLMs can interact. The idea is to load an interface akin to a 'ruby gem'. The developer of these interfaces can constrain and define how the LLM talks to these interfaces. For example, in case of a browser, a DOM can be served as input, whereas output can be executed on the Browser console. In the case of software, the input can be different menus/clicks on the software and the output will be a screenshot of the software window after different actions.&lt;/p&gt; &lt;h1&gt;Interface Components&lt;/h1&gt; &lt;p&gt;Each interface will have three main components:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Service Command&lt;/strong&gt; - This is similar to MCP servers' commands with arguments. The difference is it points to terminal opening command, starting of docker command, running an operating system VM...&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Input Interface Experience&lt;/strong&gt; - The inputs to these interfaces will be required to be constrained by the LLM. This will be based on the choice of interface developer.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Output Interface Experience&lt;/strong&gt; - The output design from the interface requires LLM communication. This again will be based on the choice of interface developer.&lt;/li&gt; &lt;/ol&gt; &lt;h1&gt;Unique Features of Interfaces&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Each interface will be an MCP server in itself&lt;/li&gt; &lt;li&gt;Each interface can be loaded within another MCP server, to serve as a base layer to be built further&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Example Interface Code&lt;/h1&gt; &lt;p&gt;An example code can look like this for defining an interface:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Interface ABC&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Service Commands:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;u/command def start(): args = [&amp;quot;commands&amp;quot;] / &amp;quot;start.sh&amp;quot; @command def stop(): args = [&amp;quot;commands&amp;quot;] / &amp;quot;stop.sh&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Input Interface:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# take input as screenshot screenshot.validate(type: image) definition: &amp;quot;this image describes the state of the software, try to understand if the user is clicking something and how this image is different from base software...&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Output Interface:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# take output as actions on a software mouse.click(x: 123, y: 122) keyboard.input(&amp;quot;top players&amp;quot;) dom.execute(&amp;quot;$('.find').click()&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;More thought needs to be put into how the actual code would look like. I'm happy to take feedback on the same.&lt;/p&gt; &lt;h1&gt;Verifier MCP Servers&lt;/h1&gt; &lt;p&gt;The responses from the LLM need to be verified by a separate black box whose context is not visible to the LLM.&lt;/p&gt; &lt;p&gt;For example, the verifiers can be used to understand the LLM response, if it:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;A.&lt;/strong&gt; Serves the purpose or not. If the response further requires a deeper LLM probe or multiple subagents to complete the task.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;B.&lt;/strong&gt; Should be served to the individual asking it (based on role of the individual or personalization of the individual). If there is further personalization that can be done to the response.&lt;/p&gt; &lt;p&gt;Another example can be if the input is correct and needs to be further detailed or explained before giving it to the main interface/further passed on.&lt;/p&gt; &lt;h1&gt;Verifier Features&lt;/h1&gt; &lt;p&gt;These are basically a black box unit serving as an LLM which runs when the developer wants to. It can be:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Just after the LLM input&lt;/li&gt; &lt;li&gt;After the LLM response&lt;/li&gt; &lt;li&gt;During the interface communication&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;They can access the memory for personalization, fetching roles. They can modify the LLM response. We also want this to serve as an integral layer to integrate with other eval services for agents that exist such as TensorZero, LangChain evals. The idea, although, is that eval intelligence should be a black box to the definition of the agent.&lt;/p&gt; &lt;h1&gt;Verifier Code Example&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;# response/input = as defined previously in code bool_access, sanitized_response = Verifier.verify( &amp;quot;this is meant for a HR professional in an organisation, check if they should have access to this answer/tool call&amp;quot; ) if bool_access: return response else: return sanitized_response &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;Client&lt;/h1&gt; &lt;p&gt;This can be a pub/sub Kafka on a socket, it can be terminal commands, it can be a chat interface. The idea here is to make the current IO for MCP servers more flexible to serve different clients. The client can be customized to have authentication, social OAuth, yada yada again loaded into the server with packages/gems/libraries which can act as proxy. The idea here is to build composable client units for main IO. Right now what's defined by Python decorators actually needs to be a lot more flexible serving more use cases. The idea here is to not restrict the intelligence by a single &amp;quot;chat client&amp;quot; design but allow more feature-rich clients to exist.&lt;/p&gt; &lt;h1&gt;Example Agent Flow&lt;/h1&gt; &lt;p&gt;Here is what an example flow and code for an agent may look like. This is an agent which checks my email address for specific flights, finds my passport information from a personal database and applies to VISA for a country I am travelling to:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Initialize components email_memory = MemoryClass(desc=&amp;quot;Gmail flight information via Vector DB&amp;quot;) # defined in Memory folder personal_vault = MemoryClass(desc=&amp;quot;Personal documents storage&amp;quot;) # defined in Memory folder browser_interface = Interface(&amp;quot;BrowserAutomation&amp;quot;) # Similar to Importing a gem visa_verifier = Verifier(&amp;quot;travel_document_validator&amp;quot;) # defined in travel_document_validator.py country_verifier = Verifier(&amp;quot;country_verifier&amp;quot;) # Verify LLM response # Agent workflow def travel_visa_agent(): # 1. Fetch flight information flights = email_memory.lookup(&amp;quot;recent flight tickets&amp;quot;) destination_country = email_memory.lookup(flights + &amp;quot; countries as an Indian I need visa to and can be given online&amp;quot;) # 2. Verify the destination country obtained is correct from the email. can_proceed, destination_country = country_verifier.verify(&amp;quot;check if it is valid country, just return the country name, indian citizens require a visa and visa can be obtained online&amp;quot;) if !can_proceed: return # 3. Retrieve passport details passport_info = personal_vault.lookup(&amp;quot;passport document current&amp;quot;) # 4. Verify eligibility can_proceed, sanitized_data = visa_verifier.verify( f&amp;quot;visa application for {destination_country}&amp;quot;, context={&amp;quot;flights&amp;quot;: flights, &amp;quot;passport&amp;quot;: passport_info} ) if !can_proceed: return # 5. Interface with visa portal browser_interface.start() browser_interface.navigate(&amp;quot;visa-portal.gov&amp;quot;) browser_interface.fill_form(passport_info, flights) browser_interface.submit() return &amp;quot;Visa application submitted successfully&amp;quot;'' &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;TLDR Version:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;I am looking for feedback on MIVC MCP Server Design Framework&lt;/strong&gt;, where we can build MCP servers using other MCP servers designed for specific purposes - like loading memory, interact with different interfaces, verify the response from LLM as accurate or not, and then serve the final response from the client as pub/sub or other ways.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/vaibhavgeek"&gt; /u/vaibhavgeek &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m49i4z/ruby_on_rails_for_mcp_memory_interface_verifier/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m49i4z/ruby_on_rails_for_mcp_memory_interface_verifier/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m49i4z/ruby_on_rails_for_mcp_memory_interface_verifier/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T22:56:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1m41nta</id>
    <title>Example TypeScript SaaS + MCP + OAuth</title>
    <updated>2025-07-19T17:19:12+00:00</updated>
    <author>
      <name>/u/otothea</name>
      <uri>https://old.reddit.com/user/otothea</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m41nta/example_typescript_saas_mcp_oauth/"&gt; &lt;img alt="Example TypeScript SaaS + MCP + OAuth" src="https://external-preview.redd.it/-5bDEmzRXMmK3GJZY7yzug41ivbTFOmomdD4-_kx-Ik.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c84ee5eec7aede83103961a4beab3aa014e89fca" title="Example TypeScript SaaS + MCP + OAuth" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have been a software developer working on SaaS platforms for over 15 years. I am very excited about MCP and the business opportunities available to builders in the new frontier of AI-first products. I wanted to give something back to the community, so I took the exact stack I use to build my saas products and put it into an example project you can use to start your own ai-first saas.&lt;/p&gt; &lt;p&gt;This example project is a fully functional TypeScript SaaS + MCP + OAuth system that can be deployed to AWS using IaC and GitHub Actions. It's certainly not perfect, but I hope this will help some up and coming SaaS entrepreneurs in this space to have a working example of a scalable, production-level, end-to-end web product.&lt;/p&gt; &lt;p&gt;It's still a work in progress as I build out my own saas, but I think it will help some people get a head start.&lt;/p&gt; &lt;p&gt;Hope you enjoy!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/otothea"&gt; /u/otothea &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/chipgpt/full-stack-saas-mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m41nta/example_typescript_saas_mcp_oauth/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m41nta/example_typescript_saas_mcp_oauth/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T17:19:12+00:00</published>
  </entry>
  <entry>
    <id>t3_1m3rix6</id>
    <title>Not recommending but i'm loving this</title>
    <updated>2025-07-19T08:52:57+00:00</updated>
    <author>
      <name>/u/Beautiful-Essay1945</name>
      <uri>https://old.reddit.com/user/Beautiful-Essay1945</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m3rix6/not_recommending_but_im_loving_this/"&gt; &lt;img alt="Not recommending but i'm loving this" src="https://preview.redd.it/lv1ds3ehosdf1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2ce38a215e6eb4c802a8d44e90dce66569316f28" title="Not recommending but i'm loving this" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Beautiful-Essay1945"&gt; /u/Beautiful-Essay1945 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/lv1ds3ehosdf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m3rix6/not_recommending_but_im_loving_this/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m3rix6/not_recommending_but_im_loving_this/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T08:52:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4asq2</id>
    <title>Model Context Protocol Explained Using AI Agents In n8n</title>
    <updated>2025-07-19T23:56:50+00:00</updated>
    <author>
      <name>/u/Silent-Willow-7543</name>
      <uri>https://old.reddit.com/user/Silent-Willow-7543</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m4asq2/model_context_protocol_explained_using_ai_agents/"&gt; &lt;img alt="Model Context Protocol Explained Using AI Agents In n8n" src="https://external-preview.redd.it/RT4XDveXm5RUfe2p5ujQV24WWtLeWp9npCfp20BivTI.jpeg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=85b12e2d119f84ca8e3fa0ddaf7dfb888d6beb2e" title="Model Context Protocol Explained Using AI Agents In n8n" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Learn how to implement Model Context Protocol (MCP) using AI agents in n8n. This tutorial breaks down the difference between prompt engineering and context engineering and why context is the real key to building powerful, reliable AI workflows. Whether you're an automation builder, founder, or no-code creator, you'll get practical insights on structuring agents that remember, reason, and act with precision.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Silent-Willow-7543"&gt; /u/Silent-Willow-7543 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://youtu.be/ibAZ1GXlueI"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4asq2/model_context_protocol_explained_using_ai_agents/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4asq2/model_context_protocol_explained_using_ai_agents/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T23:56:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1m46iay</id>
    <title>Open source MCP for the EspoCRM</title>
    <updated>2025-07-19T20:42:06+00:00</updated>
    <author>
      <name>/u/cade-zb</name>
      <uri>https://old.reddit.com/user/cade-zb</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Made this for all of us open source loving sales guys to integrate your CRM to your LLM, let me know if you check it out or have any questions &lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/zaphod-black/EspoMCP"&gt;https://github.com/zaphod-black/EspoMCP&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cade-zb"&gt; /u/cade-zb &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m46iay/open_source_mcp_for_the_espocrm/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m46iay/open_source_mcp_for_the_espocrm/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m46iay/open_source_mcp_for_the_espocrm/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T20:42:06+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4bwxe</id>
    <title>How can I make sure that mcp tool runs on every prompt in Cursor</title>
    <updated>2025-07-20T00:52:19+00:00</updated>
    <author>
      <name>/u/heraldev</name>
      <uri>https://old.reddit.com/user/heraldev</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi! I have a tool that I want to use to augment every prompt with a context. How can I make Cursor call it on every prompt reliably?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/heraldev"&gt; /u/heraldev &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4bwxe/how_can_i_make_sure_that_mcp_tool_runs_on_every/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4bwxe/how_can_i_make_sure_that_mcp_tool_runs_on_every/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4bwxe/how_can_i_make_sure_that_mcp_tool_runs_on_every/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T00:52:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1m40ga4</id>
    <title>Background tasks in MCP</title>
    <updated>2025-07-19T16:29:07+00:00</updated>
    <author>
      <name>/u/Feisty-Assignment393</name>
      <uri>https://old.reddit.com/user/Feisty-Assignment393</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m40ga4/background_tasks_in_mcp/"&gt; &lt;img alt="Background tasks in MCP" src="https://b.thumbs.redditmedia.com/mY0Cnkz9b7cFi6Iu34I4uygByCV3048eEZNFGXf8Apk.jpg" title="Background tasks in MCP" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I'm wondering why background tasks are not a thing in MCP maybe someone can help explain. For instance, what happens when you have a long running task? Anthropic mcp doesn't have support yet so I guess the task just blocks. Or maybe the emergence of background agents have somehow made this idea redundant. This came to mind because I was able to write my custom server, create a backgroundtask tool which wraps other tools. The wrapped tools are then offloaded to a celery worker via redis. This works as shown in the image...so makes me wonder why I don't see it often in practice.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Feisty-Assignment393"&gt; /u/Feisty-Assignment393 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1m40ga4"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m40ga4/background_tasks_in_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m40ga4/background_tasks_in_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T16:29:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1m3xtv5</id>
    <title>How Bloomberg scaled GenAI to 9,500+ engineers using MCP. They closed the demo-to-production gap with standardization, identity-aware middleware, and modular tools.</title>
    <updated>2025-07-19T14:39:17+00:00</updated>
    <author>
      <name>/u/No-Abies7108</name>
      <uri>https://old.reddit.com/user/No-Abies7108</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m3xtv5/how_bloomberg_scaled_genai_to_9500_engineers/"&gt; &lt;img alt="How Bloomberg scaled GenAI to 9,500+ engineers using MCP. They closed the demo-to-production gap with standardization, identity-aware middleware, and modular tools." src="https://external-preview.redd.it/G26l0HryV-fBVBC_gJpJksGM1vdY2x7vYpfeVKTyNOg.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7cf8bc9324a7bf1c97250299ac3ab96a8c9dedc4" title="How Bloomberg scaled GenAI to 9,500+ engineers using MCP. They closed the demo-to-production gap with standardization, identity-aware middleware, and modular tools." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/No-Abies7108"&gt; /u/No-Abies7108 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/blog/2025-07-19-scaling-enterprise-gen-ai-with-mcp-bloomberg-case-study"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m3xtv5/how_bloomberg_scaled_genai_to_9500_engineers/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m3xtv5/how_bloomberg_scaled_genai_to_9500_engineers/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T14:39:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4f6bp</id>
    <title>Authenticating to Neon MCP</title>
    <updated>2025-07-20T03:43:02+00:00</updated>
    <author>
      <name>/u/yangguize</name>
      <uri>https://old.reddit.com/user/yangguize</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;New to MCP so apologies for a really basic question. I want to access my Neon db via MCP. No issues when using a client like Claude Desktop - just set up the cfg json.&lt;/p&gt; &lt;p&gt;But how do I authenticate from within a custom typescript app? I set up a Neon API key, asked Claude Code to write the auth routine, but it's just thrashing and can't authenticate.&lt;/p&gt; &lt;p&gt;Can someone point me to some sample code? I've reviewed the &lt;a href="https://github.com/modelcontextprotocol/typescript-sdk?tab=readme-ov-file#sqlite-explorer"&gt;mcp sdk doc&lt;/a&gt; for generic integration with db's like sqlite, but that doesn't seem to show auth with pg db servers.&lt;/p&gt; &lt;p&gt;thx in advance...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/yangguize"&gt; /u/yangguize &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4f6bp/authenticating_to_neon_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4f6bp/authenticating_to_neon_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4f6bp/authenticating_to_neon_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T03:43:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4bou6</id>
    <title>AWS Strands Agents SDK: Simplifying AI Agent Development with a Model-First Approach</title>
    <updated>2025-07-20T00:41:02+00:00</updated>
    <author>
      <name>/u/No-Abies7108</name>
      <uri>https://old.reddit.com/user/No-Abies7108</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m4bou6/aws_strands_agents_sdk_simplifying_ai_agent/"&gt; &lt;img alt="AWS Strands Agents SDK: Simplifying AI Agent Development with a Model-First Approach" src="https://external-preview.redd.it/8U6WUhYWL7KEjKdZ3H56bjLTzQwPZlVYOT_D9pJP560.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d2f99c17c25f3a334eb5b65fd78c34094d64de4e" title="AWS Strands Agents SDK: Simplifying AI Agent Development with a Model-First Approach" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/No-Abies7108"&gt; /u/No-Abies7108 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/blog/2025-07-20-understanding-aws-strands-agents-an-open-source-ai-agents-sdk"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4bou6/aws_strands_agents_sdk_simplifying_ai_agent/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4bou6/aws_strands_agents_sdk_simplifying_ai_agent/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T00:41:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4h50x</id>
    <title>Possible for remote mcp tool to trigger a download in the browser?</title>
    <updated>2025-07-20T05:37:33+00:00</updated>
    <author>
      <name>/u/Kindly_Manager7556</name>
      <uri>https://old.reddit.com/user/Kindly_Manager7556</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Since sending large amounts of data (thinking like CSV here) isn't feasible, is sending a download link possible to have it executed on the user's browser?? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Kindly_Manager7556"&gt; /u/Kindly_Manager7556 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4h50x/possible_for_remote_mcp_tool_to_trigger_a/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4h50x/possible_for_remote_mcp_tool_to_trigger_a/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4h50x/possible_for_remote_mcp_tool_to_trigger_a/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T05:37:33+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4de2l</id>
    <title>Ollama + ollama-mcp-bridge problem by Open Web UI</title>
    <updated>2025-07-20T02:07:51+00:00</updated>
    <author>
      <name>/u/carlosetabosa</name>
      <uri>https://old.reddit.com/user/carlosetabosa</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m4de2l/ollama_ollamamcpbridge_problem_by_open_web_ui/"&gt; &lt;img alt="Ollama + ollama-mcp-bridge problem by Open Web UI" src="https://a.thumbs.redditmedia.com/TCakJ4ogaz5-kdouKm5nMHoc_aMmjax2TaZEZ6AWhG8.jpg" title="Ollama + ollama-mcp-bridge problem by Open Web UI" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/carlosetabosa"&gt; /u/carlosetabosa &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/ollama/comments/1m4d1a1/ollama_ollamamcpbridge_problem_by_open_web_ui/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4de2l/ollama_ollamamcpbridge_problem_by_open_web_ui/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4de2l/ollama_ollamamcpbridge_problem_by_open_web_ui/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T02:07:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4ijow</id>
    <title>What does the Browser Agent (like Perplexity Comet) mean for MCP?</title>
    <updated>2025-07-20T07:04:43+00:00</updated>
    <author>
      <name>/u/riverflow2025</name>
      <uri>https://old.reddit.com/user/riverflow2025</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi, I listened to an interesting podcast from Perplexity's CEO Aravind Srinivas on where the browser wars are going and how he's predicting that the browser will be the best AI agent.&lt;/p&gt; &lt;p&gt;What does this mean for MCP? If an Agent (and HITL) uses the browser why will we need MCP as an interface to tools and data? Surely we will just need the existing web interface?&lt;/p&gt; &lt;p&gt;Maybe the unloved &amp;quot;list prompts&amp;quot; part of MCP will actually be the killer app for MCP.&lt;/p&gt; &lt;p&gt;Anyone else seeing the challenges here (and opportunities) for MCP? I would love to hear your views.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/riverflow2025"&gt; /u/riverflow2025 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4ijow/what_does_the_browser_agent_like_perplexity_comet/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4ijow/what_does_the_browser_agent_like_perplexity_comet/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4ijow/what_does_the_browser_agent_like_perplexity_comet/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T07:04:43+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4j0dm</id>
    <title>MCP in for crypto</title>
    <updated>2025-07-20T07:34:36+00:00</updated>
    <author>
      <name>/u/Impossible_Cress_396</name>
      <uri>https://old.reddit.com/user/Impossible_Cress_396</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Can anyone high level architecture for college project. I was planning to create a Seperate MCP server for transferring crypto assests on user query. I not sure where to start&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Impossible_Cress_396"&gt; /u/Impossible_Cress_396 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4j0dm/mcp_in_for_crypto/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4j0dm/mcp_in_for_crypto/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4j0dm/mcp_in_for_crypto/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T07:34:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4jksf</id>
    <title>Handling batch end in STDIO transport</title>
    <updated>2025-07-20T08:11:40+00:00</updated>
    <author>
      <name>/u/Virviil</name>
      <uri>https://old.reddit.com/user/Virviil</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I don't understand from protocol specification how should client understand that it's LAST message from jsonrpc batch. JSONRPC does not define itself any mark signalling it's last message in chain.&lt;/p&gt; &lt;p&gt;MCP protocol defined request_id, thus client should use it to mark that message is a response to specific request.&lt;/p&gt; &lt;p&gt;In SSE or HTTP it works simply by closing the connection.&lt;/p&gt; &lt;p&gt;BUT in stdio - there is only &amp;quot;one&amp;quot; connection.&lt;/p&gt; &lt;p&gt;So there is a possibility that I send 2 requests&lt;br /&gt; &lt;code&gt;stdin -&amp;gt; {&amp;quot;id&amp;quot;: 1, ...}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;stdin -&amp;gt; {&amp;quot;id&amp;quot;: 2, ...}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;And then get from stdout&lt;br /&gt; &lt;code&gt;{&amp;quot;id&amp;quot;: 1, ...}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;{&amp;quot;id&amp;quot;: 2, ...}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;{&amp;quot;id&amp;quot;: 1, ...}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;How should i understand that it's LAST response with id 1????&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Virviil"&gt; /u/Virviil &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4jksf/handling_batch_end_in_stdio_transport/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4jksf/handling_batch_end_in_stdio_transport/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4jksf/handling_batch_end_in_stdio_transport/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T08:11:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4403r</id>
    <title>Introducing Shinzo: The Composable MCP Analytics Stack</title>
    <updated>2025-07-19T18:56:35+00:00</updated>
    <author>
      <name>/u/Batteryman212</name>
      <uri>https://old.reddit.com/user/Batteryman212</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hello MCP community! üëã&lt;/p&gt; &lt;p&gt;I'm happy to introduce a new project I've been working on for the betterment of the MCP ecosystem.&lt;/p&gt; &lt;h1&gt;MCP's Observability Black Hole&lt;/h1&gt; &lt;p&gt;I've been building and maintaining a few MCP servers for months now, and they get several thousand calls per month, but I never knew how they were being used or why.&lt;/p&gt; &lt;p&gt;I couldn't tell:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Which tools were actually being used vs. ignored&lt;/li&gt; &lt;li&gt;What usage patterns looked like&lt;/li&gt; &lt;li&gt;Where performance bottlenecks were happening&lt;/li&gt; &lt;li&gt;How to prioritize new features&lt;/li&gt; &lt;li&gt;If errors were happening silently&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I was flying completely blind with production traffic. The classic &amp;quot;my server works on my machine&amp;quot; situation, but scaled up.&lt;/p&gt; &lt;h1&gt;The Options Sucked&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Build custom analytics&lt;/strong&gt;: Months of work if you're not familiar with observability best practices&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Use closed-source platforms&lt;/strong&gt;: Not ideal if you're a developer like me who wants greater security over my users' data and dislikes vendor lock-in&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Ignore the problem:&lt;/strong&gt; What I was doing, obviously not sustainable&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;So I Built &lt;a href="https://github.com/shinzo-labs/shinzo-ts"&gt;Shinzo&lt;/a&gt;&lt;/h1&gt; &lt;p&gt;After getting frustrated enough times trying to debug issues or plan features without data, I decided to scratch my own itch.&lt;/p&gt; &lt;p&gt;What it is:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Drop-in instrumentation&lt;/strong&gt;: One line of code, instant telemetry for server tools&lt;/li&gt; &lt;li&gt;&lt;strong&gt;OpenTelemetry native&lt;/strong&gt;: Plays nice with existing tools across the OTel ecosystem&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Privacy-conscious&lt;/strong&gt;: Built-in PII sanitization and redaction by default (to impress your legal counsel)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Self-hostable&lt;/strong&gt;: Keeps your users' data within your control and protection&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Fair-code licensed&lt;/strong&gt;: Sustainable but transparent for developer use&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;How to Try Shinzo&lt;/h1&gt; &lt;p&gt;I will be putting out more content, blogs, etc. on OpenTelemetry and how you can use Shinzo with other tools, so keep an eye out!&lt;/p&gt; &lt;p&gt;In the meantime, feel free to check out the codebase, try it out, and let me know if you have any feedback or suggestions (stars always appreciated): &lt;a href="https://github.com/shinzo-labs/shinzo-ts"&gt;https://github.com/shinzo-labs/shinzo-ts&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Batteryman212"&gt; /u/Batteryman212 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4403r/introducing_shinzo_the_composable_mcp_analytics/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4403r/introducing_shinzo_the_composable_mcp_analytics/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4403r/introducing_shinzo_the_composable_mcp_analytics/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T18:56:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4lz0y</id>
    <title>People help me, Should I go for Mtech or CDAC PG course? After Btech</title>
    <updated>2025-07-20T10:48:48+00:00</updated>
    <author>
      <name>/u/NarwhalHour495</name>
      <uri>https://old.reddit.com/user/NarwhalHour495</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;People help me, Should I go for Mtech or CDAC PG course? After Btech&lt;/p&gt; &lt;p&gt;I have passed CDAC exam now good rank, I haven't appeared for GATE but colleges are still open to receive students&lt;br /&gt; I have paid internship in my hand 15k with experience in AI/ML&lt;br /&gt; I have referral of IBM ... right now assessment has to be given in banglore&lt;br /&gt; I want to sponsor my own education, what should I do?&lt;br /&gt; I have figured out that I can compete in Placement drives online against CDAC capabilities, so no need to finance CDAC&lt;br /&gt; Also to do CDAC, I have to leave my internship for 24/7 study&lt;br /&gt; If I do Mtech I have to wait for feb 2026 GATE exam, which seems a break in studies (although Im working) to be in Top IIT institutes. OR my friends say, MTECH is good outside of INDIA i.e. in UK. OR if I want to take MTech in any colleges rather than Top institutes am I ruining my career?&lt;/p&gt; &lt;p&gt;Please I have 2 days to decide..&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/NarwhalHour495"&gt; /u/NarwhalHour495 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4lz0y/people_help_me_should_i_go_for_mtech_or_cdac_pg/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4lz0y/people_help_me_should_i_go_for_mtech_or_cdac_pg/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4lz0y/people_help_me_should_i_go_for_mtech_or_cdac_pg/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T10:48:48+00:00</published>
  </entry>
  <entry>
    <id>t3_1m46kpb</id>
    <title>Updated my tiny MCP server - now it actually understands context (and guides your AI better)</title>
    <updated>2025-07-19T20:45:05+00:00</updated>
    <author>
      <name>/u/Acceptable-Lead9236</name>
      <uri>https://old.reddit.com/user/Acceptable-Lead9236</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Remember that tiny MCP server I built a month ago for local doc search? (&lt;a href="https://www.reddit.com/r/mcp/comments/1lf7ta6/built_a_tiny_mcp_server_so_my_ai_actually_knows/"&gt;old post&lt;/a&gt;) Well, it's gotten a lot smarter since then!&lt;/p&gt; &lt;p&gt;I've been working on some cool features based on feedback from you guys, and honestly, the latest version (1.6.0) feels like a completely different beast.&lt;/p&gt; &lt;p&gt;The biggest thing is intelligent chunking. Before, it was pretty dumb about splitting documents - it would cut right through the middle of functions or break markdown tables in weird ways. Now it actually understands what type of content you're throwing at it. Code gets chunked differently than markdown, which gets chunked differently than mixed documentation. It's like having someone who actually reads the content before deciding where to cut it.&lt;/p&gt; &lt;p&gt;But the real game-changer is context window retrieval. You know that frustrating thing where you search for something, find the perfect answer, but you're missing the setup code above it or the usage example below? Yeah, that's gone. Now when you find a relevant chunk, you can grab the surrounding chunks to get the full picture. It's what I always wanted but was too lazy to implement properly the first time.&lt;/p&gt; &lt;p&gt;What I'm really excited about though is how I've made the whole system more collaborative with the LLM. The tools now actually guide the AI on what to do next. After a search, it suggests expanding the context window if needed - sometimes multiple times until you have enough context to answer properly. When it can't find a document, it hints to check what documents are actually available instead of just giving up. It's like having a helpful assistant that knows the next logical step instead of just dumping raw results.&lt;/p&gt; &lt;p&gt;I also spent way too much time making the embedding system smarter. It now knows the dimensions of different models, handles lazy initialization better, and has proper fallbacks when transformers.js decides to have a bad day. Plus I finally added proper dotenv support because apparently I forgot that in the first version (oops).&lt;/p&gt; &lt;p&gt;Still the same setup. just drag &amp;amp; drop your docs, no config hell, all local. But now it's actually smart about guiding the conversation forward instead of leaving the LLM hanging.&lt;/p&gt; &lt;p&gt;If you want to get the full benefit of the intelligent chunking, I'd suggest readding your documents so they get processed with the new system. Everything's backward compatible so your old stuff will still work, but the new chunking is definitely worth it.&lt;/p&gt; &lt;p&gt;GitHub: [&lt;a href="https://github.com/andrea9293/mcp-documentation-server%5D(vscode-file://vscode-app/c:/Users/ANDBRAVACC/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)"&gt;https://github.com/andrea9293/mcp-documentation-server](vscode-file://vscode-app/c:/Users/ANDBRAVACC/AppData/Local/Programs/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you tried the old version and it was meh, definitely give this one a shot. And if you're new to this - it's basically RAG but stupid simple and works with any MCP client.&lt;/p&gt; &lt;p&gt;Let me know what breaks! üòÑ&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Acceptable-Lead9236"&gt; /u/Acceptable-Lead9236 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m46kpb/updated_my_tiny_mcp_server_now_it_actually/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m46kpb/updated_my_tiny_mcp_server_now_it_actually/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m46kpb/updated_my_tiny_mcp_server_now_it_actually/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-19T20:45:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4oagj</id>
    <title>How do I speed up LLM decision + tool-use flow on MCP. Feeling stuck.</title>
    <updated>2025-07-20T12:58:11+00:00</updated>
    <author>
      <name>/u/Short_Ingenuity_9286</name>
      <uri>https://old.reddit.com/user/Short_Ingenuity_9286</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi,&lt;br /&gt; I'm working on a system that makes LLM calls to decide what to do next, like bunch of MCP servers and client. Right now, it feels really slow because the model spends time thinking (reasoning) before it actually picks the tool and uses it.&lt;/p&gt; &lt;p&gt;The logic mainly goes through something like a MCP flow&lt;/p&gt; &lt;ol&gt; &lt;li&gt;First the model decides what it wants to do&lt;/li&gt; &lt;li&gt;Then it picks a tool&lt;/li&gt; &lt;li&gt;Then it uses that tool&lt;/li&gt; &lt;li&gt;Then maybe repeats if needed&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I‚Äôm totally new to this stuff and honestly pretty confused. Is there a better or faster way to structure this flow? Like, is there a method or framework that makes tool selection and usage more efficient? Or should I rethink the way I‚Äôm doing planning?&lt;/p&gt; &lt;p&gt;Would love any tips or examples. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Short_Ingenuity_9286"&gt; /u/Short_Ingenuity_9286 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4oagj/how_do_i_speed_up_llm_decision_tooluse_flow_on/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4oagj/how_do_i_speed_up_llm_decision_tooluse_flow_on/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4oagj/how_do_i_speed_up_llm_decision_tooluse_flow_on/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T12:58:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4iw2b</id>
    <title>Improved tool calling</title>
    <updated>2025-07-20T07:26:39+00:00</updated>
    <author>
      <name>/u/NervousYak153</name>
      <uri>https://old.reddit.com/user/NervousYak153</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;How are people improving the tool calling?&lt;/p&gt; &lt;p&gt;I have been finding with with some mcps the LLM is generating poor quality calls from a prompt. This either results in failed responses, repeated calls or just low quality results.&lt;/p&gt; &lt;p&gt;One method I have tried with decent success has been creating an 'llm-guide.md' that contains examples and instructions. &lt;/p&gt; &lt;p&gt;Adding this to the context definitely helps but seems like a workaround and not a solution.&lt;/p&gt; &lt;p&gt;I'm guessing either improving the tool design or perhaps we need a way to incorporate the type of instruction file i described into the mcp. Or this is already solved in another way I am unaware of!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/NervousYak153"&gt; /u/NervousYak153 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4iw2b/improved_tool_calling/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4iw2b/improved_tool_calling/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4iw2b/improved_tool_calling/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T07:26:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4cpfd</id>
    <title>Open Source Tool for Running Any MCP Server in a Secure Remote Sandbox</title>
    <updated>2025-07-20T01:32:53+00:00</updated>
    <author>
      <name>/u/Existing_Somewhere89</name>
      <uri>https://old.reddit.com/user/Existing_Somewhere89</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1m4cpfd/open_source_tool_for_running_any_mcp_server_in_a/"&gt; &lt;img alt="Open Source Tool for Running Any MCP Server in a Secure Remote Sandbox" src="https://external-preview.redd.it/r5APgEfUicR1qDh1KHyePKrn_i21P6YfSvuY8_jFi9Y.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c032b5722c324edba702c1419303f58f58e85aad" title="Open Source Tool for Running Any MCP Server in a Secure Remote Sandbox" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi all!&lt;/p&gt; &lt;p&gt;This is something I actually built for my company but I thought it would be useful / very valuable for the community to have so I've open sourced it with the Apache 2.0 license.&lt;/p&gt; &lt;p&gt;It's essentially just like Smithery where you can run any (dockerized) MCP server. Doesn't matter whether it's STDIO, SSE, or Streamable HTTP.&lt;/p&gt; &lt;p&gt;You receive a SSE &amp;amp; Streamable HTTP endpoint for every MCP server you run.&lt;/p&gt; &lt;p&gt;The main differentiator here is that we had the business need of having to run untrusted MCP servers that might possibly interact with user data and so a lot of effort went into preventing container escapes. Each MCP server process is also on its own network and not allowed to talk to other MCP servers or the host networks in order to further secure the system.&lt;/p&gt; &lt;p&gt;Containers can also automatically shut down after a period of inactivity and automatically restart when the MCP connection is started.&lt;/p&gt; &lt;p&gt;This is intended to run on Ubuntu. More information is available in the &lt;a href="https://github.com/tangier-ai/mcp-runner/blob/main/README.md"&gt;README&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Existing_Somewhere89"&gt; /u/Existing_Somewhere89 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/tangier-ai/mcp-runner"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4cpfd/open_source_tool_for_running_any_mcp_server_in_a/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4cpfd/open_source_tool_for_running_any_mcp_server_in_a/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T01:32:53+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4neac</id>
    <title>Replacing current software with MCPs and Agents</title>
    <updated>2025-07-20T12:11:33+00:00</updated>
    <author>
      <name>/u/Bargb</name>
      <uri>https://old.reddit.com/user/Bargb</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi Folks,&lt;/p&gt; &lt;p&gt;We have been shipping a certain software to our customers for over 10 years, so it is well-tested and well-maintained. This software is more rule based.&lt;/p&gt; &lt;p&gt;Given that there is a raise for MCPs and agents, there is discussion going if the software should be replaced with MCPs and agents but the problem we have is the accuracy and token cost. So, there is no clear moot to move to MCPs and agents.&lt;/p&gt; &lt;p&gt;Are we missing something here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Bargb"&gt; /u/Bargb &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4neac/replacing_current_software_with_mcps_and_agents/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4neac/replacing_current_software_with_mcps_and_agents/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4neac/replacing_current_software_with_mcps_and_agents/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T12:11:33+00:00</published>
  </entry>
  <entry>
    <id>t3_1m4o8wu</id>
    <title>MCP is Over-Engineered and Breaks Serverless</title>
    <updated>2025-07-20T12:56:00+00:00</updated>
    <author>
      <name>/u/VaderStateOfMind</name>
      <uri>https://old.reddit.com/user/VaderStateOfMind</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Been working with MCP lately ‚Äî and while it does solve a real problem, I think it's going about it the wrong way.&lt;/p&gt; &lt;p&gt;Why require a stateful server to call tools? Most tools already have clean REST APIs. Forcing devs to build and maintain persistent infra just to call them feels like overkill.&lt;/p&gt; &lt;p&gt;The issues:&lt;/p&gt; &lt;p&gt;Breaks serverless (can‚Äôt just plug into a Lambda or Cloud Function)&lt;/p&gt; &lt;p&gt;Overloads context with every tool registered up front&lt;/p&gt; &lt;p&gt;Adds complexity with sampling, retries, connections - for features most don‚Äôt even use and also allows the MCP servers to sample your data (and using your own tokens, plus security risk)&lt;/p&gt; &lt;p&gt;What we actually need:&lt;/p&gt; &lt;p&gt;Stateless tool calls (OpenAPI-style)&lt;/p&gt; &lt;p&gt;Describe tools well, let models call them directly&lt;/p&gt; &lt;p&gt;Keep it simple, serverless-friendly, and infra-light.&lt;/p&gt; &lt;p&gt;Thoughts?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/VaderStateOfMind"&gt; /u/VaderStateOfMind &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4o8wu/mcp_is_overengineered_and_breaks_serverless/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1m4o8wu/mcp_is_overengineered_and_breaks_serverless/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1m4o8wu/mcp_is_overengineered_and_breaks_serverless/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-07-20T12:56:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7pl2v</id>
    <title>Awesome MCP Servers ‚Äì A curated list of awesome Model Context Protocol (MCP) servers</title>
    <updated>2024-12-06T01:23:42+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt; &lt;img alt="Awesome MCP Servers ‚Äì A curated list of awesome Model Context Protocol (MCP) servers" src="https://external-preview.redd.it/BlNcrgap-6pz7IdUsbomFSVuqp_BB8tTUEFVIk6by18.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f25629e364c60f72e8d88ce33c5b1f90a326c065" title="Awesome MCP Servers ‚Äì A curated list of awesome Model Context Protocol (MCP) servers" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/punkpeye/awesome-mcp-servers/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T01:23:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7qe88</id>
    <title>Join the Model Context Protocol Discord Server!</title>
    <updated>2024-12-06T02:04:10+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/discord"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T02:04:10+00:00</published>
  </entry>
</feed>
