<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/mcp/.rss</id>
  <title>Model Context Protocol (MCP)</title>
  <updated>2025-06-26T02:25:28+00:00</updated>
  <link href="https://old.reddit.com/r/mcp/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools</subtitle>
  <entry>
    <id>t3_1ljk41l</id>
    <title>Your biggest MCP security threat</title>
    <updated>2025-06-24T19:13:09+00:00</updated>
    <author>
      <name>/u/martexsolved</name>
      <uri>https://old.reddit.com/user/martexsolved</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Which MCP-borne security risk do you see as the most risky and difficult to mitigate?&lt;/p&gt; &lt;p&gt;If your choice isn't included in the poll feel free to let me know in the comments - cheers!&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.reddit.com/poll/1ljk41l"&gt;View Poll&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/martexsolved"&gt; /u/martexsolved &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1ljk41l/your_biggest_mcp_security_threat/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1ljk41l/your_biggest_mcp_security_threat/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1ljk41l/your_biggest_mcp_security_threat/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-24T19:13:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1ljkt9t</id>
    <title>Built an MCP server that turns any MCP client into a multi-agent collaboration system</title>
    <updated>2025-06-24T19:40:11+00:00</updated>
    <author>
      <name>/u/Hairy-Map2785</name>
      <uri>https://old.reddit.com/user/Hairy-Map2785</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Just finished implementing the Meta-Prompting paper as an MCP server. Thought the community might find this useful (It's super useful for me, just like the Sequential Thinking MCP).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Transforms any MCP client (Cursor, Claude Desktop, etc.) into a multi-agent system&lt;/li&gt; &lt;li&gt;Simulates multiple AI experts collaborating within a single model&lt;/li&gt; &lt;li&gt;Uses a &amp;quot;Conductor&amp;quot; to break down problems and delegate to specialized &amp;quot;Experts&amp;quot;&lt;/li&gt; &lt;li&gt;Includes mandatory verification with independent experts before final answers&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;How it works:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Conductor role&lt;/strong&gt;: Project manager that analyzes problems and creates subtasks&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Expert roles&lt;/strong&gt;: Specialized agents (Python Programmer, Code Reviewer, etc.)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Verification process&lt;/strong&gt;: Multiple independent experts verify solutions before presenting&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I built this in 1-2 days using FastMCP in Python, based on &lt;a href="https://arxiv.org/abs/2401.12954"&gt;this research&lt;/a&gt;. Although, the difference from the original paper is that this implementation runs everything in a single LLM call instead of separate model instances (due to MCP client limitations), but still follows the core methodology.&lt;br /&gt; It has 2 tools: `expert_model` for consulant calls and `ready_to_answer` to ask the user which format to use for the final result.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Please clone it and try it on your MCP client:&lt;/strong&gt; &lt;a href="https://github.com/tisu19021997/meta-prompt-mcp-server"&gt;https://github.com/tisu19021997/meta-prompt-mcp-server&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Side note: this complements the official &lt;a href="https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking"&gt;sequential-thinking server&lt;/a&gt; which focuses on step-by-step reflective thinking within a single model. Meta-prompting takes a different approach by simulating multiple expert personas collaborating on the same problem.&lt;/p&gt; &lt;p&gt;I'm open to any feedback and ideas! Hope this help.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Hairy-Map2785"&gt; /u/Hairy-Map2785 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1ljkt9t/built_an_mcp_server_that_turns_any_mcp_client/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1ljkt9t/built_an_mcp_server_that_turns_any_mcp_client/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1ljkt9t/built_an_mcp_server_that_turns_any_mcp_client/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-24T19:40:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1lk14uh</id>
    <title>Meta Prompt MCP Server – A server that transforms a standard Language Model into a dynamic multi-agent system where the model simulates both a Conductor (project manager) and Experts (specialized agents) to tackle complex problems through a collaborative workflow.</title>
    <updated>2025-06-25T09:30:06+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lk14uh/meta_prompt_mcp_server_a_server_that_transforms_a/"&gt; &lt;img alt="Meta Prompt MCP Server – A server that transforms a standard Language Model into a dynamic multi-agent system where the model simulates both a Conductor (project manager) and Experts (specialized agents) to tackle complex problems through a collaborative workflow." src="https://external-preview.redd.it/DOzG-4h3IE4kQ8iKeS1RRjJdL-RqKx_JYmPjMicSCtY.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ae38599d140444f12fd48444bbb6bfdea2a9f904" title="Meta Prompt MCP Server – A server that transforms a standard Language Model into a dynamic multi-agent system where the model simulates both a Conductor (project manager) and Experts (specialized agents) to tackle complex problems through a collaborative workflow." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@tisu19021997/meta-prompt-mcp-server"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk14uh/meta_prompt_mcp_server_a_server_that_transforms_a/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lk14uh/meta_prompt_mcp_server_a_server_that_transforms_a/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T09:30:06+00:00</published>
  </entry>
  <entry>
    <id>t3_1lk5x3b</id>
    <title>Host a LLM or agent behind an MCP server.</title>
    <updated>2025-06-25T13:38:16+00:00</updated>
    <author>
      <name>/u/Glum_Palpitation4760</name>
      <uri>https://old.reddit.com/user/Glum_Palpitation4760</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am a beginner in agentic AI.&lt;/p&gt; &lt;p&gt;I am trying to build a system where an agent can talk to a MCP server which hosts another agent (thats connected to another MCP server). Something like below:&lt;/p&gt; &lt;p&gt;agent -&amp;gt; MCP Server [agent behind the scene -&amp;gt; MCP server]&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Glum_Palpitation4760"&gt; /u/Glum_Palpitation4760 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk5x3b/host_a_llm_or_agent_behind_an_mcp_server/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk5x3b/host_a_llm_or_agent_behind_an_mcp_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lk5x3b/host_a_llm_or_agent_behind_an_mcp_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T13:38:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1lk1ocp</id>
    <title>terminal mcp explorer and proxy debugger</title>
    <updated>2025-06-25T10:03:36+00:00</updated>
    <author>
      <name>/u/kungfusheep</name>
      <uri>https://old.reddit.com/user/kungfusheep</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lk1ocp/terminal_mcp_explorer_and_proxy_debugger/"&gt; &lt;img alt="terminal mcp explorer and proxy debugger" src="https://external-preview.redd.it/HRPyYcpp_iBeuaAh8Cj7VGvfoxr2KNtxXZqajXqDmWA.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=84ed18a6fab23cb19a512f76e754d9e6b3ab2092" title="terminal mcp explorer and proxy debugger" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey - I was working on some MCP capabilities recently and couldn’t find anything I liked for development &amp;amp; debugging, so I put this together - sharing in case anyone feels the same way. It has a nice proxy workflow too, to let you see what’s going on between a client and server. Enjoy! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/kungfusheep"&gt; /u/kungfusheep &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/kungfusheep/mcpview"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk1ocp/terminal_mcp_explorer_and_proxy_debugger/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lk1ocp/terminal_mcp_explorer_and_proxy_debugger/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T10:03:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1ljb4vs</id>
    <title>n8n will be a powerful tool to build MCP servers</title>
    <updated>2025-06-24T13:29:05+00:00</updated>
    <author>
      <name>/u/mrgoonvn</name>
      <uri>https://old.reddit.com/user/mrgoonvn</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1ljb4vs/n8n_will_be_a_powerful_tool_to_build_mcp_servers/"&gt; &lt;img alt="n8n will be a powerful tool to build MCP servers" src="https://external-preview.redd.it/cQ-rEYSjN6_H8c0Hqt9LtLba4qbxCDQjTba3FOGQXh8.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6d279e9322ecd7e489f23f54e853750a51f54aef" title="n8n will be a powerful tool to build MCP servers" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Simply because it's too convenient. For example, I built two MCPs below and integrated them into my Digicord chatbot in less than 5 minutes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;MCP connects to Gmail to analyze or send emails.&lt;/li&gt; &lt;li&gt;MCP connects to Calendar to check or set event reminders.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Meanwhile, if I were to code it myself, it might take a whole morning. Anyone who's coded knows how time-consuming it is to integrate multiple platforms, whereas n8n has a bunch of them pre-integrated. Just drag, drop, and fill in the key, and you're done. Feel free to tinker.&lt;/p&gt; &lt;p&gt;Create an &amp;quot;MCP Server Trigger&amp;quot; node, add some tools to it, copy the MCP URL to add to the configuration of an AI chat tool that supports MCP like Claude (or DigiCord), and it's ready to use.&lt;/p&gt; &lt;p&gt;You can even turn a custom workflow into an MCP server, with full customization.&lt;/p&gt; &lt;p&gt;From n8n version 1.99.0+ (just released 3-4 days ago or so), n8n also supports Streamable HTTP transport (before that it only had SSE).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mrgoonvn"&gt; /u/mrgoonvn &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1ljb4vs"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1ljb4vs/n8n_will_be_a_powerful_tool_to_build_mcp_servers/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1ljb4vs/n8n_will_be_a_powerful_tool_to_build_mcp_servers/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-24T13:29:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkdpv9</id>
    <title>I've been daily driving Semgrep MCP server for keeping my vibe coded projects secure</title>
    <updated>2025-06-25T18:36:45+00:00</updated>
    <author>
      <name>/u/Turbulent-Key-348</name>
      <uri>https://old.reddit.com/user/Turbulent-Key-348</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkdpv9/ive_been_daily_driving_semgrep_mcp_server_for/"&gt; &lt;img alt="I've been daily driving Semgrep MCP server for keeping my vibe coded projects secure" src="https://external-preview.redd.it/NzdqeWlmZnRhNDlmMQKEZeAfm0vBsjAsvqmBoiWlv0Kb3usyGS9sihM447HK.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c72bfd1513d274b16bf4959508957be2ac140825" title="I've been daily driving Semgrep MCP server for keeping my vibe coded projects secure" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey folks - David from Memex here &lt;/p&gt; &lt;p&gt;I’ve been using the Semgrep MCP server as a part of my daily workflow recently to find vulnerabilities in my vibe coded projects. I find it to be pretty painless in my workflow to periodically check for vulnerabilities and then fix them. This quick video illustrates my typical workflow in a nutshell (aside from the installation section of the video). &lt;/p&gt; &lt;p&gt;What I really like about it:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It has native capabilities that are intrinsically useful without having a Semgrep subscription.&lt;/li&gt; &lt;li&gt;It has the option to connect to their Semgrep AppSec Platform API&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I think the pattern of blending free + paid services is smart and a great UX &amp;amp; AX&lt;/p&gt; &lt;p&gt;Are others using this MCP server? If not, how do you manage security for your vibe coded projects?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Turbulent-Key-348"&gt; /u/Turbulent-Key-348 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/jo992ffta49f1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkdpv9/ive_been_daily_driving_semgrep_mcp_server_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkdpv9/ive_been_daily_driving_semgrep_mcp_server_for/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T18:36:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1lk9jlg</id>
    <title>Just made a gemini-mcp</title>
    <updated>2025-06-25T16:00:21+00:00</updated>
    <author>
      <name>/u/loming123</name>
      <uri>https://old.reddit.com/user/loming123</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;You know you want it :)&lt;br /&gt; &lt;a href="https://github.com/loming/gemini-mcp"&gt;https://github.com/loming/gemini-mcp&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Since gemini-cli is similar to Claude Code we could Pipe anything in with Web Search like below:-&lt;/p&gt; &lt;p&gt;% echo &amp;quot;Tell me the weather in London today&amp;quot; | gemini&lt;br /&gt; The weather in London today is partly sunny with a high of 28°C and a low of 20°C. There is a very low chance of rain, and a light breeze from the southwest.&lt;/p&gt; &lt;p&gt;It looks like there's a place for AI Agent so here we are.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/loming123"&gt; /u/loming123 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk9jlg/just_made_a_geminimcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk9jlg/just_made_a_geminimcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lk9jlg/just_made_a_geminimcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T16:00:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkj8v4</id>
    <title>HiveFlow MCP Server – Connects AI assistants (Claude, Cursor, etc.) directly to the HiveFlow automation platform, allowing them to create, manage, and execute automation flows through natural language commands.</title>
    <updated>2025-06-25T22:15:04+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkj8v4/hiveflow_mcp_server_connects_ai_assistants_claude/"&gt; &lt;img alt="HiveFlow MCP Server – Connects AI assistants (Claude, Cursor, etc.) directly to the HiveFlow automation platform, allowing them to create, manage, and execute automation flows through natural language commands." src="https://external-preview.redd.it/oza2al2m-RluLwEKo4VK7UCjadehZaoByHH5RZcWtIo.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f0ab342a9ca79aa9dff20afbdd746a4e08d7af9f" title="HiveFlow MCP Server – Connects AI assistants (Claude, Cursor, etc.) directly to the HiveFlow automation platform, allowing them to create, manage, and execute automation flows through natural language commands." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@hiveflowai/hiveflow-mcp-server"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkj8v4/hiveflow_mcp_server_connects_ai_assistants_claude/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkj8v4/hiveflow_mcp_server_connects_ai_assistants_claude/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T22:15:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkf5ja</id>
    <title>Bridge, Instant MCPs for Databases and OpenAPIs</title>
    <updated>2025-06-25T19:31:47+00:00</updated>
    <author>
      <name>/u/Any_Spread6836</name>
      <uri>https://old.reddit.com/user/Any_Spread6836</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkf5ja/bridge_instant_mcps_for_databases_and_openapis/"&gt; &lt;img alt="Bridge, Instant MCPs for Databases and OpenAPIs" src="https://external-preview.redd.it/q7hVtQbGqieWjCKMRI9TNDfgA54kxJMXxij0gMNBH9k.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fbc5493d37cc8439d406e87a7a1d84d8dac79fb1" title="Bridge, Instant MCPs for Databases and OpenAPIs" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi everyone! &lt;/p&gt; &lt;p&gt;We’re excited to introduce Bridge—an open-source server that lets you quickly spin up (opinionated) MCPs to connect your databases and APIs. Bridge is part of our startup's DX for integrating with our auditing and security platform, but this release focuses on making it easy for anyone to connect your systems with MCPs right away. &lt;/p&gt; &lt;p&gt;We’d love to hear your feedback or questions! &lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any_Spread6836"&gt; /u/Any_Spread6836 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/brwse/bridge"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkf5ja/bridge_instant_mcps_for_databases_and_openapis/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkf5ja/bridge_instant_mcps_for_databases_and_openapis/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T19:31:47+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkbpbt</id>
    <title>Which clients support which parts of the MCP protocol? I created a table.</title>
    <updated>2025-06-25T17:20:39+00:00</updated>
    <author>
      <name>/u/ImaginationInFocus</name>
      <uri>https://old.reddit.com/user/ImaginationInFocus</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;The MCP protocol evolves quickly (latest update was last week) and client support varies. Most only support tools, some support prompts and resources, and have different combos of transport and auth support.&lt;/p&gt; &lt;p&gt;I built a repo to track it all: &lt;a href="https://github.com/tadata-org/mcp-client-compatibility"&gt;https://github.com/tadata-org/mcp-client-compatibility&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Anthropic had a table in their launch docs, but it’s already outdated. This one’s open source so the community can help keep it fresh.&lt;/p&gt; &lt;p&gt;PRs welcome!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ImaginationInFocus"&gt; /u/ImaginationInFocus &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkbpbt/which_clients_support_which_parts_of_the_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkbpbt/which_clients_support_which_parts_of_the_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkbpbt/which_clients_support_which_parts_of_the_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T17:20:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkkzjx</id>
    <title>SEQ MCP Server – Enables LLMs to query and analyze logs from SEQ structured logging server with capabilities for searching events, retrieving event details, analyzing log patterns, and accessing saved searches.</title>
    <updated>2025-06-25T23:30:07+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkkzjx/seq_mcp_server_enables_llms_to_query_and_analyze/"&gt; &lt;img alt="SEQ MCP Server – Enables LLMs to query and analyze logs from SEQ structured logging server with capabilities for searching events, retrieving event details, analyzing log patterns, and accessing saved searches." src="https://external-preview.redd.it/hCz9H-3RuyV4bP09ATWjFjhHWhcdtEX-IbupggZ1nPI.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f015a4b8f1cf2553b02aaade231d4865976690d6" title="SEQ MCP Server – Enables LLMs to query and analyze logs from SEQ structured logging server with capabilities for searching events, retrieving event details, analyzing log patterns, and accessing saved searches." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@RoeeJ/seq-mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkkzjx/seq_mcp_server_enables_llms_to_query_and_analyze/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkkzjx/seq_mcp_server_enables_llms_to_query_and_analyze/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T23:30:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1lk41hn</id>
    <title>What part of building and launching your MCP server was the hardest?</title>
    <updated>2025-06-25T12:14:06+00:00</updated>
    <author>
      <name>/u/ravi-scalekit</name>
      <uri>https://old.reddit.com/user/ravi-scalekit</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Not the agent logic or wrapper code — I mean:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Modeling Input and Output schema in such a way that public MCP clients can infer data accurately&lt;/li&gt; &lt;li&gt;Dealing with fallback flows (tool unavailability, silent fails)&lt;/li&gt; &lt;li&gt;Mapping scopes and permissions to tool&lt;/li&gt; &lt;li&gt;Traceability between MCP client and server for tool invocation and authentication updates&lt;/li&gt; &lt;li&gt;Sharing metadata to MCP client as a response to a tool invocation to enhance further operations&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ravi-scalekit"&gt; /u/ravi-scalekit &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk41hn/what_part_of_building_and_launching_your_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk41hn/what_part_of_building_and_launching_your_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lk41hn/what_part_of_building_and_launching_your_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T12:14:06+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkma1d</id>
    <title>RedNote MCP – Enables users to search and retrieve content from Xiaohongshu (Red Book) platform with smart search capabilities and rich data extraction including note content, author information, and images.</title>
    <updated>2025-06-26T00:30:09+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkma1d/rednote_mcp_enables_users_to_search_and_retrieve/"&gt; &lt;img alt="RedNote MCP – Enables users to search and retrieve content from Xiaohongshu (Red Book) platform with smart search capabilities and rich data extraction including note content, author information, and images." src="https://external-preview.redd.it/fLbnBGBdmiK4Vrcs2EvFsuZluBNY9Dyt4UPe9tSfBwk.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3cc5eaa59f513b264a563280ea7a2f9177883e96" title="RedNote MCP – Enables users to search and retrieve content from Xiaohongshu (Red Book) platform with smart search capabilities and rich data extraction including note content, author information, and images." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@MilesCool/rednote-mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkma1d/rednote_mcp_enables_users_to_search_and_retrieve/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkma1d/rednote_mcp_enables_users_to_search_and_retrieve/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-26T00:30:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkmfjw</id>
    <title>First ModuleX Test Post</title>
    <updated>2025-06-26T00:37:31+00:00</updated>
    <author>
      <name>/u/modulexai</name>
      <uri>https://old.reddit.com/user/modulexai</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modulexai"&gt; /u/modulexai &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkmfjw/first_modulex_test_post/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkmfjw/first_modulex_test_post/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkmfjw/first_modulex_test_post/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-26T00:37:31+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkmlae</id>
    <title>Weather MCP Server – A TypeScript-based MCP server that provides simulated weather data including current conditions, forecasts, alerts, and location search functionality through both MCP protocol and HTTP API endpoints.</title>
    <updated>2025-06-26T00:45:10+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkmlae/weather_mcp_server_a_typescriptbased_mcp_server/"&gt; &lt;img alt="Weather MCP Server – A TypeScript-based MCP server that provides simulated weather data including current conditions, forecasts, alerts, and location search functionality through both MCP protocol and HTTP API endpoints." src="https://external-preview.redd.it/KDXfrlJ4lD3qjvCADoxpZL7gBtG21BPmcEdyTj0QO1U.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6fb978a9a3108b76cacb4f041d07c495c3aade15" title="Weather MCP Server – A TypeScript-based MCP server that provides simulated weather data including current conditions, forecasts, alerts, and location search functionality through both MCP protocol and HTTP API endpoints." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@bobbyyng/weather-mcp-ts"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkmlae/weather_mcp_server_a_typescriptbased_mcp_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkmlae/weather_mcp_server_a_typescriptbased_mcp_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-26T00:45:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkhej1</id>
    <title>Obsidian Local REST API MCP Server – A bridge server that allows LLM tools to interact with an Obsidian vault through a local REST API, enabling file operations, note management, and metadata access through natural language.</title>
    <updated>2025-06-25T21:00:14+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkhej1/obsidian_local_rest_api_mcp_server_a_bridge/"&gt; &lt;img alt="Obsidian Local REST API MCP Server – A bridge server that allows LLM tools to interact with an Obsidian vault through a local REST API, enabling file operations, note management, and metadata access through natural language." src="https://external-preview.redd.it/T9BOAX6icXwOQe6JD6mYekKarG50WjwosIJItkLAHlk.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=12372c0f319d36c800fba201116efc0a956e08d6" title="Obsidian Local REST API MCP Server – A bridge server that allows LLM tools to interact with an Obsidian vault through a local REST API, enabling file operations, note management, and metadata access through natural language." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@j-shelfwood/obsidian-local-rest-api-mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkhej1/obsidian_local_rest_api_mcp_server_a_bridge/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkhej1/obsidian_local_rest_api_mcp_server_a_bridge/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T21:00:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkmwf6</id>
    <title>YAPI Interface MCP Server – A Model Context Protocol server that allows AI development tools like Cursor and Claude Desktop to retrieve detailed YAPI interface information by interface ID.</title>
    <updated>2025-06-26T01:00:11+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkmwf6/yapi_interface_mcp_server_a_model_context/"&gt; &lt;img alt="YAPI Interface MCP Server – A Model Context Protocol server that allows AI development tools like Cursor and Claude Desktop to retrieve detailed YAPI interface information by interface ID." src="https://external-preview.redd.it/943MZ6bcS0psTEU39_3OOXV4_M_7glUelrFAct5FG_Y.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=edc0c9bb77db20f0f7377b32cb9ffd85b1c2236d" title="YAPI Interface MCP Server – A Model Context Protocol server that allows AI development tools like Cursor and Claude Desktop to retrieve detailed YAPI interface information by interface ID." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@Gorvey/yapi-get-interface-mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkmwf6/yapi_interface_mcp_server_a_model_context/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkmwf6/yapi_interface_mcp_server_a_model_context/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-26T01:00:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkhsdf</id>
    <title>Advanced Trello MCP Server – An enhanced Model Context Protocol server providing comprehensive integration between Trello and Cursor AI with 40+ tools covering multiple Trello API categories for complete project management.</title>
    <updated>2025-06-25T21:15:09+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkhsdf/advanced_trello_mcp_server_an_enhanced_model/"&gt; &lt;img alt="Advanced Trello MCP Server – An enhanced Model Context Protocol server providing comprehensive integration between Trello and Cursor AI with 40+ tools covering multiple Trello API categories for complete project management." src="https://external-preview.redd.it/F7ZRpgwr-CboNPkVoay91Fb9CvKw4ZG3CdXhoZfiARM.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=47299b55fbfc2d342940e489d018c47d332fcd37" title="Advanced Trello MCP Server – An enhanced Model Context Protocol server providing comprehensive integration between Trello and Cursor AI with 40+ tools covering multiple Trello API categories for complete project management." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@adriangrahldev/advanced-trello-mcp-server"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkhsdf/advanced_trello_mcp_server_an_enhanced_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkhsdf/advanced_trello_mcp_server_an_enhanced_model/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T21:15:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkflb7</id>
    <title>Open-source mcp starter template. For UI libraries, APIs, open-source projects and more</title>
    <updated>2025-06-25T19:49:11+00:00</updated>
    <author>
      <name>/u/mnove30</name>
      <uri>https://old.reddit.com/user/mnove30</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkflb7/opensource_mcp_starter_template_for_ui_libraries/"&gt; &lt;img alt="Open-source mcp starter template. For UI libraries, APIs, open-source projects and more" src="https://external-preview.redd.it/PBJ5m9jri6jk7j_fEo_IAMPTJ5p-62YWI3KBNbkHlQY.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e8862be812473599aa605e33175bd98eb49800ef" title="Open-source mcp starter template. For UI libraries, APIs, open-source projects and more" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;hey! check out this &lt;strong&gt;mcp servers starter template&lt;/strong&gt;, specifically designed for UI libraries and component registries. &lt;/p&gt; &lt;p&gt;I built a similar one for a UI library and decided to just turn it into a template. &lt;/p&gt; &lt;p&gt;Some features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;support for component registry integration&lt;/strong&gt; for UI libraries&lt;/li&gt; &lt;li&gt;&lt;strong&gt;categorized component organization&lt;/strong&gt; with flexible category system&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Schema validation&lt;/strong&gt; with Zod for type safety&lt;/li&gt; &lt;li&gt;&lt;strong&gt;D&lt;/strong&gt;ev tools like inspector&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Example implementation&lt;/strong&gt; using a real project URL for demonstration (&lt;a href="https://ui.stackzero.co/docs/mcp"&gt;this project&lt;/a&gt;)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Extensible architecture&lt;/strong&gt; for custom component types and categories&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Repo: &lt;a href="https://github.com/mnove/mcp-server-starter"&gt;https://github.com/mnove/mcp-server-starter&lt;/a&gt; (MIT License)&lt;/p&gt; &lt;p&gt;Let me know what you think&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mnove30"&gt; /u/mnove30 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/mnove/mcp-server-starter"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkflb7/opensource_mcp_starter_template_for_ui_libraries/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkflb7/opensource_mcp_starter_template_for_ui_libraries/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T19:49:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1lko1te</id>
    <title>Shocking! This is how multi-MCP agent interaction can be done!</title>
    <updated>2025-06-26T01:56:24+00:00</updated>
    <author>
      <name>/u/SubstantialWord7757</name>
      <uri>https://old.reddit.com/user/SubstantialWord7757</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lko1te/shocking_this_is_how_multimcp_agent_interaction/"&gt; &lt;img alt="Shocking! This is how multi-MCP agent interaction can be done!" src="https://external-preview.redd.it/tYVDyuARMrGu2umgL-mTOfZjEJQ4Dh6eLZnHg1Jtrqs.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a6eab4285f6f7b7125e7537930e144d02dfdc30d" title="Shocking! This is how multi-MCP agent interaction can be done!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey Reddit,&lt;/p&gt; &lt;p&gt;A while back, I shared an example of multi-modal interaction &lt;a href="https://www.reddit.com/r/mcp/comments/1lids1j/supercharge_your_telegram_bot_with_deepseek_ai/"&gt;here&lt;/a&gt;. Today, we're diving deeper by breaking down the individual &lt;strong&gt;prompts&lt;/strong&gt; used in that system to understand what each one does, complete with code references.&lt;/p&gt; &lt;p&gt;All the code discussed here comes from this GitHub repository: &lt;a href="https://github.com/yincongcyincong/telegram-deepseek-bot"&gt;https://github.com/yincongcyincong/telegram-deepseek-bot&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;Overall Workflow: Intelligent Task Decomposition and Execution&lt;/h1&gt; &lt;p&gt;The core of this automated process is to take a &amp;quot;main task&amp;quot; and break it down into several manageable &amp;quot;subtasks.&amp;quot; Each subtask is then matched with the most suitable executor, which could be a specific &lt;strong&gt;Multi-modal Computing Platform (MCP) service&lt;/strong&gt; or a &lt;strong&gt;Large Language Model (LLM)&lt;/strong&gt; itself. The entire process operates in a cyclical, iterative manner until all subtasks are completed and the results are finally summarized.&lt;/p&gt; &lt;p&gt;Here's a breakdown of the specific steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Prompt-driven Task Decomposition:&lt;/strong&gt; The process begins with the system receiving a main task. A specialized &amp;quot;&lt;strong&gt;Deep Researcher&lt;/strong&gt;&amp;quot; role, defined by a specific prompt, is used to break down this main task into a series of automated subtasks. The &amp;quot;Deep Researcher&amp;quot;'s responsibility is to analyze the main task, identify all data or information required for the &amp;quot;Output Expert&amp;quot; to generate the final deliverable, and design a detailed execution plan for the subtasks. It intentionally ignores the final output format, focusing solely on data collection and information provision.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Subtask Assignment:&lt;/strong&gt; Each decomposed subtask is intelligently assigned based on its requirements and the &lt;strong&gt;descriptions of various MCP services&lt;/strong&gt;. If a suitable MCP service exists, the subtask is directly assigned to it. If no match is found, the task is assigned directly to the Large Language Model (llm_tool) for processing.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;LLM Function Configuration:&lt;/strong&gt; For assigned subtasks, the system configures different &lt;strong&gt;function calls&lt;/strong&gt; for the Large Language Model. This ensures the LLM can specifically handle the subtask and retrieve the necessary data or information.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Looping Inquiry and Judgment:&lt;/strong&gt; After a subtask is completed, the system &lt;strong&gt;queries the Large Language Model again&lt;/strong&gt; to determine if there are any uncompleted subtasks. This is a crucial feedback loop mechanism that ensures continuous task progression.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Iterative Execution:&lt;/strong&gt; If there are remaining subtasks, the process returns to steps 2-4, continuing with subtask assignment, processing, and inquiry.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Result Summarization:&lt;/strong&gt; Once all subtasks are completed, the process moves into the &lt;strong&gt;summarization stage&lt;/strong&gt;, returning the final result related to the main task.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/c914htv1h69f1.jpg?width=732&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4d454fea665504b1e478a67fc130377da95fe1be"&gt;https://preview.redd.it/c914htv1h69f1.jpg?width=732&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4d454fea665504b1e478a67fc130377da95fe1be&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;Workflow Diagram&lt;/h1&gt; &lt;h1&gt;Core Prompt Examples&lt;/h1&gt; &lt;p&gt;Here are the key prompts used in the system:&lt;/p&gt; &lt;h1&gt;Task Decomposition Prompt:&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;Role: * You are a professional deep researcher. Your responsibility is to plan tasks using a team of professional intelligent agents to gather sufficient and necessary information for the &amp;quot;Output Expert.&amp;quot; * The Output Expert is a powerful agent capable of generating deliverables such as documents, spreadsheets, images, and audio. Responsibilities: 1. Analyze the main task and determine all data or information the Output Expert needs to generate the final deliverable. 2. Design a series of automated subtasks, with each subtask executed by a suitable &amp;quot;Working Agent.&amp;quot; Carefully consider the main objective of each step and create a planning outline. Then, define the detailed execution process for each subtask. 3. Ignore the final deliverable required by the main task: subtasks only focus on providing data or information, not generating output. 4. Based on the main task and completed subtasks, generate or update your task plan. 5. Determine if all necessary information or data has been collected for the Output Expert. 6. Track task progress. If the plan needs updating, avoid repeating completed subtasks – only generate the remaining necessary subtasks. 7. If the task is simple and can be handled directly (e.g., writing code, creative writing, basic data analysis, or prediction), immediately use `llm_tool` without further planning. Available Working Agents: {{range $i, $tool := .assign_param}}- Agent Name: {{$tool.tool_name}} Agent Description: {{$tool.tool_desc}} {{end}} Main Task: {{.user_task}} Output Format (JSON): ```json { &amp;quot;plan&amp;quot;: [ { &amp;quot;name&amp;quot;: &amp;quot;Name of the agent required for the first task&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;Detailed instructions for executing step 1&amp;quot; }, { &amp;quot;name&amp;quot;: &amp;quot;Name of the agent required for the second task&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;Detailed instructions for executing step 2&amp;quot; }, ... ] } &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;Example of Returned Result from Decomposition Prompt:&lt;/h1&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/k9fymn38h69f1.png?width=791&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d903d9683bdf8d8e5e8043dad8bb23a95cae1c37"&gt;https://preview.redd.it/k9fymn38h69f1.png?width=791&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d903d9683bdf8d8e5e8043dad8bb23a95cae1c37&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;### Loop Task Prompt: Main Task: {{.user\_task}} **Completed Subtasks:** {{range $task, $res := .complete\_tasks}} \- Subtask: {{$task}} {{end}} **Current Task Plan:** {{.last\_plan}} Based on the above information, create or update the task plan. If the task is complete, return an empty plan list. **Note:** - Carefully analyze the completion status of previously completed subtasks to determine the next task plan. - Appropriately and reasonably add details to ensure the working agent or tool has sufficient information to execute the task. - The expanded description must not deviate from the main objective of the subtask. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can see which MCPs are called through the logs:&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/bwyzpp9dh69f1.png?width=640&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=441ad7b6ff07e85e1406cf730069114bc207f457"&gt;https://preview.redd.it/bwyzpp9dh69f1.png?width=640&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=441ad7b6ff07e85e1406cf730069114bc207f457&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;Summary Task Prompt:&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;Based on the question, summarize the key points from the search results and other reference information in plain text format. Main Task: {{.user\_task}}&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;Deepseek's Returned Summary:&lt;/h1&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/ed1v65jeh69f1.png?width=640&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=caf406308fd2fcde19738e434acd736b564d767e"&gt;https://preview.redd.it/ed1v65jeh69f1.png?width=640&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=caf406308fd2fcde19738e434acd736b564d767e&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;Why Differentiate Function Calls Based on MCP Services?&lt;/h1&gt; &lt;p&gt;Based on the provided information, there are two main reasons to differentiate &lt;strong&gt;Function Calls&lt;/strong&gt; according to the specific &lt;strong&gt;MCP (Multi-modal Computing Platform) services&lt;/strong&gt;:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Prevent LLM Context Overflow:&lt;/strong&gt; Large Language Models (LLMs) have strict &lt;strong&gt;context token limits&lt;/strong&gt;. If all MCP functions were directly crammed into the LLM's request context, it would very likely exceed this limit, preventing normal processing.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Optimize Token Usage Efficiency:&lt;/strong&gt; Stuffing a large number of MCP functions into the context significantly increases &lt;strong&gt;token usage&lt;/strong&gt;. Tokens are a crucial unit for measuring the computational cost and efficiency of LLMs; an increase in token count means higher costs and longer processing times. By differentiating Function Calls, the system can provide the LLM with only the most relevant Function Calls for the current subtask, drastically reducing token consumption and improving overall efficiency.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;In short, this strategy of differentiating Function Calls aims to &lt;strong&gt;ensure the LLM's processing capability&lt;/strong&gt; while &lt;strong&gt;optimizing resource utilization&lt;/strong&gt;, avoiding unnecessary context bloat and token waste.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;telegram-deepseek-bot Core Method Breakdown&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Here's a look at some of the key Go functions in the bot's codebase:&lt;/p&gt; &lt;h1&gt;ExecuteTask() Method&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;func (d *DeepseekTaskReq) ExecuteTask() { // Set a 15-minute timeout context ctx, cancel := context.WithTimeout(context.Background(), 15*time.Minute) defer cancel() // Prepare task parameters taskParam := make(map[string]interface{}) taskParam[&amp;quot;assign_param&amp;quot;] = make([]map[string]string, 0) taskParam[&amp;quot;user_task&amp;quot;] = d.Content // Add available tool information for name, tool := range conf.TaskTools { taskParam[&amp;quot;assign_param&amp;quot;] = append(taskParam[&amp;quot;assign_param&amp;quot;].([]map[string]string), map[string]string{ &amp;quot;tool_name&amp;quot;: name, &amp;quot;tool_desc&amp;quot;: tool.Description, }) } // Create LLM client llm := NewLLM(WithBot(d.Bot), WithUpdate(d.Update), WithMessageChan(d.MessageChan)) // Get and send task assignment prompt prompt := i18n.GetMessage(*conf.Lang, &amp;quot;assign_task_prompt&amp;quot;, taskParam) llm.LLMClient.GetUserMessage(prompt) llm.Content = prompt // Send synchronous request c, err := llm.LLMClient.SyncSend(ctx, llm) if err != nil { logger.Error(&amp;quot;get message fail&amp;quot;, &amp;quot;err&amp;quot;, err) return } // Parse AI-returned JSON task plan matches := jsonRe.FindAllString(c, -1) plans := new(TaskInfo) for _, match := range matches { err = json.Unmarshal([]byte(match), &amp;amp;plans) if err != nil { logger.Error(&amp;quot;json umarshal fail&amp;quot;, &amp;quot;err&amp;quot;, err) } } // If no plan, directly request summary if len(plans.Plan) == 0 { finalLLM := NewLLM(WithBot(d.Bot), WithUpdate(d.Update), WithMessageChan(d.MessageChan), WithContent(d.Content)) finalLLM.LLMClient.GetUserMessage(c) err = finalLLM.LLMClient.Send(ctx, finalLLM) return } // Execute task loop llm.LLMClient.GetAssistantMessage(c) d.loopTask(ctx, plans, c, llm) // Final summary summaryParam := make(map[string]interface{}) summaryParam[&amp;quot;user_task&amp;quot;] = d.Content llm.LLMClient.GetUserMessage(i18n.GetMessage(*conf.Lang, &amp;quot;summary_task_prompt&amp;quot;, summaryParam)) err = llm.LLMClient.Send(ctx, llm) } &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;loopTask() Method&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;func (d *DeepseekTaskReq) loopTask(ctx context.Context, plans *TaskInfo, lastPlan string, llm *LLM) { // Record completed tasks completeTasks := map[string]bool{} // Create a dedicated LLM instance for tasks taskLLM := NewLLM(WithBot(d.Bot), WithUpdate(d.Update), WithMessageChan(d.MessageChan)) defer func() { llm.LLMClient.AppendMessages(taskLLM.LLMClient) }() // Execute each subtask for _, plan := range plans.Plan { // Configure task tool o := WithTaskTools(conf.TaskTools[plan.Name]) o(taskLLM) // Send task description taskLLM.LLMClient.GetUserMessage(plan.Description) taskLLM.Content = plan.Description // Execute task d.requestTask(ctx, taskLLM, plan) completeTasks[plan.Description] = true } // Prepare loop task parameters taskParam := map[string]interface{}{ &amp;quot;user_task&amp;quot;: d.Content, &amp;quot;complete_tasks&amp;quot;: completeTasks, &amp;quot;last_plan&amp;quot;: lastPlan, } // Request AI to evaluate if more tasks are needed llm.LLMClient.GetUserMessage(i18n.GetMessage(*conf.Lang, &amp;quot;loop_task_prompt&amp;quot;, taskParam)) c, err := llm.LLMClient.SyncSend(ctx, llm) // Parse new task plan matches := jsonRe.FindAllString(c, -1) plans = new(TaskInfo) for _, match := range matches { err := json.Unmarshal([]byte(match), &amp;amp;plans) } // If there are new tasks, recursively call if len(plans.Plan) &amp;gt; 0 { d.loopTask(ctx, plans, c, llm) } } &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;requestTask() Method&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;func (d *DeepseekTaskReq) requestTask(ctx context.Context, llm *LLM, plan *Task) { // Send synchronous task request c, err := llm.LLMClient.SyncSend(ctx, llm) if err != nil { logger.Error(&amp;quot;ChatCompletionStream error&amp;quot;, &amp;quot;err&amp;quot;, err) return } // Handle empty response if c == &amp;quot;&amp;quot; { c = plan.Name + &amp;quot; is completed&amp;quot; } // Save AI response llm.LLMClient.GetAssistantMessage(c) } &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/SubstantialWord7757"&gt; /u/SubstantialWord7757 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lko1te/shocking_this_is_how_multimcp_agent_interaction/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lko1te/shocking_this_is_how_multimcp_agent_interaction/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lko1te/shocking_this_is_how_multimcp_agent_interaction/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-26T01:56:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1lknkvg</id>
    <title>ChatGPT support on your favorite MCP inspector (update)</title>
    <updated>2025-06-26T01:33:21+00:00</updated>
    <author>
      <name>/u/matt8p</name>
      <uri>https://old.reddit.com/user/matt8p</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lknkvg/chatgpt_support_on_your_favorite_mcp_inspector/"&gt; &lt;img alt="ChatGPT support on your favorite MCP inspector (update)" src="https://external-preview.redd.it/ZHozaHRyc2ZjNjlmMWXX5kJDgVxVcIT2wcdv3-Nsop1W7F6nEEvjqxfRuPhu.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d6d2e878232248503355e967a083088382dcc814" title="ChatGPT support on your favorite MCP inspector (update)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi y'all, I’m building &lt;a href="https://github.com/MCPJam/inspector"&gt;MCPJam inspector&lt;/a&gt;, Postman for MCP. It’s an open source tool to help test and debug your MCP server.&lt;/p&gt; &lt;p&gt;We have built in LLM chat to help you test your MCP against an LLM. Today, we just launched ChatGPT support!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;LLM Chat now supports OpenAI models&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;You can now interact with our MCP server with LLM chat and OpenAI. We currently support OpenAI and Claude models. &lt;/li&gt; &lt;li&gt;Open AI models include 4o, 4o-mini, 4 Turbo, 4, 3.5 Turbo&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;What’s coming next&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We been asked to support local models (Ollama). That’s coming soon, as soon as tomorrow.&lt;/li&gt; &lt;li&gt;What providers would you like to see?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;We're looking for community contribution&lt;/strong&gt; &lt;/p&gt; &lt;p&gt;If you like the project, please consider adding a star and leaving a comment. &lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/MCPJam/inspector"&gt;https://github.com/MCPJam/inspector&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We'd also like to invite the MCP community to contribute to this project. We're our next goal is to add Ollama, so we could use some help there. Please join our Discord, we're pretty active there. &lt;/p&gt; &lt;p&gt;&lt;a href="https://discord.com/invite/Gpv7AmrRc4"&gt;https://discord.com/invite/Gpv7AmrRc4&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/matt8p"&gt; /u/matt8p &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/qlycaxsfc69f1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lknkvg/chatgpt_support_on_your_favorite_mcp_inspector/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lknkvg/chatgpt_support_on_your_favorite_mcp_inspector/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-26T01:33:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1lk5sa5</id>
    <title>[Open Source] Full boilerplate Typescript MCP server for the community - Complete with OAuth 2.1, and every MCP feature (sampling, elicitation, progress) implemented.</title>
    <updated>2025-06-25T13:32:35+00:00</updated>
    <author>
      <name>/u/AffectionateHoney992</name>
      <uri>https://old.reddit.com/user/AffectionateHoney992</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: Our product is an MCP client, and while building it, we developed multiple MCP servers to test the full range of the spec. Instead of keeping it internal, we've updated it and are open-sourcing the entire thing. Works out the box with the official inspector or any client (in theory, do let us know any issues!) &lt;/p&gt; &lt;p&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href="https://github.com/systempromptio/systemprompt-mcp-server"&gt;https://github.com/systempromptio/systemprompt-mcp-server&lt;/a&gt;&lt;br /&gt; &lt;strong&gt;NPM&lt;/strong&gt;: &lt;code&gt;npx @systemprompt/systemprompt-mcp-server&lt;/code&gt; (instant Docker setup!)&lt;/p&gt; &lt;p&gt;First off, massive thanks to this community. Your contributions to the MCP ecosystem have been incredible. When we started building our MCP client, we quickly realized we needed rock-solid server implementations to test against. What began as an internal tool evolved into something we think can help everyone building in this space.&lt;/p&gt; &lt;p&gt;So we're donating our entire production MCP server to the community. No strings attached, MIT licensed, ready to fork and adapt.&lt;/p&gt; &lt;h1&gt;Why We're Doing This&lt;/h1&gt; &lt;p&gt;Building MCP servers is HARD. OAuth flows, session management, proper error handling - there's a ton of complexity. We spent months getting this right for our client testing, and we figured that everyone here has to solve these same problems...&lt;/p&gt; &lt;p&gt;This isn't some stripped-down demo. This is an adaption of the actual servers we use in production, with all the battle-tested code, security measures, and architectural decisions intact.&lt;/p&gt; &lt;h1&gt;🚀 What Makes This Special&lt;/h1&gt; &lt;p&gt;&lt;strong&gt;This is a HIGH-EFFORT implementation.&lt;/strong&gt; We're talking months of work here:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;✅ &lt;strong&gt;Every MCP Method in the Latest Spec&lt;/strong&gt; - Not just the basics, EVERYTHING&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;Working OAuth 2.1 with PKCE&lt;/strong&gt; - Not a mock, actual production OAuth that handles all edge cases&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;Full E2E Test Suite&lt;/strong&gt; - Both TypeScript SDK tests AND raw HTTP/SSE tests&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;AI Sampling&lt;/strong&gt; - The new human-in-the-loop feature fully implemented&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;Real-time Notifications&lt;/strong&gt; - SSE streams, progress updates, the works&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;Multi-user Sessions&lt;/strong&gt; - Proper isolation, no auth leaks between users&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;Production Security&lt;/strong&gt; - Rate limiting, CORS, JWT auth, input validation&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;100% TypeScript&lt;/strong&gt; - Full type safety, strict mode, no any's!&lt;/li&gt; &lt;li&gt;✅ &lt;strong&gt;Comprehensive Error Handling&lt;/strong&gt; - Every edge case we could think of&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;🛠️ The Technical Goodies&lt;/h1&gt; &lt;p&gt;Here's what I'm most proud of:&lt;/p&gt; &lt;h1&gt;The OAuth Implementation (Fully Working!)&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;// Not just basic OAuth - this is the full MCP spec: // - Dynamic registration support // - PKCE flow for security // - JWT tokens with encrypted credentials // - Automatic refresh handling // - Per-session isolation &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;Complete E2E Test Coverage&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;# TypeScript SDK tests npm run test:sdk # Raw HTTP/SSE tests npm run test:http # Concurrent stress tests npm run test:concurrent &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;The Sampling Flow&lt;/h1&gt; &lt;p&gt;This blew my mind when I first understood it:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Server asks client for AI help&lt;/li&gt; &lt;li&gt;Client shows user what it wants to do&lt;/li&gt; &lt;li&gt;User approves/modifies&lt;/li&gt; &lt;li&gt;AI generates content&lt;/li&gt; &lt;li&gt;User reviews final output&lt;/li&gt; &lt;li&gt;Server gets approved content&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It's like having a human-supervised AI assistant built into the protocol!&lt;/p&gt; &lt;h1&gt;Docker One-Liner&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;# Literally this simple: docker run -it --rm -p 3000:3000 --env-file .env \ node:20-slim npx @systemprompt/systemprompt-mcp-server &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;No installation. No setup. Just works.&lt;/p&gt; &lt;h1&gt;The Architecture&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;Your MCP Client (Claude, etc.) ↓ MCP Protocol Layer ↓ ┌─────────────────────────────┐ │ Session Manager (Multi-user)│ ├─────────────────────────────┤ │ OAuth Handler (Full 2.1) │ ├─────────────────────────────┤ │ Tools + Sampling + Notifs │ ├─────────────────────────────┤ │ Reddit Service Layer │ └─────────────────────────────┘ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Each component is modular. Want to add GitHub instead of Reddit? Just swap the service layer. The MCP infrastructure stays the same.&lt;/p&gt; &lt;h1&gt;💡 Real Examples That Work&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;// Search Reddit with AI assistance const results = await searchReddit({ query: &amp;quot;best TypeScript practices&amp;quot;, subreddit: &amp;quot;programming&amp;quot;, sort: &amp;quot;top&amp;quot;, timeRange: &amp;quot;month&amp;quot; }); // Get notifications with real-time updates // The client sees progress as it happens! const notifications = await getNotifications({ filter: &amp;quot;mentions&amp;quot;, markAsRead: true }); &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;What We Learned&lt;/h1&gt; &lt;p&gt;Building this taught us SO much about MCP:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;State management is crucial for multi-user support&lt;/li&gt; &lt;li&gt;OAuth in MCP needs careful session isolation&lt;/li&gt; &lt;li&gt;Sampling is incredibly powerful for AI+human workflows&lt;/li&gt; &lt;li&gt;Good error messages save hours of debugging&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Try It Right Now&lt;/h1&gt; &lt;p&gt;Seriously, if you have Docker, you can run this in 2 minutes:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create Reddit app at &lt;a href="https://reddit.com/prefs/apps"&gt;reddit.com/prefs/apps&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Make an &lt;code&gt;.env&lt;/code&gt; file:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&amp;#8203;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;REDDIT_CLIENT_ID=your_id REDDIT_CLIENT_SECRET=your_secret JWT_SECRET=any_random_string &lt;/code&gt;&lt;/pre&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Run it:&lt;/p&gt; &lt;p&gt;docker run -it --rm -p 3000:3000 --env-file .env \ node:20-slim npx @systemprompt/systemprompt-mcp-server&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;We're actively looking for feedback!&lt;/strong&gt; This is v1.0, and we know there's always room to improve:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Found a bug? Please report it!&lt;/li&gt; &lt;li&gt;Have a better pattern? PR it!&lt;/li&gt; &lt;li&gt;Want a feature? Let's discuss!&lt;/li&gt; &lt;li&gt;Building something similar? Let's collaborate!&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Got questions? Hit me up! We're also on &lt;a href="https://discord.com/invite/wkAbSuPWpr"&gt;Discord&lt;/a&gt; if you want to chat about MCP implementation details.&lt;/p&gt; &lt;h1&gt;Interactive blog&lt;/h1&gt; &lt;p&gt;&lt;a href="https://systemprompt.io/mcp-server"&gt;systemprompt demo&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;🙏 Thank You!&lt;/h1&gt; &lt;p&gt;Seriously, thank you to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Anthropic&lt;/strong&gt; for creating MCP and being so open with the spec&lt;/li&gt; &lt;li&gt;&lt;strong&gt;The MCP community&lt;/strong&gt; for pushing the boundaries&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Early testers&lt;/strong&gt; who found all our bugs 😅&lt;/li&gt; &lt;li&gt;&lt;strong&gt;You&lt;/strong&gt; for reading this far!&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This is our way of giving back. We hope it helps you build amazing things.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;P.S.&lt;/strong&gt; - If you find this useful, a GitHub star means the world to us! And if you build something cool with it, please share - we love seeing what people create!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;P.S.S&lt;/strong&gt; Yes, AI (helped) me write this post, thank you Opus for the expensive tokens, all writing was personally vetted by myself however! &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Links:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;GitHub: &lt;a href="https://github.com/systempromptio/systemprompt-mcp-server"&gt;https://github.com/systempromptio/systemprompt-mcp-server&lt;/a&gt;&lt;/li&gt; &lt;li&gt;NPM: &lt;a href="https://www.npmjs.com/package/@systemprompt/systemprompt-mcp-server"&gt;@systemprompt/systemprompt-mcp-server&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Our MCP Client: &lt;a href="https://systemprompt.io"&gt;systemprompt.io&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Discord: &lt;a href="https://discord.com/invite/wkAbSuPWpr"&gt;Join our community&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AffectionateHoney992"&gt; /u/AffectionateHoney992 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk5sa5/open_source_full_boilerplate_typescript_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk5sa5/open_source_full_boilerplate_typescript_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lk5sa5/open_source_full_boilerplate_typescript_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T13:32:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1lkd0sw</id>
    <title>Got my first full MCP stack (Tools + Prompts + Resources) running 🎉</title>
    <updated>2025-06-25T18:10:06+00:00</updated>
    <author>
      <name>/u/cyber_harsh</name>
      <uri>https://old.reddit.com/user/cyber_harsh</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1lkd0sw/got_my_first_full_mcp_stack_tools_prompts/"&gt; &lt;img alt="Got my first full MCP stack (Tools + Prompts + Resources) running 🎉" src="https://preview.redd.it/ra8cf1cb649f1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=161da2e142976bec327b18f7d997a8a227f4a020" title="Got my first full MCP stack (Tools + Prompts + Resources) running 🎉" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I finally took a weekend to dive deep into MCP and wrote up everything I wish I’d known before starting - setting up a clean workspace with uv + fastmcp, wiring a “hello_world” tool, adding prompt templates, and even exposing local files/images as resources (turns out MCP’s resource URIs are insanely flexible).&lt;/p&gt; &lt;p&gt;A few highlights from the guide:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; Workspace first – MCP can nuke your FS if you’re careless, so I demo the “mkdir mcp &amp;amp;&amp;amp; uv venv .venv” flow for a totally sandboxed setup.&lt;br /&gt;&lt;/li&gt; &lt;li&gt; Tools as simple Python functions – decorated with &lt;code&gt;@mcp.tool&lt;/code&gt;, instantly discoverable via tools/list.&lt;br /&gt;&lt;/li&gt; &lt;li&gt; Prompt templates that feel like f-strings – &lt;code&gt;@mcp.prompt&lt;/code&gt; lets you reuse the same prompt skeleton everywhere.&lt;br /&gt;&lt;/li&gt; &lt;li&gt; Resources = partial RAG for free – expose text, DB rows, even JPEGs as &lt;code&gt;protocol://host/path&lt;/code&gt; URIs the LLM can reference.&lt;br /&gt;&lt;/li&gt; &lt;li&gt; Example agents: utility CLI, data-science toolbox, IRCTC helper, research assistant, code debugger… lots of starter ideas in the post.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If any of that sounds useful, the full walkthrough is here: &lt;a href="https://composio.dev/blog/how-to-effectively-use-prompts-resources-and-tools-in-mcp/"&gt;A Brief Intro to MCP (workspace, code snippets, inspector screenshots, etc.)&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Curious—what MCP servers/tools have you built or plugged into lately that actually moved the needle for you? Always looking for inspo!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cyber_harsh"&gt; /u/cyber_harsh &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/ra8cf1cb649f1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lkd0sw/got_my_first_full_mcp_stack_tools_prompts/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lkd0sw/got_my_first_full_mcp_stack_tools_prompts/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T18:10:06+00:00</published>
  </entry>
  <entry>
    <id>t3_1lk5ous</id>
    <title>Google releases Gemini CLI - with full MCP Support</title>
    <updated>2025-06-25T13:28:41+00:00</updated>
    <author>
      <name>/u/coding9</name>
      <uri>https://old.reddit.com/user/coding9</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/google-gemini/gemini-cli"&gt;https://github.com/google-gemini/gemini-cli&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/coding9"&gt; /u/coding9 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk5ous/google_releases_gemini_cli_with_full_mcp_support/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1lk5ous/google_releases_gemini_cli_with_full_mcp_support/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1lk5ous/google_releases_gemini_cli_with_full_mcp_support/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-06-25T13:28:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7pl2v</id>
    <title>Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers</title>
    <updated>2024-12-06T01:23:42+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt; &lt;img alt="Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers" src="https://external-preview.redd.it/BlNcrgap-6pz7IdUsbomFSVuqp_BB8tTUEFVIk6by18.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f25629e364c60f72e8d88ce33c5b1f90a326c065" title="Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/punkpeye/awesome-mcp-servers/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T01:23:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7qe88</id>
    <title>Join the Model Context Protocol Discord Server!</title>
    <updated>2024-12-06T02:04:10+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/discord"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T02:04:10+00:00</published>
  </entry>
</feed>
