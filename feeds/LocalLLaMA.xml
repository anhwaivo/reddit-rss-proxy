<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-08-07T21:05:45+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss AI &amp; Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1mk7hic</id>
    <title>Another interesting graph</title>
    <updated>2025-08-07T18:10:56+00:00</updated>
    <author>
      <name>/u/Impressive_Half_2819</name>
      <uri>https://old.reddit.com/user/Impressive_Half_2819</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7hic/another_interesting_graph/"&gt; &lt;img alt="Another interesting graph" src="https://preview.redd.it/mxih9ttn1nhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=98ed7bbca85ece0a320821b7f761c27a208f8041" title="Another interesting graph" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;In the left graph 55.0 higher than 58.1?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Impressive_Half_2819"&gt; /u/Impressive_Half_2819 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/mxih9ttn1nhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7hic/another_interesting_graph/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7hic/another_interesting_graph/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T18:10:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk0fxu</id>
    <title>DeepSeek’s MOE approach for lower model hope</title>
    <updated>2025-08-07T13:42:14+00:00</updated>
    <author>
      <name>/u/exaknight21</name>
      <uri>https://old.reddit.com/user/exaknight21</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Seeing recent Qwen3-30B-A3B, I am praying DeepSeek release something like that too. I’m surprised at the kick it gives without breaking the bank on GPUs. &lt;/p&gt; &lt;p&gt;I think Qwen should be a role model to all LLM researchers. It will bring AI to our daily drivers too.&lt;/p&gt; &lt;p&gt;Fascinating times we live in. This is where it will bend and mend.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/exaknight21"&gt; /u/exaknight21 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk0fxu/deepseeks_moe_approach_for_lower_model_hope/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk0fxu/deepseeks_moe_approach_for_lower_model_hope/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk0fxu/deepseeks_moe_approach_for_lower_model_hope/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T13:42:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk92k4</id>
    <title>gabriellarson/Huihui-gpt-oss-20b-BF16-abliterated-GGUF · Hugging Face</title>
    <updated>2025-08-07T19:10:48+00:00</updated>
    <author>
      <name>/u/jacek2023</name>
      <uri>https://old.reddit.com/user/jacek2023</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk92k4/gabriellarsonhuihuigptoss20bbf16abliteratedgguf/"&gt; &lt;img alt="gabriellarson/Huihui-gpt-oss-20b-BF16-abliterated-GGUF · Hugging Face" src="https://external-preview.redd.it/dM2syJ0lh5qODrveCus4LDlR8L4f9r_ltO_PMWMUbDA.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d8ef5dae58a1931f159f19948400500dc5e8110f" title="gabriellarson/Huihui-gpt-oss-20b-BF16-abliterated-GGUF · Hugging Face" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jacek2023"&gt; /u/jacek2023 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/gabriellarson/Huihui-gpt-oss-20b-BF16-abliterated-GGUF"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk92k4/gabriellarsonhuihuigptoss20bbf16abliteratedgguf/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk92k4/gabriellarsonhuihuigptoss20bbf16abliteratedgguf/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T19:10:48+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk6qmn</id>
    <title>"Grok 4 is still state-of-the-art on ARC-AGI-2 among frontier models" I wish xai focus more on post training</title>
    <updated>2025-08-07T17:43:03+00:00</updated>
    <author>
      <name>/u/mvp525</name>
      <uri>https://old.reddit.com/user/mvp525</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6qmn/grok_4_is_still_stateoftheart_on_arcagi2_among/"&gt; &lt;img alt="&amp;quot;Grok 4 is still state-of-the-art on ARC-AGI-2 among frontier models&amp;quot; I wish xai focus more on post training" src="https://preview.redd.it/7da76unowmhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=303cedbdf13931269bf0044cf9992db93be9e42f" title="&amp;quot;Grok 4 is still state-of-the-art on ARC-AGI-2 among frontier models&amp;quot; I wish xai focus more on post training" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mvp525"&gt; /u/mvp525 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/7da76unowmhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6qmn/grok_4_is_still_stateoftheart_on_arcagi2_among/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6qmn/grok_4_is_still_stateoftheart_on_arcagi2_among/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T17:43:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjoo7w</id>
    <title>Huihui released GPT-OSS 20b abliterated</title>
    <updated>2025-08-07T02:50:59+00:00</updated>
    <author>
      <name>/u/_extruded</name>
      <uri>https://old.reddit.com/user/_extruded</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Huihui released an abliterated version of GPT-OSS-20b&lt;/p&gt; &lt;p&gt;Waiting for the GGUF but excited to try out how uncensored it really is, after that disastrous start&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated"&gt;https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/_extruded"&gt; /u/_extruded &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjoo7w/huihui_released_gptoss_20b_abliterated/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjoo7w/huihui_released_gptoss_20b_abliterated/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjoo7w/huihui_released_gptoss_20b_abliterated/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T02:50:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjwyhl</id>
    <title>JetBrains is studying local AI adoption</title>
    <updated>2025-08-07T10:57:59+00:00</updated>
    <author>
      <name>/u/jan-niklas-wortmann</name>
      <uri>https://old.reddit.com/user/jan-niklas-wortmann</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I'm Jan-Niklas, Developer Advocate at JetBrains and we are researching how developers are actually using local LLMs. Local AI adoption is super interesting for us, but there's limited research on real-world usage patterns. If you're running models locally (whether on your gaming rig, homelab, or cloud instances you control), I'd really value your insights. The survey takes about 10 minutes and covers things like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Which models/tools you prefer and why&lt;/li&gt; &lt;li&gt;Use cases that work better locally vs. API calls&lt;/li&gt; &lt;li&gt;Pain points in the local ecosystem&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Results will be published openly and shared back with the community once we are done with our evaluation. As a small thank-you, there's a chance to win an Amazon gift card or JetBrains license.&lt;br /&gt; Click &lt;a href="https://surveys.jetbrains.com/s3/patterns-of-ai-models-usage-rpost"&gt;here&lt;/a&gt; to take the survey&lt;/p&gt; &lt;p&gt;Happy to answer questions you might have, thanks a bunch!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jan-niklas-wortmann"&gt; /u/jan-niklas-wortmann &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjwyhl/jetbrains_is_studying_local_ai_adoption/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjwyhl/jetbrains_is_studying_local_ai_adoption/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjwyhl/jetbrains_is_studying_local_ai_adoption/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T10:57:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk87kd</id>
    <title>Polymarket</title>
    <updated>2025-08-07T18:38:21+00:00</updated>
    <author>
      <name>/u/V4ldeLund</name>
      <uri>https://old.reddit.com/user/V4ldeLund</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk87kd/polymarket/"&gt; &lt;img alt="Polymarket" src="https://preview.redd.it/puuand3c6nhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7fd560e7d342a8544893e31baa753e80a4522002" title="Polymarket" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;It's too much winning Sam, please stop /s&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/V4ldeLund"&gt; /u/V4ldeLund &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/puuand3c6nhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk87kd/polymarket/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk87kd/polymarket/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T18:38:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk7r1g</id>
    <title>Trained an 41M HRM-Based Model to generate semi-coherent text!</title>
    <updated>2025-08-07T18:20:52+00:00</updated>
    <author>
      <name>/u/random-tomato</name>
      <uri>https://old.reddit.com/user/random-tomato</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7r1g/trained_an_41m_hrmbased_model_to_generate/"&gt; &lt;img alt="Trained an 41M HRM-Based Model to generate semi-coherent text!" src="https://b.thumbs.redditmedia.com/5IXZKHsgxD2_snxB5qYDZsSXRsrSDWyvbqoNOIrkjvM.jpg" title="Trained an 41M HRM-Based Model to generate semi-coherent text!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/random-tomato"&gt; /u/random-tomato &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1mk7r1g"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7r1g/trained_an_41m_hrmbased_model_to_generate/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7r1g/trained_an_41m_hrmbased_model_to_generate/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T18:20:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk5n89</id>
    <title>HuggingFace has been on a deletion spree and has already removed 16TB worth of files. dets in screenshots slide</title>
    <updated>2025-08-07T17:02:37+00:00</updated>
    <author>
      <name>/u/Tango-Down766</name>
      <uri>https://old.reddit.com/user/Tango-Down766</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk5n89/huggingface_has_been_on_a_deletion_spree_and_has/"&gt; &lt;img alt="HuggingFace has been on a deletion spree and has already removed 16TB worth of files. dets in screenshots slide" src="https://b.thumbs.redditmedia.com/-NXaX5EHmxxb7GBcWRIp5vrkgUBJaiSRrpm9inzqlEM.jpg" title="HuggingFace has been on a deletion spree and has already removed 16TB worth of files. dets in screenshots slide" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://civitaiarchive.com/"&gt;https://civitaiarchive.com/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Tango-Down766"&gt; /u/Tango-Down766 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1mk5n89"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk5n89/huggingface_has_been_on_a_deletion_spree_and_has/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk5n89/huggingface_has_been_on_a_deletion_spree_and_has/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T17:02:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjsjkn</id>
    <title>If the gpt-oss models were made by any other company than OpenAI would anyone care about them?</title>
    <updated>2025-08-07T06:22:14+00:00</updated>
    <author>
      <name>/u/chunkypenguion1991</name>
      <uri>https://old.reddit.com/user/chunkypenguion1991</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Pretty much what the title says. But to expand they are worse at coding than qwen 32B, more hallucinations than fireman festival, and they seem to be trained only to pass benchmarks. If any other company released this, it would be a shoulder shrug, yeah thats good I guess, and move on&lt;/p&gt; &lt;p&gt;Edit: I'm not asking if it's good. I'm asking if without the OpenAI name behind it would ot get this much hype&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/chunkypenguion1991"&gt; /u/chunkypenguion1991 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T06:22:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk7u6i</id>
    <title>GPT 5 seems worse than Gemini in head-to-head</title>
    <updated>2025-08-07T18:24:11+00:00</updated>
    <author>
      <name>/u/nypdk</name>
      <uri>https://old.reddit.com/user/nypdk</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7u6i/gpt_5_seems_worse_than_gemini_in_headtohead/"&gt; &lt;img alt="GPT 5 seems worse than Gemini in head-to-head" src="https://b.thumbs.redditmedia.com/BkR-ESFutx328ilHuO5vEwJk72Q5qEOzvUlacIGXlSo.jpg" title="GPT 5 seems worse than Gemini in head-to-head" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/jcuuuedh3nhf1.png?width=1032&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=54ca5f632741b68b51c12ebeb30ec2d9cf56976b"&gt;https://preview.redd.it/jcuuuedh3nhf1.png?width=1032&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=54ca5f632741b68b51c12ebeb30ec2d9cf56976b&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This image from &lt;a href="http://lmarena.ai/leaderboard/text"&gt;lmarena.ai/leaderboard/text&lt;/a&gt; shows that Gemini beats GPT-5, and that the winrates for Gemini are still higher. Not really sure what the hype is around the model in this case, especially when companies can fine tune to fit benchmarks. This is really the only thing that matters, and gemini still has higher WR in battles (66% vs 62%)&lt;/p&gt; &lt;p&gt;UPDATE: It looks like they pulled that image LOL. Not sure if the elo is just being flat out manipulated then but here is a similarish plot for one of the subcategories:&lt;/p&gt; &lt;p&gt;&lt;a href="https://lmarena.ai/leaderboard/text/english"&gt;https://lmarena.ai/leaderboard/text/english&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/nypdk"&gt; /u/nypdk &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7u6i/gpt_5_seems_worse_than_gemini_in_headtohead/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7u6i/gpt_5_seems_worse_than_gemini_in_headtohead/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk7u6i/gpt_5_seems_worse_than_gemini_in_headtohead/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T18:24:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjw40a</id>
    <title>Nonescape: SOTA AI-Image Detection Model (Open-Source)</title>
    <updated>2025-08-07T10:08:24+00:00</updated>
    <author>
      <name>/u/e3ntity_</name>
      <uri>https://old.reddit.com/user/e3ntity_</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjw40a/nonescape_sota_aiimage_detection_model_opensource/"&gt; &lt;img alt="Nonescape: SOTA AI-Image Detection Model (Open-Source)" src="https://preview.redd.it/6p2s5uidnkhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fcd836239c046a643a71f476cd112af2a16585e7" title="Nonescape: SOTA AI-Image Detection Model (Open-Source)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;strong&gt;Model Info&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Nonescape just open-sourced two AI-image detection models: a full model with SOTA accuracy and a mini 80MB model that can run in-browser.&lt;/p&gt; &lt;p&gt;Demo (works with images+videos): &lt;a href="https://www.nonescape.com"&gt;https://www.nonescape.com&lt;/a&gt;&lt;br /&gt; GitHub: &lt;a href="https://github.com/aediliclabs/nonescape"&gt;https://github.com/aediliclabs/nonescape&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Key Features&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The models detect the latest AI-images (including diffusion images, deepfakes, and GANs)&lt;/li&gt; &lt;li&gt;Trained on 1M+ images representative of the internet&lt;/li&gt; &lt;li&gt;Includes Javascript/Python libraries to run the models&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/e3ntity_"&gt; /u/e3ntity_ &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/6p2s5uidnkhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjw40a/nonescape_sota_aiimage_detection_model_opensource/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjw40a/nonescape_sota_aiimage_detection_model_opensource/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T10:08:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk4kt0</id>
    <title>Be careful in selecting providers on openrouter</title>
    <updated>2025-08-07T16:22:25+00:00</updated>
    <author>
      <name>/u/Charuru</name>
      <uri>https://old.reddit.com/user/Charuru</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk4kt0/be_careful_in_selecting_providers_on_openrouter/"&gt; &lt;img alt="Be careful in selecting providers on openrouter" src="https://preview.redd.it/o9dqe3l9imhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=63498a33a88373227cb3e4dd804ff112b545e323" title="Be careful in selecting providers on openrouter" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Charuru"&gt; /u/Charuru &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/o9dqe3l9imhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk4kt0/be_careful_in_selecting_providers_on_openrouter/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk4kt0/be_careful_in_selecting_providers_on_openrouter/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T16:22:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjju67</id>
    <title>No, no, no, wait - on a second thought, I KNOW the answer!</title>
    <updated>2025-08-06T23:11:24+00:00</updated>
    <author>
      <name>/u/Final_Wheel_7486</name>
      <uri>https://old.reddit.com/user/Final_Wheel_7486</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjju67/no_no_no_wait_on_a_second_thought_i_know_the/"&gt; &lt;img alt="No, no, no, wait - on a second thought, I KNOW the answer!" src="https://preview.redd.it/zs8aeebxdhhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fb8196976261024587d9462ed2ceb999cbda98af" title="No, no, no, wait - on a second thought, I KNOW the answer!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Yes, I know my prompt itself is flawed - let me clarify that I don't side with any country in this regard and just wanted to test for the extent of &amp;quot;SAFETY!!1&amp;quot; in OpenAI's new model. I stumbled across this funny reaction here.&lt;/p&gt; &lt;p&gt;Model: GPT-OSS 120b (High reasoning mode), default system prompt, no further context on the official GPT-OSS website.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Final_Wheel_7486"&gt; /u/Final_Wheel_7486 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/zs8aeebxdhhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjju67/no_no_no_wait_on_a_second_thought_i_know_the/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjju67/no_no_no_wait_on_a_second_thought_i_know_the/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T23:11:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk61k5</id>
    <title>GPT 5 pricing</title>
    <updated>2025-08-07T17:17:08+00:00</updated>
    <author>
      <name>/u/sruly_</name>
      <uri>https://old.reddit.com/user/sruly_</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk61k5/gpt_5_pricing/"&gt; &lt;img alt="GPT 5 pricing" src="https://preview.redd.it/erzhspvwrmhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a31a204228ed97ee7f89f2a4281b676d7a6dd615" title="GPT 5 pricing" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Pricing found here &lt;a href="https://openai.com/api/"&gt;https://openai.com/api/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sruly_"&gt; /u/sruly_ &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/erzhspvwrmhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk61k5/gpt_5_pricing/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk61k5/gpt_5_pricing/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T17:17:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk6mnf</id>
    <title>GPT - 5 graph</title>
    <updated>2025-08-07T17:38:58+00:00</updated>
    <author>
      <name>/u/Impressive_Half_2819</name>
      <uri>https://old.reddit.com/user/Impressive_Half_2819</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6mnf/gpt_5_graph/"&gt; &lt;img alt="GPT - 5 graph" src="https://preview.redd.it/gq9em5jyvmhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=cfe8461fc8e2d885741740dc1c86129fc37b05dd" title="GPT - 5 graph" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Just saw another like this.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Impressive_Half_2819"&gt; /u/Impressive_Half_2819 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/gq9em5jyvmhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6mnf/gpt_5_graph/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6mnf/gpt_5_graph/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T17:38:58+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk3rj1</id>
    <title>Jeff Geerling does what Jeff Geerling does best: Quad Strix Halo cluster using Framework Desktop</title>
    <updated>2025-08-07T15:52:01+00:00</updated>
    <author>
      <name>/u/FullstackSensei</name>
      <uri>https://old.reddit.com/user/FullstackSensei</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk3rj1/jeff_geerling_does_what_jeff_geerling_does_best/"&gt; &lt;img alt="Jeff Geerling does what Jeff Geerling does best: Quad Strix Halo cluster using Framework Desktop" src="https://external-preview.redd.it/igoznQW2BgxL6-V1AGb7GkvH_UJSMnHqmBqwd9fNVKM.jpeg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9f53b202537c26df370b20f3e2c66f92c5b25828" title="Jeff Geerling does what Jeff Geerling does best: Quad Strix Halo cluster using Framework Desktop" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;While the setup looks über cool, the software is still not ready to make good use of the hardware.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/FullstackSensei"&gt; /u/FullstackSensei &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://youtu.be/N5xhOqlvRh4"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk3rj1/jeff_geerling_does_what_jeff_geerling_does_best/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk3rj1/jeff_geerling_does_what_jeff_geerling_does_best/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T15:52:01+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk6z83</id>
    <title>GPT5 reveal plots be like (obviously a made-up tweet, don't believe what you see on the internet)</title>
    <updated>2025-08-07T17:52:00+00:00</updated>
    <author>
      <name>/u/AuspiciousApple</name>
      <uri>https://old.reddit.com/user/AuspiciousApple</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6z83/gpt5_reveal_plots_be_like_obviously_a_madeup/"&gt; &lt;img alt="GPT5 reveal plots be like (obviously a made-up tweet, don't believe what you see on the internet)" src="https://preview.redd.it/2y8c20g1ymhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=86626757ac1473a3442080ec17bff52b0ba72e6c" title="GPT5 reveal plots be like (obviously a made-up tweet, don't believe what you see on the internet)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AuspiciousApple"&gt; /u/AuspiciousApple &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/2y8c20g1ymhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6z83/gpt5_reveal_plots_be_like_obviously_a_madeup/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk6z83/gpt5_reveal_plots_be_like_obviously_a_madeup/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T17:52:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjub4z</id>
    <title>llama.cpp HQ</title>
    <updated>2025-08-07T08:14:09+00:00</updated>
    <author>
      <name>/u/jacek2023</name>
      <uri>https://old.reddit.com/user/jacek2023</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjub4z/llamacpp_hq/"&gt; &lt;img alt="llama.cpp HQ" src="https://preview.redd.it/d15gp2d33khf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=356bf4bfc9f7c3e2c9fc089431a35c0a3300f0d2" title="llama.cpp HQ" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jacek2023"&gt; /u/jacek2023 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/d15gp2d33khf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjub4z/llamacpp_hq/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjub4z/llamacpp_hq/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T08:14:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk9qxe</id>
    <title>Fixed the SWE-bench graph:</title>
    <updated>2025-08-07T19:36:45+00:00</updated>
    <author>
      <name>/u/policyweb</name>
      <uri>https://old.reddit.com/user/policyweb</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk9qxe/fixed_the_swebench_graph/"&gt; &lt;img alt="Fixed the SWE-bench graph:" src="https://b.thumbs.redditmedia.com/V9X-wElhTzujCwtEHzajd2V4dcql8pBZRAbgoyQZpuY.jpg" title="Fixed the SWE-bench graph:" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/policyweb"&gt; /u/policyweb &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1mk9qxe"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk9qxe/fixed_the_swebench_graph/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk9qxe/fixed_the_swebench_graph/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T19:36:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk8bh1</id>
    <title>caught in 4K</title>
    <updated>2025-08-07T18:42:23+00:00</updated>
    <author>
      <name>/u/JP_525</name>
      <uri>https://old.reddit.com/user/JP_525</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk8bh1/caught_in_4k/"&gt; &lt;img alt="caught in 4K" src="https://b.thumbs.redditmedia.com/YQrgzZ0f8iGzesSaaIQmX6IpiMlZjzskYA1keLu6UKk.jpg" title="caught in 4K" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/JP_525"&gt; /u/JP_525 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1mk8bh1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk8bh1/caught_in_4k/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk8bh1/caught_in_4k/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T18:42:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk26rk</id>
    <title>Llama.cpp now supports GLM 4.5 Air</title>
    <updated>2025-08-07T14:52:12+00:00</updated>
    <author>
      <name>/u/Freonr2</name>
      <uri>https://old.reddit.com/user/Freonr2</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk26rk/llamacpp_now_supports_glm_45_air/"&gt; &lt;img alt="Llama.cpp now supports GLM 4.5 Air" src="https://b.thumbs.redditmedia.com/jawkehNzIT0a-enbiD4fQc_KPJ-dSoMI8t5allPhBfU.jpg" title="Llama.cpp now supports GLM 4.5 Air" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/pull/14939"&gt;https://github.com/ggml-org/llama.cpp/pull/14939&lt;/a&gt;&lt;/p&gt; &lt;p&gt;from our hero sammcj&lt;/p&gt; &lt;p&gt;Pictured, Cuda v1.45 engine in LM Studio. (the cuda 12 1.44 runtime still not working--the GLM 4.5 PR was merged in the past 8 hours or so).&lt;/p&gt; &lt;p&gt;As an aside, my initial vibe is it is far too wordy and overthinks, though, and gpt oss 120b is better and also faster in pure t/s but that's very much early vibe so take with a heavy dose of salt.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Freonr2"&gt; /u/Freonr2 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1mk26rk"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk26rk/llamacpp_now_supports_glm_45_air/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk26rk/llamacpp_now_supports_glm_45_air/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T14:52:12+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjxx6j</id>
    <title>GPT-OSS is Another Example Why Companies Must Build a Strong Brand Name</title>
    <updated>2025-08-07T11:49:08+00:00</updated>
    <author>
      <name>/u/Iory1998</name>
      <uri>https://old.reddit.com/user/Iory1998</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Please, for the love of God, convince me that GPT-OSS is the best open-source model that exists today. I dare you to convince me. There's no way the GPT-OSS 120B is better than Qwen-235B-A22B-2507, let alone DeepSeek R1. So why do 90% of YouTubers, and even Two Minute Papers (a guy I respect), praise GPT-OSS as the most beautiful gift to humanity any company ever gave? &lt;/p&gt; &lt;p&gt;It's not even multimodal, and they're calling it a gift? WTF for? Isn't that the same coriticim when Deepseek-R1 was released, that it was text-based only? In about 2 weeks, Alibaba released a video model (Wan2.2) , an image model (Qwen-Image) that are the best open-source models in their categories, two amazing 30B models that are super fast and punch above their weight, and two incredible 4B models – yet barely any YouTubers covered them. Meanwhile, OpenAI launches a rather OK model and hell broke loose everywhere. How do you explain this? I can't find any rational explanation except OpenAI built a powerful brand name.&lt;/p&gt; &lt;p&gt;When DeepSeek-R1 was released, real innovation became public – innovation GPT-OSS clearly built upon. How can a model have 120 Experts all stable without DeepSeek's paper? And to make matters worse, OpenAI dared to show their 20B model trained for under $500K! As if that's an achievement when DeepSeek R1 cost just $5.58 million – 89x cheaper than OpenAI's rumored budgets. &lt;/p&gt; &lt;p&gt;Remember when every outlet (especially American ones) criticized DeepSeek: 'Look, the model is censored by the Communist Party. Do you want to live in a world of censorship?' Well, ask GPT-OSS about the Ukraine war and see if it answers you. The hypocrisy is rich. User &lt;a href="/u/Final_Wheel_7486"&gt;u/Final_Wheel_7486&lt;/a&gt; posted about this.&lt;/p&gt; &lt;p&gt;I'm not a coder or mathematician, and even if I were, these models wouldn't help much – they're too limited. So I DON'T CARE ABOUT CODING SCORES ON BENCHMARKS. Don't tell me 'these models are very good at coding' as if a 20B model can actually code. Coders are a niche group. We need models that help average people.&lt;/p&gt; &lt;p&gt;This whole situation reminds me of that greedy guy who rarely gives to charity, then gets praised for doing the bare minimum when he finally does.&lt;/p&gt; &lt;p&gt;I am notsaying the models OpenAI released are bad, they simply aren't. But, what I am saying is that the hype is through the roof for an OK product. I want to hear your thoughts. &lt;/p&gt; &lt;p&gt;P.S. OpenAI fanboys, please keep it objective and civil!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Iory1998"&gt; /u/Iory1998 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjxx6j/gptoss_is_another_example_why_companies_must/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjxx6j/gptoss_is_another_example_why_companies_must/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjxx6j/gptoss_is_another_example_why_companies_must/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T11:49:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1mkavhy</id>
    <title>random bar chart made by Qwen3-235B-A22B-2507</title>
    <updated>2025-08-07T20:19:55+00:00</updated>
    <author>
      <name>/u/tengo_harambe</name>
      <uri>https://old.reddit.com/user/tengo_harambe</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mkavhy/random_bar_chart_made_by_qwen3235ba22b2507/"&gt; &lt;img alt="random bar chart made by Qwen3-235B-A22B-2507" src="https://preview.redd.it/rka3lhpnonhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=dd853635222d78299767b459957da8a9ae9f30b5" title="random bar chart made by Qwen3-235B-A22B-2507" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;had it render the chart on HTML canvas&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/tengo_harambe"&gt; /u/tengo_harambe &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/rka3lhpnonhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mkavhy/random_bar_chart_made_by_qwen3235ba22b2507/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mkavhy/random_bar_chart_made_by_qwen3235ba22b2507/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T20:19:55+00:00</published>
  </entry>
  <entry>
    <id>t3_1mk5ti0</id>
    <title>Hilarious chart from GPT-5 Reveal</title>
    <updated>2025-08-07T17:08:57+00:00</updated>
    <author>
      <name>/u/lyceras</name>
      <uri>https://old.reddit.com/user/lyceras</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk5ti0/hilarious_chart_from_gpt5_reveal/"&gt; &lt;img alt="Hilarious chart from GPT-5 Reveal" src="https://preview.redd.it/ewx61i9gqmhf1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ce6f821baade0cb741dbab09472eb1f7eb1d04a5" title="Hilarious chart from GPT-5 Reveal" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/lyceras"&gt; /u/lyceras &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/ewx61i9gqmhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mk5ti0/hilarious_chart_from_gpt5_reveal/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mk5ti0/hilarious_chart_from_gpt5_reveal/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-07T17:08:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1mjf5ol</id>
    <title>r/LocalLlama is looking for moderators</title>
    <updated>2025-08-06T20:06:34+00:00</updated>
    <author>
      <name>/u/HOLUPREDICTIONS</name>
      <uri>https://old.reddit.com/user/HOLUPREDICTIONS</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/HOLUPREDICTIONS"&gt; /u/HOLUPREDICTIONS &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/r/LocalLLaMA/application/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mjf5ol/rlocalllama_is_looking_for_moderators/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mjf5ol/rlocalllama_is_looking_for_moderators/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T20:06:34+00:00</published>
  </entry>
</feed>
