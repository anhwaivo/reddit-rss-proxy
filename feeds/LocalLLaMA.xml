<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-02-24T22:48:54+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1ixavpv</id>
    <title>Anyone using RAG with Query-Aware Chunking?</title>
    <updated>2025-02-24T19:41:01+00:00</updated>
    <author>
      <name>/u/Timely-Jackfruit8885</name>
      <uri>https://old.reddit.com/user/Timely-Jackfruit8885</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I’m the developer of d.ai, a mobile app that lets you chat offline with LLMs while keeping everything private and free. I’m currently working on adding long-term memory using Retrieval-Augmented Generation (RAG), and I’m exploring query-aware chunking to improve the relevance of the results.&lt;/p&gt; &lt;p&gt;For those unfamiliar, query-aware chunking is a technique where the text is split into chunks dynamically based on the context of the user’s query, instead of fixed-size chunks. The idea is to retrieve information that’s more relevant to the actual question being asked.&lt;/p&gt; &lt;p&gt;Has anyone here implemented something similar or worked with this approach?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Timely-Jackfruit8885"&gt; /u/Timely-Jackfruit8885 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixavpv/anyone_using_rag_with_queryaware_chunking/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixavpv/anyone_using_rag_with_queryaware_chunking/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixavpv/anyone_using_rag_with_queryaware_chunking/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T19:41:01+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix46wr</id>
    <title>R1 for Spatial Reasoning</title>
    <updated>2025-02-24T15:08:13+00:00</updated>
    <author>
      <name>/u/remyxai</name>
      <uri>https://old.reddit.com/user/remyxai</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix46wr/r1_for_spatial_reasoning/"&gt; &lt;img alt="R1 for Spatial Reasoning" src="https://b.thumbs.redditmedia.com/jyqIGUOvKtGUJMPde7zV_1b5qWCF6lHqv8cfpN-Wi_Q.jpg" title="R1 for Spatial Reasoning" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Sharing an experiment in data synthesis for R1-style reasoning in my VLM, fine-tuned for enhanced spatial reasoning, more in &lt;a href="https://huggingface.co/spaces/open-r1/README/discussions/10"&gt;this discussion&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;After finding &lt;a href="https://spatial-vlm.github.io/"&gt;SpatialVLM&lt;/a&gt; last year, we open-sourced a similar 3D scene reconstruction pipeline: &lt;a href="https://github.com/remyxai/VQASynth"&gt;VQASynth&lt;/a&gt; to generate instruction following data for spatial reasoning.&lt;/p&gt; &lt;p&gt;Inspired by &lt;a href="https://typefly.github.io/"&gt;TypeFly&lt;/a&gt;, we tried applying &lt;a href="https://x.com/smellslikeml/status/1790069289413914956"&gt;this idea to VLMs&lt;/a&gt;, but it wasn't robust enough to fly our drone.&lt;/p&gt; &lt;p&gt;With R1-style reasoning, can't we ground our response on a set of observations from the VQASynth pipeline to train a VLM for better scene understanding and planning?&lt;/p&gt; &lt;p&gt;That's the goal for an upcoming VLM release &lt;a href="https://colab.research.google.com/drive/1R64daHgR50GnxH3yn7mcs8rnldWL1ZxF"&gt;based on this&lt;/a&gt; colab.&lt;/p&gt; &lt;p&gt;Would love to hear your thoughts on making a dataset and VLM which could power the next generation of more reliable embodied AI applications, join us on &lt;a href="https://github.com/remyxai/VQASynth/issues/36"&gt;github&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/rwcajdccv3le1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d924f00d5dd56b8bb5c6900799071783993fe1a4"&gt;https://preview.redd.it/rwcajdccv3le1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d924f00d5dd56b8bb5c6900799071783993fe1a4&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/gzs74o4dv3le1.png?width=754&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d20c61ca9f0cb8e8f3d97b21be473c6002abdc3a"&gt;https://preview.redd.it/gzs74o4dv3le1.png?width=754&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d20c61ca9f0cb8e8f3d97b21be473c6002abdc3a&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/remyxai"&gt; /u/remyxai &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix46wr/r1_for_spatial_reasoning/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix46wr/r1_for_spatial_reasoning/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix46wr/r1_for_spatial_reasoning/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T15:08:13+00:00</published>
  </entry>
  <entry>
    <id>t3_1iwhfl5</id>
    <title>96GB modded RTX 4090 for $4.5k</title>
    <updated>2025-02-23T18:55:09+00:00</updated>
    <author>
      <name>/u/Charuru</name>
      <uri>https://old.reddit.com/user/Charuru</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwhfl5/96gb_modded_rtx_4090_for_45k/"&gt; &lt;img alt="96GB modded RTX 4090 for $4.5k" src="https://preview.redd.it/5rf8m3k1rxke1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0d35cdb0e62ea887c4da38324fff2ccbbf226f9f" title="96GB modded RTX 4090 for $4.5k" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Charuru"&gt; /u/Charuru &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/5rf8m3k1rxke1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwhfl5/96gb_modded_rtx_4090_for_45k/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1iwhfl5/96gb_modded_rtx_4090_for_45k/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-23T18:55:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix11go</id>
    <title>aspen - Open-source voice assistant you can call, at only $0.01025/min!</title>
    <updated>2025-02-24T12:37:28+00:00</updated>
    <author>
      <name>/u/thooton</name>
      <uri>https://old.reddit.com/user/thooton</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix11go/aspen_opensource_voice_assistant_you_can_call_at/"&gt; &lt;img alt="aspen - Open-source voice assistant you can call, at only $0.01025/min!" src="https://external-preview.redd.it/Y8cU497M8VmMsSvykiiACmZpJ9cu5NkYzryYit_2lHY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8b00ce71267ae00f4c36a6263a4dd0cc5d7b9aee" title="aspen - Open-source voice assistant you can call, at only $0.01025/min!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://reddit.com/link/1ix11go/video/ohkvv8g9z2le1/player"&gt;https://reddit.com/link/1ix11go/video/ohkvv8g9z2le1/player&lt;/a&gt;&lt;/p&gt; &lt;p&gt;hi everyone, hope you're all doing great :) I thought I'd share a little project that I've been working on for the past few days. It's a voice assistant that uses Twilio's API to be accessible through a real phone number, so you can call it just like a person!&lt;/p&gt; &lt;p&gt;Using Groq's STT free tier and Google's TTS free tier, the only costs come from Twilio and Anthropic and add up to about $0.01025/min, which is a lot cheaper than the conversational agents from ElevenLabs or PlayAI which approach $0.10/min or $0.18/min respectively.&lt;/p&gt; &lt;p&gt;I wrote the code to be as modular as possible so it should be easy to modify it to use your own local LLM or whatever you like! all PRs are welcome :)&lt;/p&gt; &lt;p&gt;have an awesome day!!!&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/thooton/aspen"&gt;https://github.com/thooton/aspen&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/thooton"&gt; /u/thooton &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix11go/aspen_opensource_voice_assistant_you_can_call_at/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix11go/aspen_opensource_voice_assistant_you_can_call_at/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix11go/aspen_opensource_voice_assistant_you_can_call_at/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T12:37:28+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixcaur</id>
    <title>New Deepseek integation repo</title>
    <updated>2025-02-24T20:37:59+00:00</updated>
    <author>
      <name>/u/lucitatecapacita</name>
      <uri>https://old.reddit.com/user/lucitatecapacita</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Looks like DeepSeek has released a repo with new integrations with several frameworks:&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/deepseek-ai/awesome-deepseek-integration"&gt;https://github.com/deepseek-ai/awesome-deepseek-integration&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/lucitatecapacita"&gt; /u/lucitatecapacita &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixcaur/new_deepseek_integation_repo/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixcaur/new_deepseek_integation_repo/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixcaur/new_deepseek_integation_repo/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T20:37:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixfbzd</id>
    <title>Sonnet-3.7 is best non-thinking model in the Misguided Attention eval.</title>
    <updated>2025-02-24T22:41:46+00:00</updated>
    <author>
      <name>/u/cpldcpu</name>
      <uri>https://old.reddit.com/user/cpldcpu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixfbzd/sonnet37_is_best_nonthinking_model_in_the/"&gt; &lt;img alt="Sonnet-3.7 is best non-thinking model in the Misguided Attention eval." src="https://external-preview.redd.it/3Xlrhru-DocPv1ONkF-Le04N8KrkOyM1Ydkeb2ft68s.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8afcf14938726714cc9d549d6ef3ea05fd4f2b3c" title="Sonnet-3.7 is best non-thinking model in the Misguided Attention eval." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/cpldcpu/MisguidedAttention"&gt;Misguided Attention&lt;/a&gt; is a collection of prompts to challenge the reasoning abilities of large language models in presence of misguiding information. It consists of slightly modified well known logical problems and riddles. Many model are overfit to these problems and will therefore report a response to the unmodified problem. &lt;/p&gt; &lt;p&gt;Claude-3.7-Sonnet was evaluated in the non-thinking mode in the long eval with 52 prompt. It almost beats o3-mini despite not using the thinking mode. This is a very impressive result. &lt;/p&gt; &lt;p&gt;I will benchmark the thinking mode once I have figured out how to activate it in the openrouter API...&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/sui6i1l4z5le1.png?width=2391&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d11d6a08386a45914660a0f576b2c4c58ae88d4"&gt;https://preview.redd.it/sui6i1l4z5le1.png?width=2391&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d11d6a08386a45914660a0f576b2c4c58ae88d4&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/e1p7r416z5le1.png?width=4170&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a2cd9467c077b18212e70943d731009ff62430a6"&gt;https://preview.redd.it/e1p7r416z5le1.png?width=4170&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a2cd9467c077b18212e70943d731009ff62430a6&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cpldcpu"&gt; /u/cpldcpu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixfbzd/sonnet37_is_best_nonthinking_model_in_the/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixfbzd/sonnet37_is_best_nonthinking_model_in_the/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixfbzd/sonnet37_is_best_nonthinking_model_in_the/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T22:41:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix5vgm</id>
    <title>TIP: Open WebUI "Overview" mode</title>
    <updated>2025-02-24T16:19:18+00:00</updated>
    <author>
      <name>/u/Everlier</name>
      <uri>https://old.reddit.com/user/Everlier</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix5vgm/tip_open_webui_overview_mode/"&gt; &lt;img alt="TIP: Open WebUI &amp;quot;Overview&amp;quot; mode" src="https://a.thumbs.redditmedia.com/xhTnipJlQp9kwvDNpjx8F2VXJDkn8RgN7RNScLB8_00.jpg" title="TIP: Open WebUI &amp;quot;Overview&amp;quot; mode" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;As Google added &lt;a href="https://nitter.net/OfficialLoganK/status/1894049802557456669"&gt;branching support&lt;/a&gt; for its AI Studio product, I think the crown in terms of implementation is still held by the Open WebUI.&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/nfdla1lq34le1.png?width=2492&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=70419e34b5c6474913c5d005bf6a5125561d8302"&gt;Overview mode&lt;/a&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;To activate: click &amp;quot;...&amp;quot; at the top right and select &amp;quot;Overview&amp;quot; in the menu&lt;/li&gt; &lt;li&gt;Clicking any leaf node in the graph will update the chat state accordingly&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Everlier"&gt; /u/Everlier &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix5vgm/tip_open_webui_overview_mode/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix5vgm/tip_open_webui_overview_mode/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix5vgm/tip_open_webui_overview_mode/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T16:19:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix6bjw</id>
    <title>Is there any image models coming out?</title>
    <updated>2025-02-24T16:37:38+00:00</updated>
    <author>
      <name>/u/hoja_nasredin</name>
      <uri>https://old.reddit.com/user/hoja_nasredin</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;We were extremely spoiled this summer with Flux and SD3.1 coming out. But was anything else have been released since? Flux cannot be trained in a serious way apparently since it is distilled, and SD3 is hated by the community (or it might have some other issues I'm not aware). &lt;/p&gt; &lt;p&gt;What is happening with the image models right now? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/hoja_nasredin"&gt; /u/hoja_nasredin &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix6bjw/is_there_any_image_models_coming_out/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix6bjw/is_there_any_image_models_coming_out/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix6bjw/is_there_any_image_models_coming_out/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T16:37:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1iwvo4b</id>
    <title>An Open-Source Implementation of Deep Research using Gemini Flash 2.0</title>
    <updated>2025-02-24T06:32:56+00:00</updated>
    <author>
      <name>/u/CarpetNo5579</name>
      <uri>https://old.reddit.com/user/CarpetNo5579</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I built an open source version of deep research using Gemini Flash 2.0!&lt;/p&gt; &lt;p&gt;Feed it any topic and it'll explore it thoroughly, building and displaying a research tree in real-time as it works. &lt;/p&gt; &lt;p&gt;This implementation has three research modes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Fast (1-3min): Quick surface research, perfect for initial exploration&lt;/li&gt; &lt;li&gt;Balanced (3-6min): Moderate depth, explores main concepts and relationships&lt;/li&gt; &lt;li&gt;Comprehensive (5-12min): Deep recursive research, builds query trees, explores counter-arguments&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The coolest part is watching it think - it prints out the research tree as it explores, so you can see exactly how it's approaching your topic.&lt;/p&gt; &lt;p&gt;I built this because I haven't seen any implementation that uses Gemini and its built in search tool and thought others might find it useful too.&lt;/p&gt; &lt;p&gt;Here's the github link: &lt;a href="https://github.com/eRuaro/open-gemini-deep-research"&gt;https://github.com/eRuaro/open-gemini-deep-research&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/CarpetNo5579"&gt; /u/CarpetNo5579 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwvo4b/an_opensource_implementation_of_deep_research/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwvo4b/an_opensource_implementation_of_deep_research/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1iwvo4b/an_opensource_implementation_of_deep_research/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T06:32:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix3gao</id>
    <title>nvidia / Evo 2 Protein Design</title>
    <updated>2025-02-24T14:35:47+00:00</updated>
    <author>
      <name>/u/iamnotdeadnuts</name>
      <uri>https://old.reddit.com/user/iamnotdeadnuts</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix3gao/nvidia_evo_2_protein_design/"&gt; &lt;img alt="nvidia / Evo 2 Protein Design" src="https://preview.redd.it/fp2o6r9ql3le1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=174a8acebfd2e90b81df658a8e8c6f3c7d031293" title="nvidia / Evo 2 Protein Design" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://build.nvidia.com/nvidia/evo2-protein-design/blueprintcard"&gt;https://build.nvidia.com/nvidia/evo2-protein-design/blueprintcard&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/iamnotdeadnuts"&gt; /u/iamnotdeadnuts &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/fp2o6r9ql3le1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix3gao/nvidia_evo_2_protein_design/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix3gao/nvidia_evo_2_protein_design/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T14:35:47+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix1ddj</id>
    <title>ragit 0.3.0 released</title>
    <updated>2025-02-24T12:55:49+00:00</updated>
    <author>
      <name>/u/baehyunsol</name>
      <uri>https://old.reddit.com/user/baehyunsol</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix1ddj/ragit_030_released/"&gt; &lt;img alt="ragit 0.3.0 released" src="https://external-preview.redd.it/TipJWadkvg51FCh2k5yn7L-J4VOuk7fkeumbFTDL_OM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=91ff6bfc615eb15181fb1437f1d20a7a4e5656c6" title="ragit 0.3.0 released" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I've been working on this open source RAG solution for a while.&lt;/p&gt; &lt;p&gt;It gives you a simple CLI for local rag, without any need for writing code!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/baehyunsol"&gt; /u/baehyunsol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/baehyunsol/ragit"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix1ddj/ragit_030_released/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix1ddj/ragit_030_released/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T12:55:49+00:00</published>
  </entry>
  <entry>
    <id>t3_1iwtl7f</id>
    <title>Most people are worried about LLM's executing code. Then theres me...... 😂</title>
    <updated>2025-02-24T04:24:24+00:00</updated>
    <author>
      <name>/u/DataScientist305</name>
      <uri>https://old.reddit.com/user/DataScientist305</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwtl7f/most_people_are_worried_about_llms_executing_code/"&gt; &lt;img alt="Most people are worried about LLM's executing code. Then theres me...... 😂" src="https://preview.redd.it/92abn3ekk0le1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=09547c1d04e4bb052014aac1d2d58fba8d76d0ee" title="Most people are worried about LLM's executing code. Then theres me...... 😂" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DataScientist305"&gt; /u/DataScientist305 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/92abn3ekk0le1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwtl7f/most_people_are_worried_about_llms_executing_code/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1iwtl7f/most_people_are_worried_about_llms_executing_code/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T04:24:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix5np0</id>
    <title>I built OLLAMA GUI in next.js how do you like it?</title>
    <updated>2025-02-24T16:10:21+00:00</updated>
    <author>
      <name>/u/Itsaliensbro453</name>
      <uri>https://old.reddit.com/user/Itsaliensbro453</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix5np0/i_built_ollama_gui_in_nextjs_how_do_you_like_it/"&gt; &lt;img alt="I built OLLAMA GUI in next.js how do you like it?" src="https://preview.redd.it/f0j99mmn24le1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=494ec50651dc68222e262f195d12282a270ea7e0" title="I built OLLAMA GUI in next.js how do you like it?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hellou guys im a developer trying to land my first job so im creating projects for my portfolio!&lt;/p&gt; &lt;p&gt;I have built this OLLAMA GUI with Next.js and Typescrypt!😀&lt;/p&gt; &lt;p&gt;How do you like it? Feel free to use the app and contribute its 100% free and open source! &lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/Ablasko32/Project-Shard---GUI-for-local-LLM-s"&gt;https://github.com/Ablasko32/Project-Shard---GUI-for-local-LLM-s&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Itsaliensbro453"&gt; /u/Itsaliensbro453 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/f0j99mmn24le1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix5np0/i_built_ollama_gui_in_nextjs_how_do_you_like_it/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix5np0/i_built_ollama_gui_in_nextjs_how_do_you_like_it/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T16:10:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix0d4z</id>
    <title>Polish Ministry of Digital Affairs shared PLLuM model family on HF</title>
    <updated>2025-02-24T11:57:56+00:00</updated>
    <author>
      <name>/u/fairydreaming</name>
      <uri>https://old.reddit.com/user/fairydreaming</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/fairydreaming"&gt; /u/fairydreaming &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/CYFRAGOVPL"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix0d4z/polish_ministry_of_digital_affairs_shared_pllum/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix0d4z/polish_ministry_of_digital_affairs_shared_pllum/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T11:57:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixd0er</id>
    <title>QwQ Max Preview Published</title>
    <updated>2025-02-24T21:06:52+00:00</updated>
    <author>
      <name>/u/ortegaalfredo</name>
      <uri>https://old.reddit.com/user/ortegaalfredo</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ortegaalfredo"&gt; /u/ortegaalfredo &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://qwenlm.github.io/blog/qwq-max-preview/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixd0er/qwq_max_preview_published/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixd0er/qwq_max_preview_published/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T21:06:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixe6yo</id>
    <title>Great announcement today. Heres how we already made it better months ago</title>
    <updated>2025-02-24T21:55:08+00:00</updated>
    <author>
      <name>/u/bmlattimer</name>
      <uri>https://old.reddit.com/user/bmlattimer</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixe6yo/great_announcement_today_heres_how_we_already/"&gt; &lt;img alt="Great announcement today. Heres how we already made it better months ago" src="https://external-preview.redd.it/grYs-3O6uZipD0Sj50ba5RJGLP9auRDlnYN5RIEw2ug.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=908d238bcf53c77c3b923be9dffa7d805c8338db" title="Great announcement today. Heres how we already made it better months ago" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;h1&gt;JOSH: Self-Improving LLMs for Tool Use Without Human Feedback&lt;/h1&gt; &lt;p&gt;Our team released a paper a few months ago introducing JOSH (Juxtaposed Outcomes for Simulation Harvesting), a self-alignment algorithm that enables LLMs to autonomously improve their tool-using capabilities without human feedback including notably on τ-bench. We also have introduced an agentic tool calling dataset ToolWOZ derived from MultiWOZ. &lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/rzfdhfkkq5le1.png?width=1906&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=35804ee77ec38267881cc116304f953b5f350341"&gt;JOSH uses methods similar to Test Time Scaling to generate training data&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;What JOSH does:&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Uses tool calls as sparse rewards in a simulation environment to extract ideal dialogue turns&lt;/li&gt; &lt;li&gt;Trains models on their own outputs through beam search exploration (reminiscent of test time scaling methods that are currently used)&lt;/li&gt; &lt;li&gt;Significantly improves tool-based interactions across model sizes (from smaller Llama models to frontier models like GPT-4o)&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Key results:&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;74% improvement in success rate for Llama3-8B on our ToolWOZ benchmark&lt;/li&gt; &lt;li&gt;State-of-the-art performance on τ-bench when applied to GPT-4o&lt;/li&gt; &lt;li&gt;Maintains general model capabilities on MT-Bench and LMSYS while specializing in tool use&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Why this matters:&lt;/h1&gt; &lt;p&gt;With today's Anthropic announcement showing improvements on τ-bench, it's worth noting how our approach can already be applied to improve its capabilities! JOSH offers a general approach that works across model sizes and doesn't require human feedback - potentially making it more scalable as models continue to improve.&lt;/p&gt; &lt;p&gt;We've made our code and the ToolWOZ dataset publicly available: &lt;a href="https://github.com/asappresearch/josh-llm-simulation-training"&gt;GitHub repo&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Paper: &lt;a href="https://arxiv.org/pdf/2409.04617"&gt;Sparse Rewards Can Self-Train Dialogue Agents&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Curious to hear the community's thoughts!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/bmlattimer"&gt; /u/bmlattimer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixe6yo/great_announcement_today_heres_how_we_already/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixe6yo/great_announcement_today_heres_how_we_already/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixe6yo/great_announcement_today_heres_how_we_already/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T21:55:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1iwvvmy</id>
    <title>Qwen is releasing something tonight!</title>
    <updated>2025-02-24T06:46:53+00:00</updated>
    <author>
      <name>/u/mlon_eusk-_-</name>
      <uri>https://old.reddit.com/user/mlon_eusk-_-</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwvvmy/qwen_is_releasing_something_tonight/"&gt; &lt;img alt="Qwen is releasing something tonight!" src="https://external-preview.redd.it/vArUV2h82u8EtPauQRu5bQrqvRa1QZ1C_bg0wPIoH5o.jpg?width=108&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=263b5e9873bf302385907f40a338f7412dc9b280" title="Qwen is releasing something tonight!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mlon_eusk-_-"&gt; /u/mlon_eusk-_- &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://twitter.com/Alibaba_Qwen/status/1893907569724281088"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwvvmy/qwen_is_releasing_something_tonight/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1iwvvmy/qwen_is_releasing_something_tonight/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T06:46:53+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixcygz</id>
    <title>Qwq max preview released</title>
    <updated>2025-02-24T21:04:42+00:00</updated>
    <author>
      <name>/u/MrMrsPotts</name>
      <uri>https://old.reddit.com/user/MrMrsPotts</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://x.com/Alibaba_Qwen/status/1894130603513319842"&gt;https://x.com/Alibaba_Qwen/status/1894130603513319842&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/MrMrsPotts"&gt; /u/MrMrsPotts &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixcygz/qwq_max_preview_released/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixcygz/qwq_max_preview_released/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixcygz/qwq_max_preview_released/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T21:04:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1iwqf3z</id>
    <title>FlashMLA - Day 1 of OpenSourceWeek</title>
    <updated>2025-02-24T01:37:17+00:00</updated>
    <author>
      <name>/u/AaronFeng47</name>
      <uri>https://old.reddit.com/user/AaronFeng47</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwqf3z/flashmla_day_1_of_opensourceweek/"&gt; &lt;img alt="FlashMLA - Day 1 of OpenSourceWeek" src="https://preview.redd.it/to631nzvqzke1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3551b21c98cfb01ba242529b337443a5c85b4481" title="FlashMLA - Day 1 of OpenSourceWeek" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/deepseek-ai/FlashMLA"&gt;https://github.com/deepseek-ai/FlashMLA&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AaronFeng47"&gt; /u/AaronFeng47 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/to631nzvqzke1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1iwqf3z/flashmla_day_1_of_opensourceweek/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1iwqf3z/flashmla_day_1_of_opensourceweek/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T01:37:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixckba</id>
    <title>Making older LLMs (Llama 2 and Gemma 1) reason</title>
    <updated>2025-02-24T20:48:42+00:00</updated>
    <author>
      <name>/u/Everlier</name>
      <uri>https://old.reddit.com/user/Everlier</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixckba/making_older_llms_llama_2_and_gemma_1_reason/"&gt; &lt;img alt="Making older LLMs (Llama 2 and Gemma 1) reason" src="https://external-preview.redd.it/Y21xb3pldThnNWxlMe68FKKrQSi1VIWXGB4I0FX2lDdJRybemxt5jwSyAisL.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2fc17b1b05cbeed10c64cb4b0ff38aed9587d31e" title="Making older LLMs (Llama 2 and Gemma 1) reason" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Everlier"&gt; /u/Everlier &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/frk5teu8g5le1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixckba/making_older_llms_llama_2_and_gemma_1_reason/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixckba/making_older_llms_llama_2_and_gemma_1_reason/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T20:48:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixefsf</id>
    <title>I created a new structured output method and it works really well</title>
    <updated>2025-02-24T22:04:49+00:00</updated>
    <author>
      <name>/u/jckwind11</name>
      <uri>https://old.reddit.com/user/jckwind11</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixefsf/i_created_a_new_structured_output_method_and_it/"&gt; &lt;img alt="I created a new structured output method and it works really well" src="https://preview.redd.it/i55e55gkt5le1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=88fc258672a6dae100b76e5c3df682bffb3f9b2a" title="I created a new structured output method and it works really well" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jckwind11"&gt; /u/jckwind11 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/i55e55gkt5le1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixefsf/i_created_a_new_structured_output_method_and_it/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixefsf/i_created_a_new_structured_output_method_and_it/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T22:04:49+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixamd9</id>
    <title>QwQ-Max-Preview soon</title>
    <updated>2025-02-24T19:30:38+00:00</updated>
    <author>
      <name>/u/pkmxtw</name>
      <uri>https://old.reddit.com/user/pkmxtw</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I found that they have been updating their website on another branch:&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/qwenlm.github.io/commit/5d009b319931d473211cb4225d726b322afbb734"&gt;https://github.com/QwenLM/qwenlm.github.io/commit/5d009b319931d473211cb4225d726b322afbb734&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt;: Apache 2.0 licensed QwQ-Max, Qwen2.5-Max, QwQ-32B and probably other smaller QwQ variants, and an app for qwen chat.&lt;/p&gt; &lt;hr /&gt; &lt;blockquote&gt; &lt;p&gt;We’re happy to unveil QwQ-Max-Preview , the latest advancement in the Qwen series, designed to push the boundaries of deep reasoning and versatile problem-solving. Built on the robust foundation of Qwen2.5-Max , this preview model excels in mathematics, coding, and general-domain tasks, while delivering outstanding performance in Agent-related workflows. As a sneak peek into our upcoming QwQ-Max release, this version offers a glimpse of its enhanced capabilities, with ongoing refinements and an official Apache 2.0-licensed open-source launch of QwQ-Max and Qwen2.5-Max planned soon. Stay tuned for a new era of intelligent reasoning.&lt;/p&gt; &lt;p&gt;As we prepare for the official open-source release of QwQ-Max under the Apache 2.0 License, our roadmap extends beyond sharing cutting-edge research. We are committed to democratizing access to advanced reasoning capabilities and fostering innovation across diverse applications. Here’s what’s next:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;APP Release&lt;/strong&gt; To bridge the gap between powerful AI and everyday users, we will launch a dedicated APP for Qwen Chat. This intuitive interface will enable seamless interaction with the model for tasks like problem-solving, code generation, and logical reasoning—no technical expertise required. The app will prioritize real-time responsiveness and integration with popular productivity tools, making advanced AI accessible to a global audience.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Open-Sourcing Smaller Reasoning Models&lt;/strong&gt; Recognizing the need for lightweight, resource-efficient solutions, we will release a series of smaller QwQ variants , such as QwQ-32B, for local device deployment. These models will retain robust reasoning capabilities while minimizing computational demands, allowing developers to integrate them into devices. Perfect for privacy-sensitive applications or low-latency workflows, they will empower creators to build custom AI solutions.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Community-Driven Innovation&lt;/strong&gt; By open-sourcing QwQ-Max, Qwen2.5-Max, and its smaller counterparts, we aim to spark collaboration among developers, researchers, and hobbyists. We invite the community to experiment, fine-tune, and extend these models for specialized use cases—from education tools to autonomous agents. Our goal is to cultivate an ecosystem where innovation thrives through shared knowledge and collective problem-solving.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Stay tuned as we roll out these initiatives, designed to empower users at every level and redefine the boundaries of what AI can achieve. Together, we’re building a future where intelligence is not just powerful, but universally accessible.&lt;/p&gt; &lt;/blockquote&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/pkmxtw"&gt; /u/pkmxtw &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixamd9/qwqmaxpreview_soon/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixamd9/qwqmaxpreview_soon/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixamd9/qwqmaxpreview_soon/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T19:30:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix98kq</id>
    <title>Claude 3.7 Sonnet and Claude Code</title>
    <updated>2025-02-24T18:34:27+00:00</updated>
    <author>
      <name>/u/cpldcpu</name>
      <uri>https://old.reddit.com/user/cpldcpu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix98kq/claude_37_sonnet_and_claude_code/"&gt; &lt;img alt="Claude 3.7 Sonnet and Claude Code" src="https://external-preview.redd.it/V8JG-mmrlkT02vKigktdXzK2PH-CSO-CrYueRmf_OX0.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8beabe2cc993eb0a304f0f44ee00c9b8eb681095" title="Claude 3.7 Sonnet and Claude Code" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cpldcpu"&gt; /u/cpldcpu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.anthropic.com/news/claude-3-7-sonnet"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix98kq/claude_37_sonnet_and_claude_code/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix98kq/claude_37_sonnet_and_claude_code/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T18:34:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1ixczae</id>
    <title>QwQ-Max Preview is here...</title>
    <updated>2025-02-24T21:05:36+00:00</updated>
    <author>
      <name>/u/mlon_eusk-_-</name>
      <uri>https://old.reddit.com/user/mlon_eusk-_-</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixczae/qwqmax_preview_is_here/"&gt; &lt;img alt="QwQ-Max Preview is here..." src="https://external-preview.redd.it/bQFl5DBj7QNi2--7cYMNDWqUV0PSTT-usX89HeDXsMM.jpg?width=108&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1084b413b6f8c22df7000f62d2cf3888172ab3eb" title="QwQ-Max Preview is here..." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mlon_eusk-_-"&gt; /u/mlon_eusk-_- &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://twitter.com/Alibaba_Qwen/status/1894130603513319842"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ixczae/qwqmax_preview_is_here/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ixczae/qwqmax_preview_is_here/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T21:05:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1ix96pq</id>
    <title>Claude 3.7 is real</title>
    <updated>2025-02-24T18:32:00+00:00</updated>
    <author>
      <name>/u/ApprehensiveAd3629</name>
      <uri>https://old.reddit.com/user/ApprehensiveAd3629</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix96pq/claude_37_is_real/"&gt; &lt;img alt="Claude 3.7 is real" src="https://preview.redd.it/2qkaymexr4le1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0bf2edcabf3c5b2063f0fb29bc1b4f7da023acfe" title="Claude 3.7 is real" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Its show time folks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ApprehensiveAd3629"&gt; /u/ApprehensiveAd3629 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/2qkaymexr4le1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ix96pq/claude_37_is_real/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ix96pq/claude_37_is_real/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-02-24T18:32:00+00:00</published>
  </entry>
</feed>
