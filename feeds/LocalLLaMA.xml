<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-04-29T04:07:35+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1k9v1bp</id>
    <title>Llama may release new reasoning model and other features with llama 4.1 models tomorrow</title>
    <updated>2025-04-28T13:04:05+00:00</updated>
    <author>
      <name>/u/Independent-Wind4462</name>
      <uri>https://old.reddit.com/user/Independent-Wind4462</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9v1bp/llama_may_release_new_reasoning_model_and_other/"&gt; &lt;img alt="Llama may release new reasoning model and other features with llama 4.1 models tomorrow" src="https://preview.redd.it/zua4wxjuqkxe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=741de5b0707aaa5ca42c5eef34cbff16051e3f77" title="Llama may release new reasoning model and other features with llama 4.1 models tomorrow" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Independent-Wind4462"&gt; /u/Independent-Wind4462 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/zua4wxjuqkxe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9v1bp/llama_may_release_new_reasoning_model_and_other/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1k9v1bp/llama_may_release_new_reasoning_model_and_other/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T13:04:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka7bv4</id>
    <title>Damn qwen cooked it</title>
    <updated>2025-04-28T21:36:46+00:00</updated>
    <author>
      <name>/u/Independent-Wind4462</name>
      <uri>https://old.reddit.com/user/Independent-Wind4462</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka7bv4/damn_qwen_cooked_it/"&gt; &lt;img alt="Damn qwen cooked it" src="https://preview.redd.it/rrw7nwdbanxe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1790672bb3ea1403e9a7b9ec02f3b843d3e618bc" title="Damn qwen cooked it" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Independent-Wind4462"&gt; /u/Independent-Wind4462 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/rrw7nwdbanxe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka7bv4/damn_qwen_cooked_it/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka7bv4/damn_qwen_cooked_it/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T21:36:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1k9scp3</id>
    <title>Qwen 3 will apparently have a 235B parameter model</title>
    <updated>2025-04-28T10:35:46+00:00</updated>
    <author>
      <name>/u/queendumbria</name>
      <uri>https://old.reddit.com/user/queendumbria</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9scp3/qwen_3_will_apparently_have_a_235b_parameter_model/"&gt; &lt;img alt="Qwen 3 will apparently have a 235B parameter model" src="https://preview.redd.it/0gfy4b2c0kxe1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=178174e5467f8f4871102fb3de060ecfd2097ac4" title="Qwen 3 will apparently have a 235B parameter model" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/queendumbria"&gt; /u/queendumbria &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/0gfy4b2c0kxe1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9scp3/qwen_3_will_apparently_have_a_235b_parameter_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1k9scp3/qwen_3_will_apparently_have_a_235b_parameter_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T10:35:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1kacch6</id>
    <title>Unsloth is uploading 128K context Qwen3 GGUFs</title>
    <updated>2025-04-29T01:35:12+00:00</updated>
    <author>
      <name>/u/AaronFeng47</name>
      <uri>https://old.reddit.com/user/AaronFeng47</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kacch6/unsloth_is_uploading_128k_context_qwen3_ggufs/"&gt; &lt;img alt="Unsloth is uploading 128K context Qwen3 GGUFs" src="https://external-preview.redd.it/BOaSYNg6lhlngBhuDS68WpIBibLf88Q_KzjZVrFpgEc.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7b47505d7a8ebd834ca805c293d16277b5772c12" title="Unsloth is uploading 128K context Qwen3 GGUFs" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://huggingface.co/models?search=unsloth%20qwen3%20128k"&gt;https://huggingface.co/models?search=unsloth%20qwen3%20128k&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/36gv4a9lgoxe1.png?width=631&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d8a861695b959775b32aadc027ca0195d3e81c3"&gt;https://preview.redd.it/36gv4a9lgoxe1.png?width=631&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d8a861695b959775b32aadc027ca0195d3e81c3&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/p937wanlgoxe1.png?width=386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=201e7d0a664a2db75938da7482f14e025d2519b6"&gt;https://preview.redd.it/p937wanlgoxe1.png?width=386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=201e7d0a664a2db75938da7482f14e025d2519b6&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Plus their &lt;a href="https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF"&gt;Qwen3-30B-A3B-GGUF&lt;/a&gt; might have some bugs:&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/s3dtp56ugoxe1.png?width=561&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a82fc690b5746f668b8b00fb4520004c710da7dd"&gt;https://preview.redd.it/s3dtp56ugoxe1.png?width=561&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a82fc690b5746f668b8b00fb4520004c710da7dd&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AaronFeng47"&gt; /u/AaronFeng47 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kacch6/unsloth_is_uploading_128k_context_qwen3_ggufs/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kacch6/unsloth_is_uploading_128k_context_qwen3_ggufs/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1kacch6/unsloth_is_uploading_128k_context_qwen3_ggufs/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-29T01:35:12+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka8ban</id>
    <title>Qwen 3: unimpressive coding performance so far</title>
    <updated>2025-04-28T22:19:57+00:00</updated>
    <author>
      <name>/u/ps5cfw</name>
      <uri>https://old.reddit.com/user/ps5cfw</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Jumping ahead of the classic &amp;quot;OMG QWEN 3 IS THE LITERAL BEST IN EVERYTHING&amp;quot; and providing a small feedback on it's coding characteristics.&lt;/p&gt; &lt;p&gt;TECHNOLOGIES USED:&lt;/p&gt; &lt;p&gt;.NET 9&lt;br /&gt; Typescript&lt;br /&gt; React 18&lt;br /&gt; Material UI.&lt;/p&gt; &lt;p&gt;MODEL USED:&lt;br /&gt; Qwen3-235B-A22B (From Qwen AI chat) &lt;strong&gt;EDIT&lt;/strong&gt;: WITH MAX THINKING ENABLED&lt;/p&gt; &lt;p&gt;PROMPTS (Void of code because it's a private project):&lt;/p&gt; &lt;p&gt;- &amp;quot;My current code shows for a split second that [RELEVANT_DATA] is missing, only to then display [RELEVANT_DATA]properly. I do not want that split second missing warning to happen.&amp;quot;&lt;/p&gt; &lt;p&gt;RESULT: Fairly insignificant code change suggestions that did not fix the problem, when prompted that the solution was not successful and the rendering issue persisted, it repeated the same code again.&lt;/p&gt; &lt;p&gt;- &amp;quot;Please split $FAIRLY_BIG_DOTNET_CLASS (Around 3K lines of code) into smaller classes to enhance readability and maintainability&amp;quot;&lt;/p&gt; &lt;p&gt;RESULT: Code was &lt;em&gt;mostly&lt;/em&gt; correct, but it really hallucinated some stuff and threw away some other without a specific reason.&lt;/p&gt; &lt;p&gt;So yeah, this is a very hot opinion about Qwen 3&lt;/p&gt; &lt;p&gt;&lt;strong&gt;THE PROS&lt;/strong&gt;&lt;br /&gt; Follows instruction, doesn't spit out ungodly amount of code like Gemini Pro 2.5 does, fairly fast (at least on chat I guess)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;THE CONS&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Not so amazing coding performance, I'm sure a coder variant will fare much better though&lt;br /&gt; Knowledge cutoff is around early to mid 2024, has the same issues that other Qwen models have with never library versions with breaking changes (Example: Material UI v6 and the new Grid sizing system)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ps5cfw"&gt; /u/ps5cfw &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8ban/qwen_3_unimpressive_coding_performance_so_far/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8ban/qwen_3_unimpressive_coding_performance_so_far/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8ban/qwen_3_unimpressive_coding_performance_so_far/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T22:19:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1kaclyw</id>
    <title>Run Qwen3 (0.6B) 100% locally in your browser on WebGPU w/ Transformers.js</title>
    <updated>2025-04-29T01:48:54+00:00</updated>
    <author>
      <name>/u/xenovatech</name>
      <uri>https://old.reddit.com/user/xenovatech</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kaclyw/run_qwen3_06b_100_locally_in_your_browser_on/"&gt; &lt;img alt="Run Qwen3 (0.6B) 100% locally in your browser on WebGPU w/ Transformers.js" src="https://external-preview.redd.it/a3VnbHRmd3hpb3hlMbRgvsKi_IaAGC-viwKm_brdcymj4zDazyH2qxIAGtXM.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3a7c2bf26cc4be6e14165ab5a6b04d2793f880d1" title="Run Qwen3 (0.6B) 100% locally in your browser on WebGPU w/ Transformers.js" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/xenovatech"&gt; /u/xenovatech &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/wuflehwxioxe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kaclyw/run_qwen3_06b_100_locally_in_your_browser_on/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1kaclyw/run_qwen3_06b_100_locally_in_your_browser_on/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-29T01:48:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka8omw</id>
    <title>Why is a &lt;9 GB file on my pc able to do this? Qwen 3 14B Q4_K_S one shot prompt: "give me a snake html game, fully working"</title>
    <updated>2025-04-28T22:36:27+00:00</updated>
    <author>
      <name>/u/sebastianmicu24</name>
      <uri>https://old.reddit.com/user/sebastianmicu24</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8omw/why_is_a_9_gb_file_on_my_pc_able_to_do_this_qwen/"&gt; &lt;img alt="Why is a &amp;lt;9 GB file on my pc able to do this? Qwen 3 14B Q4_K_S one shot prompt: &amp;quot;give me a snake html game, fully working&amp;quot;" src="https://external-preview.redd.it/NDJxdDh6aGprbnhlMYpX_8uwwmYorZvO9YWXhNvaB0JdvRfyxdOqaIayhC1C.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d84cc56f8d97cc4e7ebb9479d0a6e82c0a687e7e" title="Why is a &amp;lt;9 GB file on my pc able to do this? Qwen 3 14B Q4_K_S one shot prompt: &amp;quot;give me a snake html game, fully working&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sebastianmicu24"&gt; /u/sebastianmicu24 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/fvl50yhjknxe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8omw/why_is_a_9_gb_file_on_my_pc_able_to_do_this_qwen/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8omw/why_is_a_9_gb_file_on_my_pc_able_to_do_this_qwen/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T22:36:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka6b02</id>
    <title>Qwen 3 4B is on par with Qwen 2.5 72B instruct</title>
    <updated>2025-04-28T20:53:42+00:00</updated>
    <author>
      <name>/u/numinouslymusing</name>
      <uri>https://old.reddit.com/user/numinouslymusing</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6b02/qwen_3_4b_is_on_par_with_qwen_25_72b_instruct/"&gt; &lt;img alt="Qwen 3 4B is on par with Qwen 2.5 72B instruct" src="https://b.thumbs.redditmedia.com/4xhH3IpbdVJQR6tSVD0P2PMt2f9WrE2bJMnfwmfvJUA.jpg" title="Qwen 3 4B is on par with Qwen 2.5 72B instruct" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/hjcy793l2nxe1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e10a9c0e2e022cba6582547efb31a27017a76b17"&gt;Source: https://qwenlm.github.io/blog/qwen3/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This is insane if true. Excited to test it out.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/numinouslymusing"&gt; /u/numinouslymusing &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6b02/qwen_3_4b_is_on_par_with_qwen_25_72b_instruct/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6b02/qwen_3_4b_is_on_par_with_qwen_25_72b_instruct/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6b02/qwen_3_4b_is_on_par_with_qwen_25_72b_instruct/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T20:53:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka9cp2</id>
    <title>Qwen3-30B-A3B runs at 130 tokens-per-second prompt processing and 60 tokens-per-second generation speed on M1 Max</title>
    <updated>2025-04-28T23:07:27+00:00</updated>
    <author>
      <name>/u/mark-lord</name>
      <uri>https://old.reddit.com/user/mark-lord</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://reddit.com/link/1ka9cp2/video/ra5xmwg5pnxe1/player"&gt;https://reddit.com/link/1ka9cp2/video/ra5xmwg5pnxe1/player&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This thing freaking &lt;em&gt;rips&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mark-lord"&gt; /u/mark-lord &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka9cp2/qwen330ba3b_runs_at_130_tokenspersecond_prompt/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka9cp2/qwen330ba3b_runs_at_130_tokenspersecond_prompt/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka9cp2/qwen330ba3b_runs_at_130_tokenspersecond_prompt/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T23:07:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka638t</id>
    <title>Qwen3: Think Deeper, Act Faster</title>
    <updated>2025-04-28T20:44:41+00:00</updated>
    <author>
      <name>/u/a_slay_nub</name>
      <uri>https://old.reddit.com/user/a_slay_nub</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/a_slay_nub"&gt; /u/a_slay_nub &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka638t/qwen3_think_deeper_act_faster/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka638t/qwen3_think_deeper_act_faster/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T20:44:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka6r7a</id>
    <title>Qwen3 - a unsloth Collection</title>
    <updated>2025-04-28T21:12:32+00:00</updated>
    <author>
      <name>/u/FullstackSensei</name>
      <uri>https://old.reddit.com/user/FullstackSensei</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6r7a/qwen3_a_unsloth_collection/"&gt; &lt;img alt="Qwen3 - a unsloth Collection" src="https://external-preview.redd.it/3P4HwI5x2HyPU9Mu2Vb_-7vgmEa7LlQZpRYlpMm54cw.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2b478b284df11d21c9e69bb850d00bf3cf95d9d4" title="Qwen3 - a unsloth Collection" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Unsloth GGUFs for Qwen 3 models are up!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/FullstackSensei"&gt; /u/FullstackSensei &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/collections/unsloth/qwen3-680edabfb790c8c34a242f95"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6r7a/qwen3_a_unsloth_collection/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6r7a/qwen3_a_unsloth_collection/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T21:12:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1kabje8</id>
    <title>VULKAN is faster tan CUDA currently with LLAMACPP! 62.2 T/S vs 77.5 t/s</title>
    <updated>2025-04-29T00:53:40+00:00</updated>
    <author>
      <name>/u/Healthy-Nebula-3603</name>
      <uri>https://old.reddit.com/user/Healthy-Nebula-3603</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kabje8/vulkan_is_faster_tan_cuda_currently_with_llamacpp/"&gt; &lt;img alt="VULKAN is faster tan CUDA currently with LLAMACPP! 62.2 T/S vs 77.5 t/s" src="https://b.thumbs.redditmedia.com/YSFSJJW5nUik24Hs1Ku14s40WKPTveZbDPy36-Nx8dg.jpg" title="VULKAN is faster tan CUDA currently with LLAMACPP! 62.2 T/S vs 77.5 t/s" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/e6czeihv8oxe1.png?width=1667&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=314e72291b8b6af832651693a05247ee94d5bf52"&gt;https://preview.redd.it/e6czeihv8oxe1.png?width=1667&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=314e72291b8b6af832651693a05247ee94d5bf52&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/3wkmekhv8oxe1.png?width=1724&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e8398a6816eab3dff55461cd2953579971c7e72f"&gt;https://preview.redd.it/3wkmekhv8oxe1.png?width=1724&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e8398a6816eab3dff55461cd2953579971c7e72f&lt;/a&gt;&lt;/p&gt; &lt;p&gt;RTX 3090&lt;/p&gt; &lt;p&gt;I used qwen 3 30b-a3b - q4km&lt;/p&gt; &lt;p&gt;And vulkan even takes less VRAM than cuda.&lt;/p&gt; &lt;p&gt;VULKAN 19.3 GB VRAM&lt;/p&gt; &lt;p&gt;CUDA 12 - 19.9 GB VRAM&lt;/p&gt; &lt;p&gt;So ... I think is time for me to migrate to VULKAN finally ;) ... &lt;/p&gt; &lt;p&gt;CUDA redundant ..still cannot believe ... &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Healthy-Nebula-3603"&gt; /u/Healthy-Nebula-3603 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kabje8/vulkan_is_faster_tan_cuda_currently_with_llamacpp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kabje8/vulkan_is_faster_tan_cuda_currently_with_llamacpp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1kabje8/vulkan_is_faster_tan_cuda_currently_with_llamacpp/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-29T00:53:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka8n18</id>
    <title>Qwen3-30B-A3B is magic.</title>
    <updated>2025-04-28T22:34:23+00:00</updated>
    <author>
      <name>/u/thebadslime</name>
      <uri>https://old.reddit.com/user/thebadslime</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I don't believe a model this good runs at 20 tps on my 4gb gpu (rx 6550m).&lt;/p&gt; &lt;p&gt;Running it through paces, seems like the benches were right on.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/thebadslime"&gt; /u/thebadslime &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8n18/qwen330ba3b_is_magic/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8n18/qwen330ba3b_is_magic/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8n18/qwen330ba3b_is_magic/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T22:34:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1k9zhrl</id>
    <title>QWEN 3 0.6 B is a REASONING MODEL</title>
    <updated>2025-04-28T16:14:45+00:00</updated>
    <author>
      <name>/u/josho2001</name>
      <uri>https://old.reddit.com/user/josho2001</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9zhrl/qwen_3_06_b_is_a_reasoning_model/"&gt; &lt;img alt="QWEN 3 0.6 B is a REASONING MODEL" src="https://a.thumbs.redditmedia.com/lgrYndp_STfrw7_XSBqXvRpGeE_wZkXrogcxEEdBbK8.jpg" title="QWEN 3 0.6 B is a REASONING MODEL" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/mawjeakqolxe1.png?width=861&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db1d64f37495b2897199f1fa729ae25a6722a16f"&gt;https://preview.redd.it/mawjeakqolxe1.png?width=861&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db1d64f37495b2897199f1fa729ae25a6722a16f&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Reasoning in comments, will test more prompts&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/josho2001"&gt; /u/josho2001 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9zhrl/qwen_3_06_b_is_a_reasoning_model/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9zhrl/qwen_3_06_b_is_a_reasoning_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1k9zhrl/qwen_3_06_b_is_a_reasoning_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T16:14:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1k9ufo8</id>
    <title>It's happening!</title>
    <updated>2025-04-28T12:34:18+00:00</updated>
    <author>
      <name>/u/DuckyBlender</name>
      <uri>https://old.reddit.com/user/DuckyBlender</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9ufo8/its_happening/"&gt; &lt;img alt="It's happening!" src="https://preview.redd.it/mwisik2ilkxe1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=96b6980f6a7b054ad8f1c1812253f2a6b82d5456" title="It's happening!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://huggingface.co/organizations/Qwen/activity/all"&gt;https://huggingface.co/organizations/Qwen/activity/all&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DuckyBlender"&gt; /u/DuckyBlender &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/mwisik2ilkxe1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9ufo8/its_happening/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1k9ufo8/its_happening/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T12:34:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka9ltx</id>
    <title>Qwen did it!</title>
    <updated>2025-04-28T23:19:19+00:00</updated>
    <author>
      <name>/u/josho2001</name>
      <uri>https://old.reddit.com/user/josho2001</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka9ltx/qwen_did_it/"&gt; &lt;img alt="Qwen did it!" src="https://b.thumbs.redditmedia.com/u6u6-206cP6GQfMdPkcYmLUDgdNtL8CfLg_DT718cyU.jpg" title="Qwen did it!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/wh2chz5crnxe1.png?width=808&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e7106c82745c39c5eedc28046f41fc84112717e"&gt;https://preview.redd.it/wh2chz5crnxe1.png?width=808&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e7106c82745c39c5eedc28046f41fc84112717e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Qwen did it! A 600 million parameter model, which is also arround 600mb, which is also a REASONING MODEL, running at 134tok/sec did it.&lt;br /&gt; this model family is spectacular, I can see that from here, qwen3 4B is similar to qwen2.5 7b + is a reasoning model and runs extremely fast alongide its 600 million parameter brother-with speculative decoding enabled.&lt;br /&gt; I can only imagine the things this will enable&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/josho2001"&gt; /u/josho2001 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka9ltx/qwen_did_it/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka9ltx/qwen_did_it/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka9ltx/qwen_did_it/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T23:19:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka10er</id>
    <title>Unsloth's Qwen 3 collection has 58 items. All still hidden.</title>
    <updated>2025-04-28T17:17:17+00:00</updated>
    <author>
      <name>/u/Cool-Chemical-5629</name>
      <uri>https://old.reddit.com/user/Cool-Chemical-5629</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka10er/unsloths_qwen_3_collection_has_58_items_all_still/"&gt; &lt;img alt="Unsloth's Qwen 3 collection has 58 items. All still hidden." src="https://preview.redd.it/pv8uhn7mzlxe1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=48744ff79b663fa07474da8e4cd0c02fb5714e23" title="Unsloth's Qwen 3 collection has 58 items. All still hidden." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I guess that this includes different repos for quants that will be available on day 1 once it's official?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cool-Chemical-5629"&gt; /u/Cool-Chemical-5629 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/pv8uhn7mzlxe1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka10er/unsloths_qwen_3_collection_has_58_items_all_still/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka10er/unsloths_qwen_3_collection_has_58_items_all_still/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T17:17:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka66y0</id>
    <title>Qwen3 Benchmark Results</title>
    <updated>2025-04-28T20:48:54+00:00</updated>
    <author>
      <name>/u/No_Weather8173</name>
      <uri>https://old.reddit.com/user/No_Weather8173</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka66y0/qwen3_benchmark_results/"&gt; &lt;img alt="Qwen3 Benchmark Results" src="https://a.thumbs.redditmedia.com/RNfuYLlWGg4mOGT-WkPEAFh63OvGImwEoaRKtCiVli8.jpg" title="Qwen3 Benchmark Results" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/No_Weather8173"&gt; /u/No_Weather8173 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1ka66y0"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka66y0/qwen3_benchmark_results/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka66y0/qwen3_benchmark_results/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T20:48:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1k9qxbl</id>
    <title>Qwen3 Published 30 seconds ago (Model Weights Available)</title>
    <updated>2025-04-28T08:54:39+00:00</updated>
    <author>
      <name>/u/random-tomato</name>
      <uri>https://old.reddit.com/user/random-tomato</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/"&gt; &lt;img alt="Qwen3 Published 30 seconds ago (Model Weights Available)" src="https://preview.redd.it/472i9pxaijxe1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7159a0fbacf3b156659f562487286b785c7f6484" title="Qwen3 Published 30 seconds ago (Model Weights Available)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://modelscope.cn/organization/Qwen"&gt;https://modelscope.cn/organization/Qwen&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/random-tomato"&gt; /u/random-tomato &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/472i9pxaijxe1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T08:54:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1kaa8iz</id>
    <title>This is 600M parameters??? Yesterday I would have told you this was impossible.</title>
    <updated>2025-04-28T23:49:16+00:00</updated>
    <author>
      <name>/u/JohnnyLiverman</name>
      <uri>https://old.reddit.com/user/JohnnyLiverman</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Prompt: &amp;quot;If 5 brog 5 is 1, and 4 brog 2 is 2, what is 3 brog 1?&amp;quot;&lt;/p&gt; &lt;p&gt;thinking content: &amp;lt;think&amp;gt;&lt;/p&gt; &lt;p&gt;Okay, let's see. The problem says that if 5 brog 5 is 1, and 4 brog 2 is 2, then what is 3 brog 1? Hmm, so I need to figure out a pattern or a relationship between the numbers here. Let me start by breaking down the given information.&lt;/p&gt; &lt;p&gt;First, let's parse the question. It mentions &amp;quot;brog&amp;quot; which I assume is a typo or a term that needs to be clarified. Maybe it's supposed to be &amp;quot;bro&amp;quot; or &amp;quot;brog&amp;quot; as in &amp;quot;bro&amp;quot; with a different meaning? Wait, maybe it's a play on words? Like, maybe &amp;quot;brog&amp;quot; stands for something related to numbers or operations. Alternatively, maybe it's a misprint for &amp;quot;bro&amp;quot; which could mean &amp;quot;brog&amp;quot; as in &amp;quot;brog&amp;quot; as in &amp;quot;brog&amp;quot; which is a term used in some contexts, but I'm not sure. Let me think.&lt;/p&gt; &lt;p&gt;Alternatively, perhaps &amp;quot;brog&amp;quot; is a shorthand for multiplication or some other operation. Let me check the examples again. If 5 brog 5 is 1, and 4 brog 2 is 2, then maybe each operation involves multiplying the two numbers? Let me test that. For example, 5 times 5 is 25, which would be 25, but the result given is 1. So that doesn't fit. Alternatively, maybe it's a different operation. Let me think.&lt;/p&gt; &lt;p&gt;Alternatively, maybe it's a combination of numbers. For instance, maybe it's a function f(n, m) where f(n, m) is defined as something. Let's try to think of possible functions. For example, maybe f(n, m) = something like n/m or n + m? Let's check:&lt;/p&gt; &lt;p&gt;If 5 brog 5 is 1, then maybe f(5, 5) = 1. If 4 brog 2 is 2, then f(4, 2) = 2. Let's see if there's a pattern. If we think of 5 brog 5 as 1, which is 5/5 = 1. Then 4 brog 2 is 2, which would be 4/2 = 2. That seems to fit! So maybe the function is f(n, m) = n/m. Then 3 brog 1 would be 3/1 = 3. Therefore, the answer should be 3. But let me check again to make sure there's no other possible interpretation.&lt;/p&gt; &lt;p&gt;Alternatively, maybe there's another operation. For example, maybe it's a combination like n + m, but 5 + 5 is 10, which doesn't match. Or maybe n multiplied by m, but 5*5 is 25, which doesn't match. Or maybe n divided by m, which would be 1 for the first case and 2 for the second. So that seems consistent. Therefore, if 5 brog 5 is 1, then 3 brog 1 is 3. Therefore, the answer is 3. But let me check if there's another possibility.&lt;/p&gt; &lt;p&gt;Wait, another thought: maybe &amp;quot;brog&amp;quot; is a term related to numbers in a different way. For example, maybe it's a cipher or a code. For example, if &amp;quot;brog&amp;quot; represents something else. But without more context, it's hard to tell. However, given the two examples, multiplying the two numbers gives the result. So 5/5=1, 4/2=2, so 3/1=3. Therefore, I think that's the intended relationship.&lt;/p&gt; &lt;p&gt;Alternatively, maybe it's a function where &amp;quot;brog&amp;quot; represents the number of something. For example, if you have &amp;quot;brog&amp;quot; as in &amp;quot;bro&amp;quot; meaning something else. But again, without knowing the exact meaning, this is speculative.&lt;/p&gt; &lt;p&gt;Alternatively, maybe it's a function where &amp;quot;brog&amp;quot; is a variable. Let me think of a function f(n, m) where n and m are numbers, and f(n, m) is defined in some way. For example, maybe f(n, m) = n - m? Then 5-5=0, which doesn't match. Or f(n, m) = n + m? 5+5=10≠1. Not helpful.&lt;/p&gt; &lt;p&gt;Alternatively, maybe it's a function where the result is the sum of the numbers divided by something. For example, 5 brog 5 is 1. Let me think of fractions. If 5/5=1, then 4/2=2, so 3/1=3. That seems to fit. So maybe the rule is f(n, m) = n/m. Therefore, the answer is 3. Therefore, I think the answer is 3.&lt;/p&gt; &lt;p&gt;**Final Answer**&lt;/p&gt; &lt;p&gt;The value of 3 brog 1 is \boxed{3}.&lt;/p&gt; &lt;p&gt;&amp;lt;/think&amp;gt;&lt;/p&gt; &lt;p&gt;content: To solve the problem, we are given two equations:&lt;/p&gt; &lt;p&gt;- $ 5 \text{ brog } 5 = 1 $&lt;/p&gt; &lt;p&gt;- $ 4 \text{ brog } 2 = 2 $&lt;/p&gt; &lt;p&gt;We are asked to determine the value of $ 3 \text{ brog } 1 $.&lt;/p&gt; &lt;p&gt;---&lt;/p&gt; &lt;p&gt;### Step 1: Identify the Pattern&lt;/p&gt; &lt;p&gt;We observe that:&lt;/p&gt; &lt;p&gt;- $ 5 \text{ brog } 5 = 1 $&lt;/p&gt; &lt;p&gt;- $ 4 \text{ brog } 2 = 2 $&lt;/p&gt; &lt;p&gt;If we interpret &amp;quot;brog&amp;quot; as a simple mathematical operation, and assume it is the operation of division, then:&lt;/p&gt; &lt;p&gt;- $ 5 \text{ brog } 5 = \frac{5}{5} = 1 $&lt;/p&gt; &lt;p&gt;- $ 4 \text{ brog } 2 = \frac{4}{2} = 2 $&lt;/p&gt; &lt;p&gt;This pattern suggests that the operation is defined as $ \frac{n}{m} $, where $ n $ and $ m $ are the numbers in the &amp;quot;brog&amp;quot; expression.&lt;/p&gt; &lt;p&gt;---&lt;/p&gt; &lt;p&gt;### Step 2: Apply the Pattern to Find the Result&lt;/p&gt; &lt;p&gt;We are now asked to find the value of $ 3 \text{ brog } 1 $. Using the same pattern:&lt;/p&gt; &lt;p&gt;$$&lt;/p&gt; &lt;p&gt;3 \text{ brog } 1 = \frac{3}{1} = 3&lt;/p&gt; &lt;p&gt;$$&lt;/p&gt; &lt;p&gt;---&lt;/p&gt; &lt;p&gt;### Final Answer&lt;/p&gt; &lt;p&gt;$$&lt;/p&gt; &lt;p&gt;\boxed{3}&lt;/p&gt; &lt;p&gt;$$&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/JohnnyLiverman"&gt; /u/JohnnyLiverman &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kaa8iz/this_is_600m_parameters_yesterday_i_would_have/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1kaa8iz/this_is_600m_parameters_yesterday_i_would_have/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1kaa8iz/this_is_600m_parameters_yesterday_i_would_have/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T23:49:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka6b9p</id>
    <title>Qwen 3 MoE making Llama 4 Maverick obsolete... 😱</title>
    <updated>2025-04-28T20:53:59+00:00</updated>
    <author>
      <name>/u/Cool-Chemical-5629</name>
      <uri>https://old.reddit.com/user/Cool-Chemical-5629</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6b9p/qwen_3_moe_making_llama_4_maverick_obsolete/"&gt; &lt;img alt="Qwen 3 MoE making Llama 4 Maverick obsolete... 😱" src="https://preview.redd.it/szckfh6i2nxe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6dfa045be761753915c1f77e27b33367ce3b36c5" title="Qwen 3 MoE making Llama 4 Maverick obsolete... 😱" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cool-Chemical-5629"&gt; /u/Cool-Chemical-5629 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/szckfh6i2nxe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6b9p/qwen_3_moe_making_llama_4_maverick_obsolete/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6b9p/qwen_3_moe_making_llama_4_maverick_obsolete/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T20:53:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka5t8z</id>
    <title>Qwen3 Github Repo is up</title>
    <updated>2025-04-28T20:32:57+00:00</updated>
    <author>
      <name>/u/Predatedtomcat</name>
      <uri>https://old.reddit.com/user/Predatedtomcat</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/QwenLM/qwen3"&gt;https://github.com/QwenLM/qwen3&lt;/a&gt;&lt;/p&gt; &lt;p&gt;ollama is up &lt;a href="https://ollama.com/library/qwen3"&gt;https://ollama.com/library/qwen3&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Benchmarks are up too &lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;https://qwenlm.github.io/blog/qwen3/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Model weights seems to be up here, &lt;a href="https://huggingface.co/organizations/Qwen/activity/models"&gt;https://huggingface.co/organizations/Qwen/activity/models&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Chat is up at &lt;a href="https://chat.qwen.ai/"&gt;https://chat.qwen.ai/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;HF demo is up too &lt;a href="https://huggingface.co/spaces/Qwen/Qwen3-Demo"&gt;https://huggingface.co/spaces/Qwen/Qwen3-Demo&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Model collection here &lt;a href="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f"&gt;https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Predatedtomcat"&gt; /u/Predatedtomcat &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka5t8z/qwen3_github_repo_is_up/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka5t8z/qwen3_github_repo_is_up/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka5t8z/qwen3_github_repo_is_up/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T20:32:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka8b2u</id>
    <title>Qwen3-30B-A3B is what most people have been waiting for</title>
    <updated>2025-04-28T22:19:39+00:00</updated>
    <author>
      <name>/u/ForsookComparison</name>
      <uri>https://old.reddit.com/user/ForsookComparison</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A QwQ competitor that limits its thinking that uses MoE with very small experts for lightspeed inference.&lt;/p&gt; &lt;p&gt;It's out, it's the real deal, Q5 is competing with QwQ easily in my personal local tests and pipelines. It's succeeding at coding one-shots, it's succeeding at editing existing codebases, it's succeeding as the 'brains' of an agentic pipeline of mine- and it's doing it all at blazing fast speeds.&lt;/p&gt; &lt;p&gt;No excuse now - intelligence that used to be SOTA now runs on modest gaming rigs - &lt;em&gt;GO BUILD SOMETHING COOL&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ForsookComparison"&gt; /u/ForsookComparison &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8b2u/qwen330ba3b_is_what_most_people_have_been_waiting/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8b2u/qwen330ba3b_is_what_most_people_have_been_waiting/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8b2u/qwen330ba3b_is_what_most_people_have_been_waiting/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T22:19:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka8r2t</id>
    <title>Qwen didn't just cook. They had a whole barbecue!</title>
    <updated>2025-04-28T22:39:32+00:00</updated>
    <author>
      <name>/u/MushroomGecko</name>
      <uri>https://old.reddit.com/user/MushroomGecko</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8r2t/qwen_didnt_just_cook_they_had_a_whole_barbecue/"&gt; &lt;img alt="Qwen didn't just cook. They had a whole barbecue!" src="https://preview.redd.it/z8nu50rdlnxe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=42135693763896c9c446089c6fa47afc509ad7f4" title="Qwen didn't just cook. They had a whole barbecue!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/MushroomGecko"&gt; /u/MushroomGecko &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/z8nu50rdlnxe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8r2t/qwen_didnt_just_cook_they_had_a_whole_barbecue/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka8r2t/qwen_didnt_just_cook_they_had_a_whole_barbecue/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T22:39:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1ka6mic</id>
    <title>Qwen 3 !!!</title>
    <updated>2025-04-28T21:07:01+00:00</updated>
    <author>
      <name>/u/ResearchCrafty1804</name>
      <uri>https://old.reddit.com/user/ResearchCrafty1804</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6mic/qwen_3/"&gt; &lt;img alt="Qwen 3 !!!" src="https://b.thumbs.redditmedia.com/rxKFE9weQYC5m_GiwAPp1WBzACIB-lnfHoSDBbyeOEE.jpg" title="Qwen 3 !!!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Introducing Qwen3! &lt;/p&gt; &lt;p&gt;We release and open-weight Qwen3, our latest large language models, including 2 MoE models and 6 dense models, ranging from 0.6B to 235B. Our flagship model, Qwen3-235B-A22B, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, Qwen3-30B-A3B, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.&lt;/p&gt; &lt;p&gt;For more information, feel free to try them out in Qwen Chat Web (chat.qwen.ai) and APP and visit our GitHub, HF, ModelScope, etc.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ResearchCrafty1804"&gt; /u/ResearchCrafty1804 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1ka6mic"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6mic/qwen_3/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ka6mic/qwen_3/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-04-28T21:07:01+00:00</published>
  </entry>
</feed>
