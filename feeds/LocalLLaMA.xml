<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-03-04T08:50:09+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1j2pm6n</id>
    <title>Cache-Craft: Chunk-Level KV Cache Reuse for Faster and Efficient RAG (SIGMOD 2025)</title>
    <updated>2025-03-03T18:29:59+00:00</updated>
    <author>
      <name>/u/Lucky-Ad79</name>
      <uri>https://old.reddit.com/user/Lucky-Ad79</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Excited to share &lt;strong&gt;&lt;em&gt;Cache-Craft&lt;/em&gt;&lt;/strong&gt; [&lt;a href="https://www.arxiv.org/pdf/2502.15734"&gt;PDF&lt;/a&gt;], our SIGMOD 2025 paper on efficient &lt;strong&gt;chunk-aware KV reuse&lt;/strong&gt; for RAG! 🚀&lt;/p&gt; &lt;p&gt;Large language models (LLMs) in retrieval-augmented generation (RAG) often recompute KV caches unnecessarily, leading to inefficiencies. &lt;strong&gt;&lt;em&gt;Cache-Craft&lt;/em&gt;&lt;/strong&gt; introduces a &lt;strong&gt;granular&lt;/strong&gt; &lt;strong&gt;chunk-level KV reuse strategy&lt;/strong&gt; that selectively recomputes only what’s necessary—reducing redundant computation while maintaining generation quality.&lt;/p&gt; &lt;p&gt;🔹 &lt;strong&gt;Key contributions:&lt;/strong&gt;&lt;br /&gt; ✅ &lt;strong&gt;Chunked KV Reuse:&lt;/strong&gt; Efficiently caches and reuses KV states at a RAG chunk level, unlike traditional full-prefix-cache methods.&lt;br /&gt; ✅ &lt;strong&gt;Selective Recompute Planning:&lt;/strong&gt; Dynamically determines which KV states to reuse vs. recompute, optimizing for efficiency.&lt;br /&gt; ✅ &lt;strong&gt;Real-World Gains:&lt;/strong&gt; Evaluated on production-scale RAG traces, showing significant reductions in compute overhead.&lt;br /&gt; ✅ &lt;strong&gt;vLLM-based Open Source Coming Soon!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Would love to hear your thoughts! How do you see caching evolving for efficient LLM inference? 🤔&lt;/p&gt; &lt;p&gt;&lt;em&gt;[1] Agarwal, S., Sundaresan, S., Mitra, S., Mahapatra, D., Gupta, A., Sharma, R., Kapu, N.J., Yu, T. and Saini, S., 2025. Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation. arXiv preprint arXiv:2502.15734.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Lucky-Ad79"&gt; /u/Lucky-Ad79 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2pm6n/cachecraft_chunklevel_kv_cache_reuse_for_faster/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2pm6n/cachecraft_chunklevel_kv_cache_reuse_for_faster/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2pm6n/cachecraft_chunklevel_kv_cache_reuse_for_faster/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T18:29:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1j31jqr</id>
    <title>What is the best multi-modal or llm for tax table PDF/image?</title>
    <updated>2025-03-04T03:29:37+00:00</updated>
    <author>
      <name>/u/caphohotain</name>
      <uri>https://old.reddit.com/user/caphohotain</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Reading tax tables and reports is painful. I wonder if there are some good models can help. &lt;/p&gt; &lt;p&gt;Edit:typo&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/caphohotain"&gt; /u/caphohotain &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j31jqr/what_is_the_best_multimodal_or_llm_for_tax_table/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j31jqr/what_is_the_best_multimodal_or_llm_for_tax_table/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j31jqr/what_is_the_best_multimodal_or_llm_for_tax_table/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T03:29:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2tdtt</id>
    <title>Build your own evals in minutes, including comparing to human preferences. Plus: Sonnet 3.7 Thinking fine-tuning &amp; eval. [KilnAI Guide]</title>
    <updated>2025-03-03T21:03:53+00:00</updated>
    <author>
      <name>/u/davernow</name>
      <uri>https://old.reddit.com/user/davernow</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2tdtt/build_your_own_evals_in_minutes_including/"&gt; &lt;img alt="Build your own evals in minutes, including comparing to human preferences. Plus: Sonnet 3.7 Thinking fine-tuning &amp;amp; eval. [KilnAI Guide]" src="https://external-preview.redd.it/fkk_hfuiSuMOZjLy_dEtjSiqJMOwZz9w_oAKY_5Q2Nk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a3dadc03291c7ac04f201561f33b9b740f85a835" title="Build your own evals in minutes, including comparing to human preferences. Plus: Sonnet 3.7 Thinking fine-tuning &amp;amp; eval. [KilnAI Guide]" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I've just released an update of Kiln on Github which provides a powerful toolkit for evaluating AI models and tasks.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href="https://docs.getkiln.ai/docs/evaluations#video-walkthrough"&gt;walkthrough vid&lt;/a&gt; shows the process from start to end&lt;/li&gt; &lt;li&gt;Our docs have &lt;a href="https://docs.getkiln.ai/docs/evaluations"&gt;evaluation guide&lt;/a&gt; if you want to try it out yourself&lt;/li&gt; &lt;li&gt;Here's the ~&lt;a href="https://github.com/Kiln-AI/Kiln"&gt;Github repo&lt;/a&gt;~ with all of the source code&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The eval feature includes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Multiple state of the art evaluation methods (G-Eval, LLM as Judge)&lt;/li&gt; &lt;li&gt;Synthetic data generation makes it easy to generaet hundreds or thousands of eval data samples in minutes.&lt;/li&gt; &lt;li&gt;Includes tooling to find the best evaluation method for your task. It finds the eval algo+model which best correlates to human preference (Kendall’s Tau, Spearman, MSE, etc).&lt;/li&gt; &lt;li&gt;Includes eval dashboard to find the highest quality method to run your task (prompt+model)&lt;/li&gt; &lt;li&gt;Fine-tunes: create then evaluate custom fine-tunes for your task&lt;/li&gt; &lt;li&gt;Intuitive UI for eval dataset management: create eval sets, manage golden sets, add human ratings, etc.&lt;/li&gt; &lt;li&gt;Automatic eval generation: it will examine your task definition, then automatically create an evaluator for you.&lt;/li&gt; &lt;li&gt;Supports custom evaluators: create evals for any score/goals/instructions you want.&lt;/li&gt; &lt;li&gt;Built in eval templates for common scenarios: toxicity, bias, jailbreaking, factual correctness, and maliciousness.&lt;/li&gt; &lt;li&gt;Synthetic data templates to generate adversarial datasets using uncensored and unaligned models like Dolphin/Grok. Weird use case where very inappropriate content has a very ethical use. The video has a demo of Dolphin trying to jailbreak the core model.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: this release also includes the ability to distill Sonnet 3.7 Thinking into an open model you can run locally. I evaluate a few of these fine-tunes against foundation models, and they do quite well (at task-specific metrics).&lt;/p&gt; &lt;p&gt;Kiln runs locally and we never have access to your dataset. If you use Ollama, data never leaves your device.&lt;/p&gt; &lt;p&gt;If anyone wants to try Kiln, here's the &lt;a href="https://github.com/Kiln-AI/Kiln/releases/tag/v0.12.1"&gt;latest release on Github&lt;/a&gt; and the &lt;a href="https://docs.getkiln.ai/"&gt;docs are here&lt;/a&gt;. Getting started is super easy - it's a one-click install to get setup and running. Let me know if you have any feedback or ideas! It really helps me improve Kiln. Thanks!&lt;/p&gt; &lt;p&gt;&lt;a href="https://reddit.com/link/1j2tdtt/video/f4mqimpchjme1/player"&gt;Walkthrough of creating an AI Eval&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/davernow"&gt; /u/davernow &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2tdtt/build_your_own_evals_in_minutes_including/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2tdtt/build_your_own_evals_in_minutes_including/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2tdtt/build_your_own_evals_in_minutes_including/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T21:03:53+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2j8x5</id>
    <title>Ran R1 on one server, but I have three. Should I go the EXO route and buy 100gb nics?</title>
    <updated>2025-03-03T13:59:10+00:00</updated>
    <author>
      <name>/u/zR0B3ry2VAiH</name>
      <uri>https://old.reddit.com/user/zR0B3ry2VAiH</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2j8x5/ran_r1_on_one_server_but_i_have_three_should_i_go/"&gt; &lt;img alt="Ran R1 on one server, but I have three. Should I go the EXO route and buy 100gb nics?" src="https://preview.redd.it/x73g8sumdhme1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=86a6a6523268d0e31eb6f4341c716de3ee799ab2" title="Ran R1 on one server, but I have three. Should I go the EXO route and buy 100gb nics?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;100gb nics are $330 with two ports each, so I’d run it direct connections between all three. Each server has two Xeon process with 512 gb of ram. Did some shuffling with the ram sticks to get R1 to run locally, but as you would expect, it’s pretty slow.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/zR0B3ry2VAiH"&gt; /u/zR0B3ry2VAiH &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/x73g8sumdhme1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2j8x5/ran_r1_on_one_server_but_i_have_three_should_i_go/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2j8x5/ran_r1_on_one_server_but_i_have_three_should_i_go/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T13:59:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1j3621h</id>
    <title>What prompt template should be used for finetuning on Unsloth ?</title>
    <updated>2025-03-04T08:13:02+00:00</updated>
    <author>
      <name>/u/Prior-Blood5979</name>
      <uri>https://old.reddit.com/user/Prior-Blood5979</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I'm trying to finetune an llama-3b on Unsloth. I used the given alpaca format and it's training is good. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Then I thought I can improve it by using llama prompt template instead of alpaca.&lt;/strong&gt; But It's not even as good as using Alpaca format. &lt;/p&gt; &lt;p&gt;Why is this happening. Am I doing something wrong here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Prior-Blood5979"&gt; /u/Prior-Blood5979 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j3621h/what_prompt_template_should_be_used_for/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j3621h/what_prompt_template_should_be_used_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j3621h/what_prompt_template_should_be_used_for/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T08:13:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2wzky</id>
    <title>Which do you think is better: Deepseek-R1-32B vs QWQ-32b-preview?</title>
    <updated>2025-03-03T23:40:14+00:00</updated>
    <author>
      <name>/u/swagonflyyyy</name>
      <uri>https://old.reddit.com/user/swagonflyyyy</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I've been using QWQ-32b-preview for a lot of different things, only to find out Qwen2.5-coder-32b provides comparable performance in math and coding.&lt;/p&gt; &lt;p&gt;This made me question whether QWQ really was an effective reasoning model, but my comparison will not be against Coder, but with Deepseek-r1-32B instead. Is the latter model any better than QWQ? I would really like to settle the matter.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/swagonflyyyy"&gt; /u/swagonflyyyy &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2wzky/which_do_you_think_is_better_deepseekr132b_vs/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2wzky/which_do_you_think_is_better_deepseekr132b_vs/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2wzky/which_do_you_think_is_better_deepseekr132b_vs/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T23:40:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1j32szk</id>
    <title>Any Update on the HF's Open R1 Project?</title>
    <updated>2025-03-04T04:35:42+00:00</updated>
    <author>
      <name>/u/Iory1998</name>
      <uri>https://old.reddit.com/user/Iory1998</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am curious. Following the release of Deepseek R1, Hugging Face announced a new project dubbed Open R1 attempting to reproduce R1. I haven't heard about it since.&lt;/p&gt; &lt;p&gt;Do you know if there is any meaningful step forward?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Iory1998"&gt; /u/Iory1998 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j32szk/any_update_on_the_hfs_open_r1_project/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j32szk/any_update_on_the_hfs_open_r1_project/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j32szk/any_update_on_the_hfs_open_r1_project/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T04:35:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2horr</id>
    <title>NLP Brain-to-Text Decoding: A Non-invasive Approach via Typing</title>
    <updated>2025-03-03T12:36:04+00:00</updated>
    <author>
      <name>/u/iamnotdeadnuts</name>
      <uri>https://old.reddit.com/user/iamnotdeadnuts</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2horr/nlp_braintotext_decoding_a_noninvasive_approach/"&gt; &lt;img alt="NLP Brain-to-Text Decoding: A Non-invasive Approach via Typing" src="https://preview.redd.it/8gyz8kzsygme1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a88d058b7bc64d9941684f9dc53c45071cf7f231" title="NLP Brain-to-Text Decoding: A Non-invasive Approach via Typing" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/"&gt;https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/iamnotdeadnuts"&gt; /u/iamnotdeadnuts &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/8gyz8kzsygme1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2horr/nlp_braintotext_decoding_a_noninvasive_approach/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2horr/nlp_braintotext_decoding_a_noninvasive_approach/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T12:36:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1j29mi4</id>
    <title>Me Today</title>
    <updated>2025-03-03T03:38:52+00:00</updated>
    <author>
      <name>/u/ForsookComparison</name>
      <uri>https://old.reddit.com/user/ForsookComparison</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j29mi4/me_today/"&gt; &lt;img alt="Me Today" src="https://preview.redd.it/qrxhvlblaeme1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6a2767bc89a037159368246cac9dac0d3050c85f" title="Me Today" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ForsookComparison"&gt; /u/ForsookComparison &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/qrxhvlblaeme1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j29mi4/me_today/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j29mi4/me_today/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T03:38:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2wf5j</id>
    <title>High demand for DIGITS</title>
    <updated>2025-03-03T23:14:14+00:00</updated>
    <author>
      <name>/u/Cane_P</name>
      <uri>https://old.reddit.com/user/Cane_P</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I don't know if the claim is valid, but according to Taiwanese &amp;quot;United News Media&amp;quot; (udn.com), more production capacity will be allocated to DIGITS than initially planned, because AI companies want to use it for edge computing.&lt;/p&gt; &lt;p&gt;Source: &lt;a href="https://money.udn.com/money/story/5612/8581326"&gt;https://money.udn.com/money/story/5612/8581326&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Google translated version: &lt;a href="https://money-udn-com.translate.goog/money/story/5612/8581326?_x_tr_sl=auto&amp;amp;_x_tr_tl=en&amp;amp;_x_tr_hl=en-US&amp;amp;_x_tr_pto=wapp"&gt;https://money-udn-com.translate.goog/money/story/5612/8581326?_x_tr_sl=auto&amp;amp;_x_tr_tl=en&amp;amp;_x_tr_hl=en-US&amp;amp;_x_tr_pto=wapp&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cane_P"&gt; /u/Cane_P &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2wf5j/high_demand_for_digits/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2wf5j/high_demand_for_digits/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2wf5j/high_demand_for_digits/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T23:14:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2m5a3</id>
    <title>I just made something really cursed. It's a local AI javascript library that allows for generating all of your websites styles... using text... It's like tailwind!</title>
    <updated>2025-03-03T16:08:39+00:00</updated>
    <author>
      <name>/u/valdev</name>
      <uri>https://old.reddit.com/user/valdev</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2m5a3/i_just_made_something_really_cursed_its_a_local/"&gt; &lt;img alt="I just made something really cursed. It's a local AI javascript library that allows for generating all of your websites styles... using text... It's like tailwind!" src="https://external-preview.redd.it/MzV5cjJiYnAwaW1lMVP5w4KiH2jOdvVLO5M2qzHTvkueIwiHgKlPWJafTXUE.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=85988097e8c3bdd3a2d386e68bcd0b55c2d2f2c0" title="I just made something really cursed. It's a local AI javascript library that allows for generating all of your websites styles... using text... It's like tailwind!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/valdev"&gt; /u/valdev &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/ys7qtcbp0ime1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2m5a3/i_just_made_something_really_cursed_its_a_local/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2m5a3/i_just_made_something_really_cursed_its_a_local/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T16:08:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1j34snr</id>
    <title>I open sourced my project to analyze your years of Apple Health data with Local Llama</title>
    <updated>2025-03-04T06:40:45+00:00</updated>
    <author>
      <name>/u/Fit_Chair2340</name>
      <uri>https://old.reddit.com/user/Fit_Chair2340</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j34snr/i_open_sourced_my_project_to_analyze_your_years/"&gt; &lt;img alt="I open sourced my project to analyze your years of Apple Health data with Local Llama" src="https://external-preview.redd.it/lLsIvxvl6coJk3dd69rue5IjQS1mwSUfJjRAQiI0jak.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0705f2c7bb303cf84d8b222fd9c148b2417ea6ce" title="I open sourced my project to analyze your years of Apple Health data with Local Llama" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I was playing around and found out that you can export all your Apple health data. I've been wearing an Apple watch for 8 years and whoop for 3 years. I always check my day to day and week to week stats but I never looked at the data over the years. What if I could send this data to A.I. for analysis? But I also don't want to send my private data to a public LLM. What if I could run the analysis locally?&lt;/p&gt; &lt;p&gt;I exported my data and there was 989MB of data! So I needed to write some code to break this down. The code takes in your export data and gives you options to look at Steps, Distance, Heart rate, Sleep and more. It gave me some cool charts and you can use local llama to run the A.I. analysis!&lt;/p&gt; &lt;p&gt;I was really stressed at work last 2 years.&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/65612e77cmme1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=784225ea3990427860e9abb16fcd60eec3da2563"&gt;https://preview.redd.it/65612e77cmme1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=784225ea3990427860e9abb16fcd60eec3da2563&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It gave me some CRAZY insights:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Seasonal Anomalies: While there's a general trend of higher activity in spring/summer, some of your most active periods occurred during winter months, particularly in December and January of recent years.&lt;/li&gt; &lt;li&gt;Reversed Weekend Pattern: Unlike most people who are more active on weekends, your data shows consistently lower step counts on weekends, suggesting your physical activity is more tied to workdays than leisure time.&lt;/li&gt; &lt;li&gt;COVID Impact: There's a clear signature of the pandemic in your data, with more erratic step patterns and changed workout routines during 2020-2021, followed by a distinct recovery pattern in late 2021.&lt;/li&gt; &lt;li&gt;Morning Consistency: Your most successful workout periods consistently occur in morning hours, with these sessions showing better heart rate performance compared to other times.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can run this on your own computer. No one can access your data. &lt;a href="https://github.com/krumjahn/applehealth"&gt;&lt;strong&gt;Here's the link to the project.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you need more guidance on how to run it (not a programmer), &lt;a href="https://rumjahn.com/how-i-used-a-i-to-analyze-8-years-of-apple-health-fitness-data-to-uncover-actionable-insights/"&gt;check out my detailed instructions here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If people like this, I will make a web app version so you can run it without using code. Give this a like if you find it useful!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Fit_Chair2340"&gt; /u/Fit_Chair2340 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j34snr/i_open_sourced_my_project_to_analyze_your_years/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j34snr/i_open_sourced_my_project_to_analyze_your_years/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j34snr/i_open_sourced_my_project_to_analyze_your_years/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T06:40:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1j29hm0</id>
    <title>New Atom of Thoughts looks promising for helping smaller models reason</title>
    <updated>2025-03-03T03:31:16+00:00</updated>
    <author>
      <name>/u/nuclearbananana</name>
      <uri>https://old.reddit.com/user/nuclearbananana</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j29hm0/new_atom_of_thoughts_looks_promising_for_helping/"&gt; &lt;img alt="New Atom of Thoughts looks promising for helping smaller models reason" src="https://preview.redd.it/xlairo4g9eme1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=767c07ca77e2312ef37e77aa5686232b9b3aebb6" title="New Atom of Thoughts looks promising for helping smaller models reason" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/nuclearbananana"&gt; /u/nuclearbananana &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/xlairo4g9eme1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j29hm0/new_atom_of_thoughts_looks_promising_for_helping/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j29hm0/new_atom_of_thoughts_looks_promising_for_helping/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T03:31:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2xzsj</id>
    <title>I used a 100-line LLM Framework to let AI Agents build Agents for me (Step-by-Step Video Tutorial)</title>
    <updated>2025-03-04T00:27:24+00:00</updated>
    <author>
      <name>/u/Willing-Site-8137</name>
      <uri>https://old.reddit.com/user/Willing-Site-8137</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I made a video tutorial on a personal hack that can let Cursor AI build complex LLM Agents and greatly improve my productivity : &lt;a href="https://youtu.be/wc9O-9mcObc"&gt;https://youtu.be/wc9O-9mcObc&lt;/a&gt;&lt;/p&gt; &lt;p&gt;For example, in this tutorial, I mostly write the high-level design doc, and Cursor AI handles all the implementation and coding to build an &lt;a href="https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple"&gt;AI YouTube Summarizer&lt;/a&gt;. The secret is &lt;a href="https://github.com/The-Pocket/PocketFlow"&gt;Pocket Flow&lt;/a&gt;, a 100-line framework that fits easily into Cursor’s &lt;a href="https://docs.cursor.com/context/rules-for-ai"&gt;rules&lt;/a&gt;, remains flexible for all sorts of designs, and nudges Cursor to follow good coding practices.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Background of 100-line framework&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I built this &lt;a href="https://github.com/The-Pocket/PocketFlow"&gt;100-line LLM framework&lt;/a&gt; over Christmas. It provides the core “graph abstraction” that LLM workflows need—for (&lt;a href="https://the-pocket.github.io/PocketFlow/design_pattern/multi_agent.html"&gt;multi-&lt;/a&gt;)&lt;a href="https://the-pocket.github.io/PocketFlow/design_pattern/agent.html"&gt;agents&lt;/a&gt;, &lt;a href="https://the-pocket.github.io/PocketFlow/design_pattern/rag.html"&gt;Retrieval-Augmented Generation (RAG)&lt;/a&gt;, &lt;a href="https://the-pocket.github.io/PocketFlow/design_pattern/workflow.html"&gt;workflow&lt;/a&gt;, and more. I built this because:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Most big frameworks have &lt;em&gt;messy abstractions&lt;/em&gt;, deprecated methods, and annoying dependencies that are very hard to use.&lt;/li&gt; &lt;li&gt;These issues don’t just confuse humans; they confuse AI coding assistants as well! For example, if you let &lt;em&gt;Cursor AI&lt;/em&gt; build a LLM project with those frameworks, you’ll likely run into a bunch of version or deprecation errors.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;So I stripped everything down to &lt;strong&gt;100 lines&lt;/strong&gt;, making it easy for AI tools (like &lt;em&gt;Cursor AI&lt;/em&gt;) to read and build on top of it as “rules.” Surprisingly, &lt;strong&gt;Cursor understands Pocket Flow really well&lt;/strong&gt;-its generated code is modular, maintainable, and has &lt;em&gt;greatly boosted my productivity&lt;/em&gt; over the past year.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Demo in the YouTube Video&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;To demonstrate this further, I made &lt;a href="https://www.youtube.com/watch?v=wc9O-9mcObc"&gt;this &lt;em&gt;YouTube video&lt;/em&gt;&lt;/a&gt; showing exactly how I fed &lt;em&gt;Cursor AI&lt;/em&gt; the &lt;strong&gt;Pocket Flow&lt;/strong&gt; docs and a high-level design to build LLM apps. I asked &lt;em&gt;Cursor AI&lt;/em&gt; to create a &lt;a href="https://github.com/The-Pocket/Tutorial-Youtube-Made-Simple"&gt;YouTube “explainer” agent &lt;/a&gt;that summarizes long videos into &lt;em&gt;simple “5-year-old-friendly” terms&lt;/em&gt;—for instance, it can condense Lex Fridman’s &lt;em&gt;5-hour DeepSeek&lt;/em&gt; interview into a &lt;a href="https://the-pocket.github.io/Tutorial-Youtube-Made-Simple/examples/DeepSeek%2C%20China%2C%20OpenAI%2C%20NVIDIA%2C%20xAI%2C%20TSMC%2C%20Stargate%2C%20and%20AI%20Megaclusters%20%7C%20Lex%20Fridman%20Podcast%20%23459.html"&gt;concise, sharp summary&lt;/a&gt;. The entire development took me &lt;em&gt;less than an hour&lt;/em&gt;—and you can do the same!&lt;/p&gt; &lt;p&gt;I’m very new to YouTube, so &lt;em&gt;please, please, please&lt;/em&gt; give me your feedback on which parts are unclear! If there’s another LLM project you’d like to see me build with Pocket Flow + Cursor, let me know!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Willing-Site-8137"&gt; /u/Willing-Site-8137 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2xzsj/i_used_a_100line_llm_framework_to_let_ai_agents/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2xzsj/i_used_a_100line_llm_framework_to_let_ai_agents/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2xzsj/i_used_a_100line_llm_framework_to_let_ai_agents/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T00:27:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2kdeb</id>
    <title>OpenBenchTable is great for trying out different compute hardware configurations. Does anyone have benchmarking tips?</title>
    <updated>2025-03-03T14:52:19+00:00</updated>
    <author>
      <name>/u/eso_logic</name>
      <uri>https://old.reddit.com/user/eso_logic</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2kdeb/openbenchtable_is_great_for_trying_out_different/"&gt; &lt;img alt="OpenBenchTable is great for trying out different compute hardware configurations. Does anyone have benchmarking tips?" src="https://b.thumbs.redditmedia.com/WEagdfr42ScIzJVwvfP__c7O6w-pNG7grBkUGiA0rAk.jpg" title="OpenBenchTable is great for trying out different compute hardware configurations. Does anyone have benchmarking tips?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/eso_logic"&gt; /u/eso_logic &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1j2kdeb"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2kdeb/openbenchtable_is_great_for_trying_out_different/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2kdeb/openbenchtable_is_great_for_trying_out_different/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T14:52:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1j329e9</id>
    <title>ktransformers troll rig R1 671B UD-Q2_K_XL on 96GB RAM in the wild</title>
    <updated>2025-03-04T04:07:23+00:00</updated>
    <author>
      <name>/u/VoidAlchemy</name>
      <uri>https://old.reddit.com/user/VoidAlchemy</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j329e9/ktransformers_troll_rig_r1_671b_udq2_k_xl_on_96gb/"&gt; &lt;img alt="ktransformers troll rig R1 671B UD-Q2_K_XL on 96GB RAM in the wild" src="https://external-preview.redd.it/Iv7H9o8LgDHbszU_vTFdZ8XMQmmCZhgShm1FiEoXFQ4.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a13486bc9da50e971c1852f3ecbc2b560e6b2f4b" title="ktransformers troll rig R1 671B UD-Q2_K_XL on 96GB RAM in the wild" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/VoidAlchemy"&gt; /u/VoidAlchemy &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.youtube.com/watch?v=4ucmn3b44x4"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j329e9/ktransformers_troll_rig_r1_671b_udq2_k_xl_on_96gb/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j329e9/ktransformers_troll_rig_r1_671b_udq2_k_xl_on_96gb/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T04:07:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2leve</id>
    <title>new Hugging Face course on building reasoning models like deepseek r1</title>
    <updated>2025-03-03T15:37:25+00:00</updated>
    <author>
      <name>/u/Zealousideal-Cut590</name>
      <uri>https://old.reddit.com/user/Zealousideal-Cut590</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A new FREE and CERTIFIED course is here, and It’s called &lt;strong&gt;The Reasoning Course.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;To sign up for the course, follow the org: &lt;a href="https://huggingface.co/reasoning-course"&gt;https://huggingface.co/reasoning-course&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This is what the course will cover:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It will teach you to build your own reasoning model like Deepseek r1.&lt;/li&gt; &lt;li&gt;It’s suitable for code and non-coders with separate certification.&lt;/li&gt; &lt;li&gt;The course has material and exercises from Hugging Face, Maxime Labonne, Unsloth, and Marimo notebooks. &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This is how the course works:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Sign up now, the first release is already live.&lt;/li&gt; &lt;li&gt;Each week we’ll release new material and exercises. &lt;/li&gt; &lt;li&gt;We have interactive demos and quizzes&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Zealousideal-Cut590"&gt; /u/Zealousideal-Cut590 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2leve/new_hugging_face_course_on_building_reasoning/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2leve/new_hugging_face_course_on_building_reasoning/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2leve/new_hugging_face_course_on_building_reasoning/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T15:37:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2vhhq</id>
    <title>Story writing benchmark/dataset</title>
    <updated>2025-03-03T22:32:38+00:00</updated>
    <author>
      <name>/u/CorrectLow9302</name>
      <uri>https://old.reddit.com/user/CorrectLow9302</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2vhhq/story_writing_benchmarkdataset/"&gt; &lt;img alt="Story writing benchmark/dataset" src="https://external-preview.redd.it/C3b4DWbqwScAlqlFr8UQw42SuiBsrSRBBL5H3HRmHFA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a47dcafbfc7088a32a7fc1410e5b9704fd4e1a93" title="Story writing benchmark/dataset" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/hu1npsu3xjme1.jpg?width=4665&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5ef87cc79183f0cb10bc67f5b10121bb979b878c"&gt;https://preview.redd.it/hu1npsu3xjme1.jpg?width=4665&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5ef87cc79183f0cb10bc67f5b10121bb979b878c&lt;/a&gt;&lt;/p&gt; &lt;p&gt;dataset: &lt;a href="https://huggingface.co/datasets/lars1234/story_writing_benchmark"&gt;https://huggingface.co/datasets/lars1234/story_writing_benchmark&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Each model was instructed to write 568 short stories. Each story was then rated by 4 models: Llama 3.3 70B, Mistral Small 24B (2501), Gemma 2 9B (SPPO-Iter3), Aya Expanse 32B. The ranking correlation between the evaluators is approx. 90%. Evaluation criteria such as creativity, world-building and grammar were weighted equally.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/CorrectLow9302"&gt; /u/CorrectLow9302 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2vhhq/story_writing_benchmarkdataset/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2vhhq/story_writing_benchmarkdataset/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2vhhq/story_writing_benchmarkdataset/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T22:32:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1j3479c</id>
    <title>I'm working on a open source UI coding tool with artifacts, cli, agent actions, and github connection</title>
    <updated>2025-03-04T06:00:27+00:00</updated>
    <author>
      <name>/u/United-Rush4073</name>
      <uri>https://old.reddit.com/user/United-Rush4073</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j3479c/im_working_on_a_open_source_ui_coding_tool_with/"&gt; &lt;img alt="I'm working on a open source UI coding tool with artifacts, cli, agent actions, and github connection" src="https://b.thumbs.redditmedia.com/FJNdfekndsHi-w5W0N_AnNYGW8A2CD2BuNGLk_uW8iI.jpg" title="I'm working on a open source UI coding tool with artifacts, cli, agent actions, and github connection" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/United-Rush4073"&gt; /u/United-Rush4073 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1j3479c"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j3479c/im_working_on_a_open_source_ui_coding_tool_with/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j3479c/im_working_on_a_open_source_ui_coding_tool_with/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T06:00:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2pw8i</id>
    <title>The sound Tesla P40s make while training is eerie. My apartment lights also phase pulse during passes.. 🤩</title>
    <updated>2025-03-03T18:40:59+00:00</updated>
    <author>
      <name>/u/AffectSouthern9894</name>
      <uri>https://old.reddit.com/user/AffectSouthern9894</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2pw8i/the_sound_tesla_p40s_make_while_training_is_eerie/"&gt; &lt;img alt="The sound Tesla P40s make while training is eerie. My apartment lights also phase pulse during passes.. 🤩" src="https://external-preview.redd.it/ZmV0aG1ibndyaW1lMWFNzMK25hHzjNvt4Y-OO73o5sGhDV6XnH6G0Oq87xCn.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e39fa10a7873118e9284eb276fb4ef9c51960837" title="The sound Tesla P40s make while training is eerie. My apartment lights also phase pulse during passes.. 🤩" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AffectSouthern9894"&gt; /u/AffectSouthern9894 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/lakifgrwrime1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2pw8i/the_sound_tesla_p40s_make_while_training_is_eerie/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2pw8i/the_sound_tesla_p40s_make_while_training_is_eerie/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T18:40:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1j345eq</id>
    <title>AMD Rocm User Forum</title>
    <updated>2025-03-04T05:57:04+00:00</updated>
    <author>
      <name>/u/Nerina23</name>
      <uri>https://old.reddit.com/user/Nerina23</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j345eq/amd_rocm_user_forum/"&gt; &lt;img alt="AMD Rocm User Forum" src="https://external-preview.redd.it/y_FINKO8XMlAJhEf7w8V__pSsdOlGq2_AygT_2N_tmE.jpg?width=108&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=90054cd4dd3bf4dc8ffabe4326ea716b454230eb" title="AMD Rocm User Forum" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Fingers crossed for competition to the Nvidia Dominance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Nerina23"&gt; /u/Nerina23 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://x.com/AMD/status/1896709832629158323"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j345eq/amd_rocm_user_forum/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j345eq/amd_rocm_user_forum/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T05:57:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1j32y7c</id>
    <title>Split brain (Update) - What I've learned and will improve</title>
    <updated>2025-03-04T04:43:51+00:00</updated>
    <author>
      <name>/u/Alienanthony</name>
      <uri>https://old.reddit.com/user/Alienanthony</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j32y7c/split_brain_update_what_ive_learned_and_will/"&gt; &lt;img alt="Split brain (Update) - What I've learned and will improve" src="https://external-preview.redd.it/UWvmtQPs4ScGH0IthYKdfU1hrMW7JnkAzdMKFse7jL0.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c740e7b82c11757b66468f76734733c2aa704f1c" title="Split brain (Update) - What I've learned and will improve" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;This is a update post to the last one &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1j25luw/split_brain_deepseekr1distillqwen15b_and/"&gt;Here&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I have uploaded a inference page to the code I had previously discussed. &lt;a href="https://github.com/alientony/Split-brain/blob/main/inference-app.py"&gt;Inference&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can download the fusion layer here. &lt;a href="https://huggingface.co/Alienanthony/Splitbrain_Fusion_model"&gt;Fusion layer&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The original models can be found here:&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"&gt;https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/meta-llama/Llama-3.2-1B"&gt;https://huggingface.co/meta-llama/Llama-3.2-1B&lt;/a&gt; &lt;/p&gt; &lt;p&gt;So far the inference has been fascinating. Unfortunately I have only had the original gpt4all dataset on hand for training. (800mb) &lt;/p&gt; &lt;p&gt;Including I have learned that if you're doing to use a fused layer for differentiation for one model output you should probably make another. So moving forward I will update the training and attempt again. &lt;/p&gt; &lt;p&gt;BUT I am extremely fascinated by this new crazy system.&lt;/p&gt; &lt;p&gt;As you can see below. While we did not give the model on the left &amp;quot;Describe the history of chocolate chip cookies.&amp;quot; it does begin to think in that direction within it's &amp;quot;Think&amp;quot; space. &lt;/p&gt; &lt;p&gt;I have been able to replicate this sort of &amp;quot;thought directions&amp;quot; multiple times but it is very erratic. As both models are actually not on the same playing field due to the dependency in the way the architecture functions and it is asymmetrical rather than mirrored.&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/m19l6vxpklme1.png?width=1428&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fdbd8edda0fb1b9a6b03d5922cf233fa462911a1"&gt;https://preview.redd.it/m19l6vxpklme1.png?width=1428&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fdbd8edda0fb1b9a6b03d5922cf233fa462911a1&lt;/a&gt;&lt;/p&gt; &lt;p&gt;One major issue I need to fix is the fused layer to realign the model on the right to produce usable tokens.&lt;/p&gt; &lt;p&gt;I also need a larger dataset as this will give more of a wider branch of training for the &amp;quot;sharing of info&amp;quot; across models but I find these results majorly agreeable!&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/ckwixc26rlme1.png?width=1164&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4164c7d255c32c1c00275f121437c96a65eef5b4"&gt;https://preview.redd.it/ckwixc26rlme1.png?width=1164&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4164c7d255c32c1c00275f121437c96a65eef5b4&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Alienanthony"&gt; /u/Alienanthony &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j32y7c/split_brain_update_what_ive_learned_and_will/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j32y7c/split_brain_update_what_ive_learned_and_will/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j32y7c/split_brain_update_what_ive_learned_and_will/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T04:43:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2usb0</id>
    <title>Is qwen 2.5 coder still the best?</title>
    <updated>2025-03-03T22:02:25+00:00</updated>
    <author>
      <name>/u/Ambitious_Subject108</name>
      <uri>https://old.reddit.com/user/Ambitious_Subject108</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Has anything better been released for coding? (&amp;lt;=32b parameters)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Ambitious_Subject108"&gt; /u/Ambitious_Subject108 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2usb0/is_qwen_25_coder_still_the_best/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2usb0/is_qwen_25_coder_still_the_best/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2usb0/is_qwen_25_coder_still_the_best/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T22:02:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1j2j7su</id>
    <title>I open-sourced Klee today, a desktop app designed to run LLMs locally with ZERO data collection. It also includes built-in RAG knowledge base and note-taking capabilities.</title>
    <updated>2025-03-03T13:57:34+00:00</updated>
    <author>
      <name>/u/w-zhong</name>
      <uri>https://old.reddit.com/user/w-zhong</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2j7su/i_opensourced_klee_today_a_desktop_app_designed/"&gt; &lt;img alt="I open-sourced Klee today, a desktop app designed to run LLMs locally with ZERO data collection. It also includes built-in RAG knowledge base and note-taking capabilities." src="https://preview.redd.it/54k8f1ladhme1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=aa20219f6ef894d7607d0ad10ab575e376420b53" title="I open-sourced Klee today, a desktop app designed to run LLMs locally with ZERO data collection. It also includes built-in RAG knowledge base and note-taking capabilities." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/w-zhong"&gt; /u/w-zhong &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/54k8f1ladhme1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j2j7su/i_opensourced_klee_today_a_desktop_app_designed/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j2j7su/i_opensourced_klee_today_a_desktop_app_designed/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-03T13:57:34+00:00</published>
  </entry>
  <entry>
    <id>t3_1j32p97</id>
    <title>Qwen 32b coder instruct can now drive a coding agent fairly well</title>
    <updated>2025-03-04T04:29:49+00:00</updated>
    <author>
      <name>/u/ai-christianson</name>
      <uri>https://old.reddit.com/user/ai-christianson</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j32p97/qwen_32b_coder_instruct_can_now_drive_a_coding/"&gt; &lt;img alt="Qwen 32b coder instruct can now drive a coding agent fairly well" src="https://external-preview.redd.it/aDJ4N25hdXlvbG1lMXyf8-rvm1C__Q4bDL3gJBkjO_bjkyMUPsobX80FiZpA.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0b763684453c2eb0539d13912eebe98f2d438296" title="Qwen 32b coder instruct can now drive a coding agent fairly well" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ai-christianson"&gt; /u/ai-christianson &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/c2000d3tolme1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1j32p97/qwen_32b_coder_instruct_can_now_drive_a_coding/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1j32p97/qwen_32b_coder_instruct_can_now_drive_a_coding/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-04T04:29:49+00:00</published>
  </entry>
</feed>
