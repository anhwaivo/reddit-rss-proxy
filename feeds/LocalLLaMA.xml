<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-01-24T15:05:49+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1i81iim</id>
    <title>Been ages since google released an open model</title>
    <updated>2025-01-23T11:43:36+00:00</updated>
    <author>
      <name>/u/Amgadoz</name>
      <uri>https://old.reddit.com/user/Amgadoz</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i81iim/been_ages_since_google_released_an_open_model/"&gt; &lt;img alt="Been ages since google released an open model" src="https://preview.redd.it/fa91scqqdqee1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4f78c10935c8984f8f9d17834c7720f182fed482" title="Been ages since google released an open model" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Amgadoz"&gt; /u/Amgadoz &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/fa91scqqdqee1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i81iim/been_ages_since_google_released_an_open_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i81iim/been_ages_since_google_released_an_open_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T11:43:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8ur2c</id>
    <title>WebRover - Your AI Co-pilot for Web Navigation üöÄ</title>
    <updated>2025-01-24T12:56:35+00:00</updated>
    <author>
      <name>/u/Elegant_Fish_3822</name>
      <uri>https://old.reddit.com/user/Elegant_Fish_3822</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ur2c/webrover_your_ai_copilot_for_web_navigation/"&gt; &lt;img alt="WebRover - Your AI Co-pilot for Web Navigation üöÄ" src="https://external-preview.redd.it/uGXGDtOqF0El7p0QKiiaYuh-4n8GTnWBDFAYTSa_Ns8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6b5eb2f4380186bc94114e3a7e0183e0764cbd73" title="WebRover - Your AI Co-pilot for Web Navigation üöÄ" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Ever wished for an AI that not only understands your commands but also autonomously navigates the web to accomplish tasks? üåêü§ñIntroducing WebRover üõ†Ô∏è, an open-source Autonomous AI Agent I've been developing, designed to interpret user input and seamlessly browse the internet to fulfill your requests.&lt;/p&gt; &lt;p&gt;Similar to Anthropic's &amp;quot;Computer Use&amp;quot; feature in Claude 3.5 Sonnet and OpenAI's &amp;quot;Operator&amp;quot; announced today , WebRover represents my effort in implementing this emerging technology.&lt;/p&gt; &lt;p&gt;Although it sometimes encounters loops and is not yet perfect, I believe that further fine-tuning a foundational model to execute appropriate tasks can effectively improve its efficacy.&lt;/p&gt; &lt;p&gt;Explore the project on GitHub: &lt;a href="https://github.com/hrithikkoduri/WebRover"&gt;https://github.com/hrithikkoduri/WebRover&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I welcome your feedback, suggestions, and contributions to enhance WebRover further. Let's collaborate to push the boundaries of autonomous AI agents! üöÄ&lt;/p&gt; &lt;p&gt;[In the demo video below, I prompted the agent to find the cheapest flight from Tucson to Austin, departing on Feb 1st and returning on Feb 10th.]&lt;/p&gt; &lt;p&gt;&lt;a href="https://reddit.com/link/1i8ur2c/video/dkawbbgsvxee1/player"&gt;https://reddit.com/link/1i8ur2c/video/dkawbbgsvxee1/player&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Elegant_Fish_3822"&gt; /u/Elegant_Fish_3822 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ur2c/webrover_your_ai_copilot_for_web_navigation/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ur2c/webrover_your_ai_copilot_for_web_navigation/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ur2c/webrover_your_ai_copilot_for_web_navigation/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T12:56:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8ptsj</id>
    <title>Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback</title>
    <updated>2025-01-24T07:08:28+00:00</updated>
    <author>
      <name>/u/ninjasaid13</name>
      <uri>https://old.reddit.com/user/ninjasaid13</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ninjasaid13"&gt; /u/ninjasaid13 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://arxiv.org/abs/2501.10799"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ptsj/stepkto_optimizing_mathematical_reasoning_through/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ptsj/stepkto_optimizing_mathematical_reasoning_through/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T07:08:28+00:00</published>
  </entry>
  <entry>
    <id>t3_1i856wr</id>
    <title>Open-source Deepseek beat not so OpenAI in 'humanity's last exam' !</title>
    <updated>2025-01-23T14:57:59+00:00</updated>
    <author>
      <name>/u/BidHot8598</name>
      <uri>https://old.reddit.com/user/BidHot8598</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i856wr/opensource_deepseek_beat_not_so_openai_in/"&gt; &lt;img alt="Open-source Deepseek beat not so OpenAI in 'humanity's last exam' !" src="https://preview.redd.it/lxwhx4eicree1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b6a7b23129dc6a37671b0f77472359990567d0e4" title="Open-source Deepseek beat not so OpenAI in 'humanity's last exam' !" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/BidHot8598"&gt; /u/BidHot8598 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/lxwhx4eicree1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i856wr/opensource_deepseek_beat_not_so_openai_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i856wr/opensource_deepseek_beat_not_so_openai_in/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T14:57:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8fpza</id>
    <title>SmolVLM 256M: The world's smallest multimodal model, running 100% locally in-browser on WebGPU.</title>
    <updated>2025-01-23T22:17:19+00:00</updated>
    <author>
      <name>/u/xenovatech</name>
      <uri>https://old.reddit.com/user/xenovatech</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8fpza/smolvlm_256m_the_worlds_smallest_multimodal_model/"&gt; &lt;img alt="SmolVLM 256M: The world's smallest multimodal model, running 100% locally in-browser on WebGPU." src="https://external-preview.redd.it/NTYzZXAwOXdpdGVlMeNP1riRHGftFiyraDTq8M0dXNR_Xk41nSkLrV2F0EOo.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=aefeccdf988fce29d96f197804b176f76684cb54" title="SmolVLM 256M: The world's smallest multimodal model, running 100% locally in-browser on WebGPU." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/xenovatech"&gt; /u/xenovatech &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/qikrzy8witee1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8fpza/smolvlm_256m_the_worlds_smallest_multimodal_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8fpza/smolvlm_256m_the_worlds_smallest_multimodal_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T22:17:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8svno</id>
    <title>"R1-Pro" - a 'Deep Think' Mode for DeepSeek-R1-Distilled Models ‚Äì Boost Reasoning Effort for Local LLMs</title>
    <updated>2025-01-24T10:59:52+00:00</updated>
    <author>
      <name>/u/AaronFeng47</name>
      <uri>https://old.reddit.com/user/AaronFeng47</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8svno/r1pro_a_deep_think_mode_for_deepseekr1distilled/"&gt; &lt;img alt="&amp;quot;R1-Pro&amp;quot; - a 'Deep Think' Mode for DeepSeek-R1-Distilled Models ‚Äì Boost Reasoning Effort for Local LLMs" src="https://external-preview.redd.it/eGF3YmJreDBheGVlMS3Azf7ct8pfQm1z9XYMY4QGWDLBtvNoRs9oapizu3FU.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=dac3f476e3c4ee2348f56005b736e1b0adac0d81" title="&amp;quot;R1-Pro&amp;quot; - a 'Deep Think' Mode for DeepSeek-R1-Distilled Models ‚Äì Boost Reasoning Effort for Local LLMs" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AaronFeng47"&gt; /u/AaronFeng47 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/qdylplx0axee1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8svno/r1pro_a_deep_think_mode_for_deepseekr1distilled/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8svno/r1pro_a_deep_think_mode_for_deepseekr1distilled/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T10:59:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1i86e4y</id>
    <title>Scale AI CEO says China has quickly caught the U.S. with the DeepSeek open-source model</title>
    <updated>2025-01-23T15:50:30+00:00</updated>
    <author>
      <name>/u/etherd0t</name>
      <uri>https://old.reddit.com/user/etherd0t</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i86e4y/scale_ai_ceo_says_china_has_quickly_caught_the_us/"&gt; &lt;img alt="Scale AI CEO says China has quickly caught the U.S. with the DeepSeek open-source model" src="https://external-preview.redd.it/QaGEWAoaN73yKpJcRFLASUVmy5TY0ehTzhGZuFAVhPY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=05b9252fa9a2aa815d8f1c4c41bc8b680d1e4628" title="Scale AI CEO says China has quickly caught the U.S. with the DeepSeek open-source model" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/etherd0t"&gt; /u/etherd0t &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.cnbc.com/2025/01/23/scale-ai-ceo-says-china-has-quickly-caught-the-us-with-deepseek.html"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i86e4y/scale_ai_ceo_says_china_has_quickly_caught_the_us/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i86e4y/scale_ai_ceo_says_china_has_quickly_caught_the_us/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T15:50:30+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8i41v</id>
    <title>Openai is ahead only till china reverse engineers...</title>
    <updated>2025-01-24T00:04:50+00:00</updated>
    <author>
      <name>/u/TheLogiqueViper</name>
      <uri>https://old.reddit.com/user/TheLogiqueViper</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8i41v/openai_is_ahead_only_till_china_reverse_engineers/"&gt; &lt;img alt="Openai is ahead only till china reverse engineers..." src="https://preview.redd.it/zy8ljay42uee1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8e8626d46d75e083e4343a6f229defc70f8055d8" title="Openai is ahead only till china reverse engineers..." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheLogiqueViper"&gt; /u/TheLogiqueViper &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/zy8ljay42uee1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8i41v/openai_is_ahead_only_till_china_reverse_engineers/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8i41v/openai_is_ahead_only_till_china_reverse_engineers/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T00:04:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8hqp0</id>
    <title>DeepSeek R1 (reasoner) can use internet there o1 still can't</title>
    <updated>2025-01-23T23:47:38+00:00</updated>
    <author>
      <name>/u/Healthy-Nebula-3603</name>
      <uri>https://old.reddit.com/user/Healthy-Nebula-3603</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8hqp0/deepseek_r1_reasoner_can_use_internet_there_o1/"&gt; &lt;img alt="DeepSeek R1 (reasoner) can use internet there o1 still can't" src="https://b.thumbs.redditmedia.com/NWZ7upEkaFaUDhq-5d7CT7VuzH9PhcF4ym1RrfuBo1M.jpg" title="DeepSeek R1 (reasoner) can use internet there o1 still can't" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Funny ... DeepSeek doing more for free than paid o1...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Healthy-Nebula-3603"&gt; /u/Healthy-Nebula-3603 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1i8hqp0"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8hqp0/deepseek_r1_reasoner_can_use_internet_there_o1/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8hqp0/deepseek_r1_reasoner_can_use_internet_there_o1/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T23:47:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1i87fkl</id>
    <title>Deepseek R1 is the only one that nails this new viral benchmark</title>
    <updated>2025-01-23T16:34:21+00:00</updated>
    <author>
      <name>/u/Charuru</name>
      <uri>https://old.reddit.com/user/Charuru</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i87fkl/deepseek_r1_is_the_only_one_that_nails_this_new/"&gt; &lt;img alt="Deepseek R1 is the only one that nails this new viral benchmark" src="https://external-preview.redd.it/dTNsOXYwcnJ0cmVlMQcGL6cDuoI_ROA8VT0SlOGuG2iHRRkQmxqkRS_k8D6O.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1f916bf51cb83dcc443906e66c7cbbd04f4cf9cc" title="Deepseek R1 is the only one that nails this new viral benchmark" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Charuru"&gt; /u/Charuru &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/4skrezsntree1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i87fkl/deepseek_r1_is_the_only_one_that_nails_this_new/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i87fkl/deepseek_r1_is_the_only_one_that_nails_this_new/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T16:34:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8r0on</id>
    <title>I actually really like the idea of this. It won‚Äôt be long before they can look at your PC on call as well.</title>
    <updated>2025-01-24T08:39:17+00:00</updated>
    <author>
      <name>/u/omnisvosscio</name>
      <uri>https://old.reddit.com/user/omnisvosscio</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8r0on/i_actually_really_like_the_idea_of_this_it_wont/"&gt; &lt;img alt="I actually really like the idea of this. It won‚Äôt be long before they can look at your PC on call as well." src="https://preview.redd.it/3vxre6rklwee1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6ddbef961cfc76e4dbc466509afe79469c4b921c" title="I actually really like the idea of this. It won‚Äôt be long before they can look at your PC on call as well." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/omnisvosscio"&gt; /u/omnisvosscio &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/3vxre6rklwee1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8r0on/i_actually_really_like_the_idea_of_this_it_wont/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8r0on/i_actually_really_like_the_idea_of_this_it_wont/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T08:39:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8srsv</id>
    <title>Simple Open source tool like AI (Apple Intelligence) but completely private / local using Ollama and Kokoro</title>
    <updated>2025-01-24T10:51:58+00:00</updated>
    <author>
      <name>/u/namuan</name>
      <uri>https://old.reddit.com/user/namuan</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8srsv/simple_open_source_tool_like_ai_apple/"&gt; &lt;img alt="Simple Open source tool like AI (Apple Intelligence) but completely private / local using Ollama and Kokoro" src="https://external-preview.redd.it/ZGpreW02NWU5eGVlMaNbrH4VawvqtBNIlI_TN6ZdlIQIRM_6iX5iv_gMzF0s.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6705fa9a9d3760b8b461e07042fb465480bf217a" title="Simple Open source tool like AI (Apple Intelligence) but completely private / local using Ollama and Kokoro" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/namuan"&gt; /u/namuan &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/3lmdx75e9xee1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8srsv/simple_open_source_tool_like_ai_apple/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8srsv/simple_open_source_tool_like_ai_apple/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T10:51:58+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8chpr</id>
    <title>Deepseek-r1-Qwen 1.5B's overthinking is adorable</title>
    <updated>2025-01-23T20:01:44+00:00</updated>
    <author>
      <name>/u/Ill-Still-6859</name>
      <uri>https://old.reddit.com/user/Ill-Still-6859</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8chpr/deepseekr1qwen_15bs_overthinking_is_adorable/"&gt; &lt;img alt="Deepseek-r1-Qwen 1.5B's overthinking is adorable" src="https://external-preview.redd.it/azZ1d2EzZ2x1c2VlMWwcsRUdCKlecN3EYDmX-jmw1aKFL7Ec90KkMpgcpWxW.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9ffd8792fef56427e2ddfd654527bbf426c6fbf8" title="Deepseek-r1-Qwen 1.5B's overthinking is adorable" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Ill-Still-6859"&gt; /u/Ill-Still-6859 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/b5coo5glusee1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8chpr/deepseekr1qwen_15bs_overthinking_is_adorable/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8chpr/deepseekr1qwen_15bs_overthinking_is_adorable/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T20:01:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8vthd</id>
    <title>8xB200 - Fully Idle for the Next Few Weeks - What Should I Run on It?</title>
    <updated>2025-01-24T13:50:52+00:00</updated>
    <author>
      <name>/u/yanjb</name>
      <uri>https://old.reddit.com/user/yanjb</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8vthd/8xb200_fully_idle_for_the_next_few_weeks_what/"&gt; &lt;img alt="8xB200 - Fully Idle for the Next Few Weeks - What Should I Run on It?" src="https://b.thumbs.redditmedia.com/usMRslexXuegsZieGf8Y7gaTQ43rnlxwroSXfMnoOiM.jpg" title="8xB200 - Fully Idle for the Next Few Weeks - What Should I Run on It?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;So we recently got the DGX B200 system, but here‚Äôs the catch: there‚Äôs &lt;em&gt;literally no support&lt;/em&gt; for our use case right now (PyTorch, Exllama, TensorRT). &lt;/p&gt; &lt;p&gt;Feels like owning a rocket ship with no launchpad.&lt;/p&gt; &lt;p&gt;While NVIDIA sorts out firmware and support, I‚Äôve got 8 GPUs just sitting there begging to make some noise. Any suggestions on what I can run in the meantime? Maybe a massive DeepSeek finetune or something cool that could take advantage of this hardware?&lt;/p&gt; &lt;p&gt;Open to any and all creative ideas‚Äîdon‚Äôt let these GPUs stay silent!&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/gnz26t335yee1.png?width=1306&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=85fa0a49b002765d6d6f9fc7335a488c65da153e"&gt;https://preview.redd.it/gnz26t335yee1.png?width=1306&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=85fa0a49b002765d6d6f9fc7335a488c65da153e&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/yanjb"&gt; /u/yanjb &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8vthd/8xb200_fully_idle_for_the_next_few_weeks_what/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8vthd/8xb200_fully_idle_for_the_next_few_weeks_what/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8vthd/8xb200_fully_idle_for_the_next_few_weeks_what/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T13:50:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8a9qb</id>
    <title>Deepmind learning from Deepseek. Power of open source!</title>
    <updated>2025-01-23T18:30:30+00:00</updated>
    <author>
      <name>/u/Charuru</name>
      <uri>https://old.reddit.com/user/Charuru</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8a9qb/deepmind_learning_from_deepseek_power_of_open/"&gt; &lt;img alt="Deepmind learning from Deepseek. Power of open source!" src="https://preview.redd.it/xouhskggesee1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3e2d75d3fe9869f9aa59bf1661a57a8050b9bde4" title="Deepmind learning from Deepseek. Power of open source!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Charuru"&gt; /u/Charuru &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/xouhskggesee1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8a9qb/deepmind_learning_from_deepseek_power_of_open/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8a9qb/deepmind_learning_from_deepseek_power_of_open/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T18:30:30+00:00</published>
  </entry>
  <entry>
    <id>t3_1i80cwf</id>
    <title>deepseek is a side project</title>
    <updated>2025-01-23T10:22:48+00:00</updated>
    <author>
      <name>/u/ParsaKhaz</name>
      <uri>https://old.reddit.com/user/ParsaKhaz</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i80cwf/deepseek_is_a_side_project/"&gt; &lt;img alt="deepseek is a side project" src="https://preview.redd.it/zdvrlxahzpee1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=df808bd8bc2e4ba90db2fdb005eaae092d5d8206" title="deepseek is a side project" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ParsaKhaz"&gt; /u/ParsaKhaz &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/zdvrlxahzpee1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i80cwf/deepseek_is_a_side_project/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i80cwf/deepseek_is_a_side_project/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T10:22:48+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8qmwv</id>
    <title>Economist: "China‚Äôs AI industry has almost caught up with America‚Äôs"</title>
    <updated>2025-01-24T08:09:10+00:00</updated>
    <author>
      <name>/u/mayalihamur</name>
      <uri>https://old.reddit.com/user/mayalihamur</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8qmwv/economist_chinas_ai_industry_has_almost_caught_up/"&gt; &lt;img alt="Economist: &amp;quot;China‚Äôs AI industry has almost caught up with America‚Äôs&amp;quot;" src="https://a.thumbs.redditmedia.com/ZQ8Jd3yNsMvXFQX-vWNUOP50oj7_BpX4CfG1prbLj84.jpg" title="Economist: &amp;quot;China‚Äôs AI industry has almost caught up with America‚Äôs&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;In a recent article, The Economist claims that Chinese AI models are &amp;quot;more open and more effective&amp;quot; and &amp;quot;DeepSeek‚Äôs llm is not only bigger than many of its Western counterparts‚Äîit is also better, matched only by the proprietary models at Google and Openai.&amp;quot;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/ucks1vgggwee1.png?width=360&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=57e7a71f13589a314f53cda9a39bd3ba318ec59b"&gt;https://preview.redd.it/ucks1vgggwee1.png?width=360&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=57e7a71f13589a314f53cda9a39bd3ba318ec59b&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The article goes on to explain how DeepSeek is more effective thanks to a series of improvements, and more open, not only in terms of availability but also of research transparency: &amp;quot;This permissiveness is matched by a remarkable openness: the two companies publish papers whenever they release new models that provide a wealth of detail on the techniques used to improve their performance.&amp;quot;&lt;/p&gt; &lt;p&gt;Worth a read: &lt;a href="https://archive.is/vAop1#selection-1373.91-1373.298"&gt;https://archive.is/vAop1#selection-1373.91-1373.298&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mayalihamur"&gt; /u/mayalihamur &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8qmwv/economist_chinas_ai_industry_has_almost_caught_up/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8qmwv/economist_chinas_ai_industry_has_almost_caught_up/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8qmwv/economist_chinas_ai_industry_has_almost_caught_up/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T08:09:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8mwpc</id>
    <title>Coming soon: 100% Local Video Understanding Engine (an open-source project that can classify, caption, transcribe, and understand any video on your local device)</title>
    <updated>2025-01-24T04:06:24+00:00</updated>
    <author>
      <name>/u/ParsaKhaz</name>
      <uri>https://old.reddit.com/user/ParsaKhaz</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8mwpc/coming_soon_100_local_video_understanding_engine/"&gt; &lt;img alt="Coming soon: 100% Local Video Understanding Engine (an open-source project that can classify, caption, transcribe, and understand any video on your local device)" src="https://external-preview.redd.it/a3BrbTdjZjVzdWVlMe21Biif0sGFU8GTsH3N7D_CJugYvIxsEVZ-nvrUed0U.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e198b50c956615f546356a1784f29f65d0e8c5ea" title="Coming soon: 100% Local Video Understanding Engine (an open-source project that can classify, caption, transcribe, and understand any video on your local device)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ParsaKhaz"&gt; /u/ParsaKhaz &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/v8xdjbf5suee1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8mwpc/coming_soon_100_local_video_understanding_engine/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8mwpc/coming_soon_100_local_video_understanding_engine/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T04:06:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8996r</id>
    <title>I think it's forced. DeepSeek did its best...</title>
    <updated>2025-01-23T17:49:34+00:00</updated>
    <author>
      <name>/u/Alexs1200AD</name>
      <uri>https://old.reddit.com/user/Alexs1200AD</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8996r/i_think_its_forced_deepseek_did_its_best/"&gt; &lt;img alt="I think it's forced. DeepSeek did its best..." src="https://preview.redd.it/b3n1jpj17see1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=55a5ea362bf2cb802996106f2fc698c1f579cfff" title="I think it's forced. DeepSeek did its best..." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Alexs1200AD"&gt; /u/Alexs1200AD &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/b3n1jpj17see1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8996r/i_think_its_forced_deepseek_did_its_best/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8996r/i_think_its_forced_deepseek_did_its_best/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T17:49:34+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8u9jk</id>
    <title>DeepSeek-R1 appears on LMSYS Arena Leaderboard</title>
    <updated>2025-01-24T12:29:12+00:00</updated>
    <author>
      <name>/u/jpydych</name>
      <uri>https://old.reddit.com/user/jpydych</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8u9jk/deepseekr1_appears_on_lmsys_arena_leaderboard/"&gt; &lt;img alt="DeepSeek-R1 appears on LMSYS Arena Leaderboard" src="https://b.thumbs.redditmedia.com/Cbe6Zl-znSiMPkTrr0J7qqua6y3OL0gAQYUhGg_4B2M.jpg" title="DeepSeek-R1 appears on LMSYS Arena Leaderboard" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jpydych"&gt; /u/jpydych &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1i8u9jk"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8u9jk/deepseekr1_appears_on_lmsys_arena_leaderboard/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8u9jk/deepseekr1_appears_on_lmsys_arena_leaderboard/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T12:29:12+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8ifxd</id>
    <title>Ollama is confusing people by pretending that the little distillation models are "R1"</title>
    <updated>2025-01-24T00:20:07+00:00</updated>
    <author>
      <name>/u/blahblahsnahdah</name>
      <uri>https://old.reddit.com/user/blahblahsnahdah</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I was baffled at the number of people who seem to think they're using &amp;quot;R1&amp;quot; when they're actually running a Qwen or Llama finetune, until I saw a screenshot of the Ollama interface earlier. Ollama is misleadingly pretending in their UI and command line that &amp;quot;R1&amp;quot; is a series of differently-sized models and that distillations are just smaller sizes of &amp;quot;R1&amp;quot;. Rather than what they actually are which is some quasi-related experimental finetunes of other models that Deepseek happened to release at the same time.&lt;/p&gt; &lt;p&gt;It's not just annoying, it seems to be doing reputational damage to Deepseek as well, because a lot of low information Ollama users are using a shitty 1.5B model, noticing that it sucks (because it's 1.5B), and saying &amp;quot;wow I don't see why people are saying R1 is so good, this is terrible&amp;quot;. Plus there's misleading social media influencer content like &amp;quot;I got R1 running on my phone!&amp;quot; (no, you got a Qwen-1.5B finetune running on your phone).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/blahblahsnahdah"&gt; /u/blahblahsnahdah &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ifxd/ollama_is_confusing_people_by_pretending_that_the/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ifxd/ollama_is_confusing_people_by_pretending_that_the/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8ifxd/ollama_is_confusing_people_by_pretending_that_the/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T00:20:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1i88g4y</id>
    <title>Meta panicked by Deepseek</title>
    <updated>2025-01-23T17:15:55+00:00</updated>
    <author>
      <name>/u/Optimal_Hamster5789</name>
      <uri>https://old.reddit.com/user/Optimal_Hamster5789</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i88g4y/meta_panicked_by_deepseek/"&gt; &lt;img alt="Meta panicked by Deepseek" src="https://preview.redd.it/ek65oz361see1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fd236f1570226e841c54a41cd8f2a2e7c6328a8c" title="Meta panicked by Deepseek" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Optimal_Hamster5789"&gt; /u/Optimal_Hamster5789 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/ek65oz361see1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i88g4y/meta_panicked_by_deepseek/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i88g4y/meta_panicked_by_deepseek/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-23T17:15:55+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8rujw</id>
    <title>Notes on Deepseek r1: Just how good it is compared to OpenAI o1</title>
    <updated>2025-01-24T09:44:13+00:00</updated>
    <author>
      <name>/u/SunilKumarDash</name>
      <uri>https://old.reddit.com/user/SunilKumarDash</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Finally, there is a model worthy of the hype it has been getting since Claude 3.6 Sonnet. Deepseek has released something anyone hardly expected: a reasoning model on par with OpenAI‚Äôs o1 within a month of the v3 release, with an MIT license and 1/20th of o1‚Äôs cost.&lt;/p&gt; &lt;p&gt;This is easily the best release since GPT-4. It's wild; the general public seems excited about this, while the big AI labs are probably scrambling. It feels like things are about to speed up in the AI world. And it's all thanks to this new DeepSeek-R1 model and how they trained it. &lt;/p&gt; &lt;p&gt;Some key details from the paper&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Pure RL (GRPO) on v3-base to get r1-zero. (No Monte-Carlo Tree Search or Process Reward Modelling)&lt;/li&gt; &lt;li&gt;The model uses ‚ÄúAha moments‚Äù as pivot tokens to reflect and reevaluate answers during CoT.&lt;/li&gt; &lt;li&gt;To overcome r1-zero‚Äôs readability issues, v3 was SFTd on cold start data.&lt;/li&gt; &lt;li&gt;Distillation works, small models like Qwen and Llama trained over r1 generated data show significant improvements.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Here‚Äôs an overall r0 pipeline&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;v3 base + RL (GRPO) ‚Üí r1-zero &lt;/p&gt; &lt;p&gt;r1 training pipeline.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;DeepSeek-V3 Base&lt;/strong&gt; + SFT (Cold Start Data) ‚Üí &lt;strong&gt;Checkpoint 1&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Checkpoint 1&lt;/strong&gt; + RL (GRPO + Language Consistency) ‚Üí &lt;strong&gt;Checkpoint 2&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Checkpoint 2&lt;/strong&gt; used to Generate Data (Rejection Sampling)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;DeepSeek-V3 Base&lt;/strong&gt; + SFT (Generated Data + Other Data) ‚Üí &lt;strong&gt;Checkpoint 3&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Checkpoint 3&lt;/strong&gt; + RL (Reasoning + Preference Rewards) ‚Üí &lt;strong&gt;DeepSeek-R1&lt;/strong&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We know the benchmarks, but just how good is it?&lt;/p&gt; &lt;h1&gt;Deepseek r1 vs OpenAI o1.&lt;/h1&gt; &lt;p&gt;So, for this, I tested r1 and o1 side by side on complex reasoning, math, coding, and creative writing problems. These are the questions that o1 solved only or by none before.&lt;/p&gt; &lt;p&gt;Here‚Äôs what I found:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;For &lt;strong&gt;reasoning&lt;/strong&gt;, it is much better than any previous SOTA model until o1. It is better than o1-preview but a notch below o1. This is also shown in the ARC AGI bench.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Mathematics&lt;/strong&gt;: It's also the same for mathematics; r1 is a killer, but o1 is better.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Coding&lt;/strong&gt;: I didn‚Äôt get to play much, but on first look, it‚Äôs up there with o1, and the fact that it costs 20x less makes it the practical winner.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Writing&lt;/strong&gt;: This is where R1 takes the lead. It gives the same vibes as early Opus. It‚Äôs free, less censored, has much more personality, is easy to steer, and is very creative compared to the rest, even o1-pro.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;What interested me was how free the model sounded and thought traces were, akin to human internal monologue. Perhaps this is because of the less stringent RLHF, unlike US models.&lt;/p&gt; &lt;p&gt;The fact that you can get r1 from v3 via pure RL was the most surprising.&lt;/p&gt; &lt;p&gt;For in-depth analysis, commentary, and remarks on the Deepseek r1, check out this blog post: &lt;a href="https://composio.dev/blog/notes-on-the-new-deepseek-r1/"&gt;Notes on Deepseek r1&lt;/a&gt;&lt;/p&gt; &lt;p&gt;What are your experiences with the new Deepseek r1? Did you find the model useful for your use cases?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/SunilKumarDash"&gt; /u/SunilKumarDash &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8rujw/notes_on_deepseek_r1_just_how_good_it_is_compared/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8rujw/notes_on_deepseek_r1_just_how_good_it_is_compared/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8rujw/notes_on_deepseek_r1_just_how_good_it_is_compared/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T09:44:13+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8tx5z</id>
    <title>I benchmarked (almost) every model that can fit in 24GB VRAM (Qwens, R1 distils, Mistrals, even Llama 70b gguf)</title>
    <updated>2025-01-24T12:08:50+00:00</updated>
    <author>
      <name>/u/kyazoglu</name>
      <uri>https://old.reddit.com/user/kyazoglu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/"&gt; &lt;img alt="I benchmarked (almost) every model that can fit in 24GB VRAM (Qwens, R1 distils, Mistrals, even Llama 70b gguf)" src="https://preview.redd.it/es9l38ezmxee1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6a66f2c3fda0b03915eea1c0a72185b32e17e660" title="I benchmarked (almost) every model that can fit in 24GB VRAM (Qwens, R1 distils, Mistrals, even Llama 70b gguf)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/kyazoglu"&gt; /u/kyazoglu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/es9l38ezmxee1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T12:08:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1i8vclf</id>
    <title>Depseek promises to open source agi</title>
    <updated>2025-01-24T13:27:12+00:00</updated>
    <author>
      <name>/u/Notdesciplined</name>
      <uri>https://old.reddit.com/user/Notdesciplined</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://x.com/victor207755822/status/1882757279436718454"&gt;https://x.com/victor207755822/status/1882757279436718454&lt;/a&gt;&lt;/p&gt; &lt;p&gt;From Deli chen: ‚Äú All I know is we keep pushing forward to make open-source AGI a reality for everyone. ‚Äú&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Notdesciplined"&gt; /u/Notdesciplined &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8vclf/depseek_promises_to_open_source_agi/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1i8vclf/depseek_promises_to_open_source_agi/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1i8vclf/depseek_promises_to_open_source_agi/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-24T13:27:12+00:00</published>
  </entry>
</feed>
