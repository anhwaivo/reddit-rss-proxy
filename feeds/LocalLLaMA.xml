<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-08-06T09:29:51+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss AI &amp; Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1milm9t</id>
    <title>Just wanna say : Kudos to llama cpp our unsung heroes ü´°</title>
    <updated>2025-08-05T21:15:05+00:00</updated>
    <author>
      <name>/u/dreamai87</name>
      <uri>https://old.reddit.com/user/dreamai87</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Kudos to you guys&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/dreamai87"&gt; /u/dreamai87 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milm9t/just_wanna_say_kudos_to_llama_cpp_our_unsung/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milm9t/just_wanna_say_kudos_to_llama_cpp_our_unsung/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1milm9t/just_wanna_say_kudos_to_llama_cpp_our_unsung/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T21:15:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1miqzgb</id>
    <title>Let me fix that chart for you</title>
    <updated>2025-08-06T01:01:50+00:00</updated>
    <author>
      <name>/u/sstainsby</name>
      <uri>https://old.reddit.com/user/sstainsby</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miqzgb/let_me_fix_that_chart_for_you/"&gt; &lt;img alt="Let me fix that chart for you" src="https://preview.redd.it/69scmtwzsahf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=90ff74d87020e05e7f407a73bbc2874a6ef21143" title="Let me fix that chart for you" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Because range matters.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sstainsby"&gt; /u/sstainsby &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/69scmtwzsahf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miqzgb/let_me_fix_that_chart_for_you/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miqzgb/let_me_fix_that_chart_for_you/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T01:01:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1mihfp7</id>
    <title>Am i the only one seeing it this way ?</title>
    <updated>2025-08-05T18:38:06+00:00</updated>
    <author>
      <name>/u/Severe-Awareness829</name>
      <uri>https://old.reddit.com/user/Severe-Awareness829</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mihfp7/am_i_the_only_one_seeing_it_this_way/"&gt; &lt;img alt="Am i the only one seeing it this way ?" src="https://preview.redd.it/e8eauyilw8hf1.jpeg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=bc7e2a6e64c3c38ddae74650deab4d5b10f30cb3" title="Am i the only one seeing it this way ?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Severe-Awareness829"&gt; /u/Severe-Awareness829 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/e8eauyilw8hf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mihfp7/am_i_the_only_one_seeing_it_this_way/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mihfp7/am_i_the_only_one_seeing_it_this_way/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T18:38:06+00:00</published>
  </entry>
  <entry>
    <id>t3_1miqbyk</id>
    <title>The openai gpt-oss model is too safe!</title>
    <updated>2025-08-06T00:31:59+00:00</updated>
    <author>
      <name>/u/sunshinecheung</name>
      <uri>https://old.reddit.com/user/sunshinecheung</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/"&gt; &lt;img alt="The openai gpt-oss model is too safe!" src="https://a.thumbs.redditmedia.com/9AYqrIhNJjW4c44_58a53bBAstFq2WK6RLkfAreEYV8.jpg" title="The openai gpt-oss model is too safe!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b"&gt;https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Every time answering the question, Gpt-oss will check whether it contains disallowed content(explicit/violent/illegal content),and ‚Äùaccording to policy, we must refuse‚Äú.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sunshinecheung"&gt; /u/sunshinecheung &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T00:31:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1miw41b</id>
    <title>rednote-hilab/dots.vlm1.inst</title>
    <updated>2025-08-06T05:20:24+00:00</updated>
    <author>
      <name>/u/jacek2023</name>
      <uri>https://old.reddit.com/user/jacek2023</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miw41b/rednotehilabdotsvlm1inst/"&gt; &lt;img alt="rednote-hilab/dots.vlm1.inst" src="https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=37f493347207fe571e78519d5d47caadcba70841" title="rednote-hilab/dots.vlm1.inst" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;new dots model from rednote:&lt;/p&gt; &lt;p&gt;We are excited to introduce &lt;strong&gt;dots.vlm1&lt;/strong&gt;, the first vision-language model in the dots model family. Built upon a 1.2 billion-parameter vision encoder and the DeepSeek V3 large language model (LLM), &lt;strong&gt;dots.vlm1&lt;/strong&gt; demonstrates strong multimodal understanding and reasoning capabilities.&lt;/p&gt; &lt;p&gt;Through large-scale pretraining and carefully tuned post-training, &lt;strong&gt;dots.vlm1 achieves near state-of-the-art performance in both visual perception and reasoning&lt;/strong&gt;, setting a new performance ceiling for open-source vision-language models‚Äîwhile still maintaining competitive capabilities in pure-text tasks.&lt;/p&gt; &lt;h1&gt;&lt;a href="https://huggingface.co/rednote-hilab/dots.vlm1.inst#model-summary"&gt;&lt;/a&gt;&lt;/h1&gt; &lt;h1&gt;Model Summary&lt;/h1&gt; &lt;p&gt;&lt;strong&gt;This repo contains the instruction-tuned&lt;/strong&gt; &lt;code&gt;dots.vlm1&lt;/code&gt; &lt;strong&gt;model&lt;/strong&gt; which has the following features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Type: A multimodal vision-language model with 1.2B vision encoder and DeepSeek V3 LLM&lt;/li&gt; &lt;li&gt;Training Stages: Vision encoder pretraining, VLM pretraining, and supervised fine-tuning (SFT)&lt;/li&gt; &lt;li&gt;Architecture: NaViT vision encoder + MLP adapter + DeepSeek V3 MoE language model&lt;/li&gt; &lt;li&gt;Vision Encoder: 1.2B parameters, 42 transformer layers with RMSNorm, SwiGLU, and 2D RoPE&lt;/li&gt; &lt;li&gt;Supported Languages: English, Chinese&lt;/li&gt; &lt;li&gt;Context Length: 65,536 tokens&lt;/li&gt; &lt;li&gt;License: MIT&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Model Highlights&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;NaViT Vision Encoder&lt;/strong&gt;: Trained entirely from scratch rather than fine-tuning an existing vision backbone. It natively supports dynamic resolution and incorporates pure visual supervision in addition to traditional text supervision, thereby enhancing the upper bound of perceptual capacity. Beyond image captioning datasets, a large amount of structured image data was introduced during pretraining to improve the model's perceptual capabilities‚Äîparticularly for tasks such as OCR.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multimodal Training Data&lt;/strong&gt;: In addition to conventional approaches, dots.vlm1 leverages a wide range of synthetic data strategies to cover diverse image types (e.g., tables, charts, documents, graphics) and descriptions (e.g., alt text, dense captions, grounding annotations). Furthermore, a strong multimodal model was used to rewrite web page data with interleaved text and images, significantly improving the quality of the training corpus.&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jacek2023"&gt; /u/jacek2023 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/rednote-hilab/dots.vlm1.inst"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miw41b/rednotehilabdotsvlm1inst/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miw41b/rednotehilabdotsvlm1inst/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T05:20:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1mic8kf</id>
    <title>Llama.cpp: Add GPT-OSS</title>
    <updated>2025-08-05T15:25:57+00:00</updated>
    <author>
      <name>/u/atgctg</name>
      <uri>https://old.reddit.com/user/atgctg</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mic8kf/llamacpp_add_gptoss/"&gt; &lt;img alt="Llama.cpp: Add GPT-OSS" src="https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=95a9e3e605eab496c9ba148173f1d7e68a1d7e9f" title="Llama.cpp: Add GPT-OSS" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/atgctg"&gt; /u/atgctg &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/pull/15091"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mic8kf/llamacpp_add_gptoss/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mic8kf/llamacpp_add_gptoss/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T15:25:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1mifuqk</id>
    <title>gpt-oss-120b outperforms DeepSeek-R1-0528 in benchmarks</title>
    <updated>2025-08-05T17:40:56+00:00</updated>
    <author>
      <name>/u/oobabooga4</name>
      <uri>https://old.reddit.com/user/oobabooga4</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Here is a table I put together:&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th&gt;Benchmark&lt;/th&gt; &lt;th&gt;DeepSeek-R1&lt;/th&gt; &lt;th&gt;DeepSeek-R1-0528&lt;/th&gt; &lt;th&gt;GPT-OSS-20B&lt;/th&gt; &lt;th&gt;GPT-OSS-120B&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;GPQA Diamond&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;71.5&lt;/td&gt; &lt;td&gt;81.0&lt;/td&gt; &lt;td&gt;71.5&lt;/td&gt; &lt;td&gt;80.1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Humanity's Last Exam&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;8.5&lt;/td&gt; &lt;td&gt;17.7&lt;/td&gt; &lt;td&gt;17.3&lt;/td&gt; &lt;td&gt;19.0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;AIME 2024&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;79.8&lt;/td&gt; &lt;td&gt;91.4&lt;/td&gt; &lt;td&gt;96.0&lt;/td&gt; &lt;td&gt;96.6&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;AIME 2025&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;70.0&lt;/td&gt; &lt;td&gt;87.5&lt;/td&gt; &lt;td&gt;98.7&lt;/td&gt; &lt;td&gt;97.9&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;57.5&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;69.4&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;70.9&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;73.4&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;based on&lt;/p&gt; &lt;p&gt;&lt;a href="https://openai.com/open-models/"&gt;https://openai.com/open-models/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"&gt;https://huggingface.co/deepseek-ai/DeepSeek-R1-0528&lt;/a&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Here is the table without AIME, as some have pointed out the GPT-OSS benchmarks used tools while the DeepSeek ones did not:&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th&gt;Benchmark&lt;/th&gt; &lt;th&gt;DeepSeek-R1&lt;/th&gt; &lt;th&gt;DeepSeek-R1-0528&lt;/th&gt; &lt;th&gt;GPT-OSS-20B&lt;/th&gt; &lt;th&gt;GPT-OSS-120B&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;GPQA Diamond&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;71.5&lt;/td&gt; &lt;td&gt;81.0&lt;/td&gt; &lt;td&gt;71.5&lt;/td&gt; &lt;td&gt;80.1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Humanity's Last Exam&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;8.5&lt;/td&gt; &lt;td&gt;17.7&lt;/td&gt; &lt;td&gt;17.3&lt;/td&gt; &lt;td&gt;19.0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;40.0&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;49.4&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;44.4&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;49.6&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/oobabooga4"&gt; /u/oobabooga4 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mifuqk/gptoss120b_outperforms_deepseekr10528_in/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mifuqk/gptoss120b_outperforms_deepseekr10528_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mifuqk/gptoss120b_outperforms_deepseekr10528_in/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T17:40:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1midi67</id>
    <title>GPT-OSS today?</title>
    <updated>2025-08-05T16:14:54+00:00</updated>
    <author>
      <name>/u/jacek2023</name>
      <uri>https://old.reddit.com/user/jacek2023</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1midi67/gptoss_today/"&gt; &lt;img alt="GPT-OSS today?" src="https://preview.redd.it/2br9oi8178hf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=20cd517e2220fa7745b9e909a9f4bfcf589d5f03" title="GPT-OSS today?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;because this is almost merged &lt;a href="https://github.com/ggml-org/llama.cpp/pull/15091"&gt;https://github.com/ggml-org/llama.cpp/pull/15091&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jacek2023"&gt; /u/jacek2023 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/2br9oi8178hf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1midi67/gptoss_today/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1midi67/gptoss_today/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T16:14:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1milkqp</id>
    <title>Run gpt-oss locally with Unsloth GGUFs + Fixes!</title>
    <updated>2025-08-05T21:13:26+00:00</updated>
    <author>
      <name>/u/danielhanchen</name>
      <uri>https://old.reddit.com/user/danielhanchen</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/"&gt; &lt;img alt="Run gpt-oss locally with Unsloth GGUFs + Fixes!" src="https://preview.redd.it/6s62jsx2o9hf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d4a03b38836e71df4373dc670859d4fca8398ff1" title="Run gpt-oss locally with Unsloth GGUFs + Fixes!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey guys! You can now run OpenAI's gpt-oss-120b &amp;amp; 20b open models locally with our &lt;a href="https://github.com/unslothai/unsloth"&gt;Unsloth&lt;/a&gt; GGUFs! ü¶•&lt;/p&gt; &lt;p&gt;The uploads includes some of our chat template fixes including casing errors and other fixes. We also reuploaded the quants to facilitate OpenAI's recent change to their chat template and our new fixes.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;20b GGUF: &lt;a href="https://huggingface.co/unsloth/gpt-oss-20b-GGUF"&gt;https://huggingface.co/unsloth/gpt-oss-20b-GGUF&lt;/a&gt;&lt;/li&gt; &lt;li&gt;120b GGUF: &lt;a href="https://huggingface.co/unsloth/gpt-oss-120b-GGUF"&gt;https://huggingface.co/unsloth/gpt-oss-120b-GGUF&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can run both of the models in original precision with the GGUFs. The 120b model fits on 66GB RAM/unified mem &amp;amp; 20b model on 14GB RAM/unified mem. Both will run at &amp;gt;6 token/s. The original model were in f4 but we renamed it to bf16 for easier navigation.&lt;/p&gt; &lt;p&gt;Guide to run model: &lt;a href="https://docs.unsloth.ai/basics/gpt-oss"&gt;https://docs.unsloth.ai/basics/gpt-oss&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;: You must build llama.cpp from source. Update llama.cpp, Ollama, LM Studio etc. to run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \ -hf unsloth/gpt-oss-20b-GGUF:F16 \ --jinja -ngl 99 --threads -1 --ctx-size 16384 \ --temp 0.6 --top-p 1.0 --top-k 0 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or Ollama:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ollama run hf.co/unsloth/gpt-oss-20b-GGUF &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To run the &lt;strong&gt;120B model&lt;/strong&gt; via llama.cpp:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \ --model unsloth/gpt-oss-120b-GGUF/gpt-oss-120b-F16.gguf \ --threads -1 \ --ctx-size 16384 \ --n-gpu-layers 99 \ -ot &amp;quot;.ffn_.*_exps.=CPU&amp;quot; \ --temp 0.6 \ --min-p 0.0 \ --top-p 1.0 \ --top-k 0.0 \ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Thanks for the support guys and happy running. ü•∞&lt;/p&gt; &lt;p&gt;Finetuning support coming soon (likely tomorrow)!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/danielhanchen"&gt; /u/danielhanchen &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/6s62jsx2o9hf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T21:13:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1miv8y4</id>
    <title>WE CAN COMPLY</title>
    <updated>2025-08-06T04:32:04+00:00</updated>
    <author>
      <name>/u/Pro-editor-1105</name>
      <uri>https://old.reddit.com/user/Pro-editor-1105</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miv8y4/we_can_comply/"&gt; &lt;img alt="WE CAN COMPLY" src="https://preview.redd.it/uud2hotmubhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=83f0ba8ed65182bcac75f14c808ee28882456760" title="WE CAN COMPLY" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Pro-editor-1105"&gt; /u/Pro-editor-1105 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/uud2hotmubhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miv8y4/we_can_comply/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miv8y4/we_can_comply/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T04:32:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1milmrl</id>
    <title>OpenAI gpt-oss-120b &amp; 20b EQ-Bench &amp; creative writing results</title>
    <updated>2025-08-05T21:15:36+00:00</updated>
    <author>
      <name>/u/_sqrkl</name>
      <uri>https://old.reddit.com/user/_sqrkl</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/"&gt; &lt;img alt="OpenAI gpt-oss-120b &amp;amp; 20b EQ-Bench &amp;amp; creative writing results" src="https://b.thumbs.redditmedia.com/ddG4iHe_QohGbzMrf1QVWE9bWoVRavxmRobwbx0Do3Y.jpg" title="OpenAI gpt-oss-120b &amp;amp; 20b EQ-Bench &amp;amp; creative writing results" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://eqbench.com/"&gt;https://eqbench.com/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;gpt-oss-120b:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Creative writing&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Longform writing:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;EQ-Bench:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;gpt-oss-20b:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Creative writing&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Longform writing:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;EQ-Bench:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/_sqrkl"&gt; /u/_sqrkl &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1milmrl"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T21:15:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1miotjk</id>
    <title>GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?</title>
    <updated>2025-08-05T23:25:41+00:00</updated>
    <author>
      <name>/u/Different_Fix_2217</name>
      <uri>https://old.reddit.com/user/Different_Fix_2217</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/"&gt; &lt;img alt="GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?" src="https://preview.redd.it/yu8x76wnbahf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c5a7c3a67a52ed6461fbbc4ed074a559a66c3df6" title="GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Another one. &lt;a href="https://simple-bench.com/"&gt;https://simple-bench.com/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Different_Fix_2217"&gt; /u/Different_Fix_2217 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/yu8x76wnbahf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T23:25:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1mieqcb</id>
    <title>openai/gpt-oss-120b ¬∑ Hugging Face</title>
    <updated>2025-08-05T17:00:37+00:00</updated>
    <author>
      <name>/u/ShreckAndDonkey123</name>
      <uri>https://old.reddit.com/user/ShreckAndDonkey123</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/"&gt; &lt;img alt="openai/gpt-oss-120b ¬∑ Hugging Face" src="https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4ae7c659a21f868f6dba51b958c810a90c5bfe24" title="openai/gpt-oss-120b ¬∑ Hugging Face" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ShreckAndDonkey123"&gt; /u/ShreckAndDonkey123 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/openai/gpt-oss-120b"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T17:00:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1minnrb</id>
    <title>Lol this is some next level brain fried from censorship.</title>
    <updated>2025-08-05T22:36:54+00:00</updated>
    <author>
      <name>/u/Different_Fix_2217</name>
      <uri>https://old.reddit.com/user/Different_Fix_2217</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/"&gt; &lt;img alt="Lol this is some next level brain fried from censorship." src="https://preview.redd.it/tcnuqjo63ahf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=043f9f18d071dc3ac979b1c42c6e3c2c762f2319" title="Lol this is some next level brain fried from censorship." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Different_Fix_2217"&gt; /u/Different_Fix_2217 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/tcnuqjo63ahf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T22:36:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1mivbuo</id>
    <title>in other words benchmaxxed</title>
    <updated>2025-08-06T04:36:37+00:00</updated>
    <author>
      <name>/u/mvp525</name>
      <uri>https://old.reddit.com/user/mvp525</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mivbuo/in_other_words_benchmaxxed/"&gt; &lt;img alt="in other words benchmaxxed" src="https://preview.redd.it/i2vavxugvbhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d0659e158cc4f10d87cf14b124dccd590bed50dc" title="in other words benchmaxxed" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mvp525"&gt; /u/mvp525 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/i2vavxugvbhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mivbuo/in_other_words_benchmaxxed/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mivbuo/in_other_words_benchmaxxed/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T04:36:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1miupht</id>
    <title>GPT -OSS is heavily trained on benchmark. scored rank 34 on simplebench worse than grok 2</title>
    <updated>2025-08-06T04:02:50+00:00</updated>
    <author>
      <name>/u/mvp525</name>
      <uri>https://old.reddit.com/user/mvp525</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miupht/gpt_oss_is_heavily_trained_on_benchmark_scored/"&gt; &lt;img alt="GPT -OSS is heavily trained on benchmark. scored rank 34 on simplebench worse than grok 2" src="https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=994e72edd24558bb078da5397d66ecabc0d9a45a" title="GPT -OSS is heavily trained on benchmark. scored rank 34 on simplebench worse than grok 2" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mvp525"&gt; /u/mvp525 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/cbd2wyrfpbhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miupht/gpt_oss_is_heavily_trained_on_benchmark_scored/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miupht/gpt_oss_is_heavily_trained_on_benchmark_scored/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T04:02:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1mix2kg</id>
    <title>Safemaxxed for your safety!</title>
    <updated>2025-08-06T06:17:32+00:00</updated>
    <author>
      <name>/u/Caffdy</name>
      <uri>https://old.reddit.com/user/Caffdy</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mix2kg/safemaxxed_for_your_safety/"&gt; &lt;img alt="Safemaxxed for your safety!" src="https://preview.redd.it/gaqdycledchf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e5a2b32eb53633ee05256ff12a01a15e7ee6f844" title="Safemaxxed for your safety!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Caffdy"&gt; /u/Caffdy &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/gaqdycledchf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mix2kg/safemaxxed_for_your_safety/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mix2kg/safemaxxed_for_your_safety/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T06:17:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1migl0k</id>
    <title>gpt-oss-120b is safetymaxxed (cw: explicit safety)</title>
    <updated>2025-08-05T18:07:05+00:00</updated>
    <author>
      <name>/u/TheLocalDrummer</name>
      <uri>https://old.reddit.com/user/TheLocalDrummer</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheLocalDrummer"&gt; /u/TheLocalDrummer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/o893aealq8hf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1migl0k/gptoss120b_is_safetymaxxed_cw_explicit_safety/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1migl0k/gptoss120b_is_safetymaxxed_cw_explicit_safety/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T18:07:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1migo6d</id>
    <title>I FEEL SO SAFE! THANK YOU SO MUCH OPENAI!</title>
    <updated>2025-08-05T18:10:18+00:00</updated>
    <author>
      <name>/u/Different_Fix_2217</name>
      <uri>https://old.reddit.com/user/Different_Fix_2217</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1migo6d/i_feel_so_safe_thank_you_so_much_openai/"&gt; &lt;img alt="I FEEL SO SAFE! THANK YOU SO MUCH OPENAI!" src="https://preview.redd.it/7e3v67opr8hf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c78bd2d594d80d839e43d136cedfee6e05b2b464" title="I FEEL SO SAFE! THANK YOU SO MUCH OPENAI!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;It also lacks all general knowledge and is terrible at coding compared to the same sized GLM air, what is the use case here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Different_Fix_2217"&gt; /u/Different_Fix_2217 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/7e3v67opr8hf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1migo6d/i_feel_so_safe_thank_you_so_much_openai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1migo6d/i_feel_so_safe_thank_you_so_much_openai/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T18:10:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1miodyp</id>
    <title>GPT-OSS 120B and 20B feel kind of‚Ä¶ bad?</title>
    <updated>2025-08-05T23:07:10+00:00</updated>
    <author>
      <name>/u/SlackEight</name>
      <uri>https://old.reddit.com/user/SlackEight</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;After feeling horribly underwhelmed by these models, the more I look around, the more I‚Äôm noticing reports of excessive censorship, high hallucination rates, and lacklustre performance. &lt;/p&gt; &lt;p&gt;Our company builds character AI systems. After plugging both of these models into our workflows and running our eval sets against them, we are getting some of the worst performance we‚Äôve ever seen in the models we‚Äôve tested (120B performing marginally better than Qwen 3 32B, and both models getting demolished by Llama 4 Maverick, K2, DeepSeek V3, and even GPT 4.1 mini)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/SlackEight"&gt; /u/SlackEight &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T23:07:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1miyix4</id>
    <title>I'm sorry, but I can't provide that... patience - I already have none...</title>
    <updated>2025-08-06T07:49:59+00:00</updated>
    <author>
      <name>/u/Cool-Chemical-5629</name>
      <uri>https://old.reddit.com/user/Cool-Chemical-5629</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miyix4/im_sorry_but_i_cant_provide_that_patience_i/"&gt; &lt;img alt="I'm sorry, but I can't provide that... patience - I already have none..." src="https://preview.redd.it/aufyauketchf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=88ae39d0f21635e24eb2be18f44662947077760e" title="I'm sorry, but I can't provide that... patience - I already have none..." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;That's it. I'm done with this useless piece of trash of a model...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cool-Chemical-5629"&gt; /u/Cool-Chemical-5629 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/aufyauketchf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miyix4/im_sorry_but_i_cant_provide_that_patience_i/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miyix4/im_sorry_but_i_cant_provide_that_patience_i/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T07:49:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1minpqr</id>
    <title>Finally, a model that's SAFE</title>
    <updated>2025-08-05T22:39:10+00:00</updated>
    <author>
      <name>/u/RandumbRedditor1000</name>
      <uri>https://old.reddit.com/user/RandumbRedditor1000</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"&gt; &lt;img alt="Finally, a model that's SAFE" src="https://a.thumbs.redditmedia.com/vPXQi6mxUBYl7zt9fZCD3LWOB6PaZGcjaDHZr2r1u18.jpg" title="Finally, a model that's SAFE" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81"&gt;https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks openai, you're really contributing to the open-source LLM community&lt;/p&gt; &lt;p&gt;I haven't been this blown away by a model since Llama 4!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/RandumbRedditor1000"&gt; /u/RandumbRedditor1000 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T22:39:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1miezct</id>
    <title>üöÄ OpenAI released their open-weight models!!!</title>
    <updated>2025-08-05T17:09:35+00:00</updated>
    <author>
      <name>/u/ResearchCrafty1804</name>
      <uri>https://old.reddit.com/user/ResearchCrafty1804</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miezct/openai_released_their_openweight_models/"&gt; &lt;img alt="üöÄ OpenAI released their open-weight models!!!" src="https://preview.redd.it/1yckal6wg8hf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=dc6b586f5d511d8c0e30969100e707e6e00a1815" title="üöÄ OpenAI released their open-weight models!!!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Welcome to the gpt-oss series, OpenAI‚Äôs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.&lt;/p&gt; &lt;p&gt;We‚Äôre releasing two flavors of the open models:&lt;/p&gt; &lt;p&gt;gpt-oss-120b ‚Äî for production, general purpose, high reasoning use cases that fits into a single H100 GPU (117B parameters with 5.1B active parameters)&lt;/p&gt; &lt;p&gt;gpt-oss-20b ‚Äî for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)&lt;/p&gt; &lt;p&gt;Hugging Face: &lt;a href="https://huggingface.co/openai/gpt-oss-120b"&gt;https://huggingface.co/openai/gpt-oss-120b&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ResearchCrafty1804"&gt; /u/ResearchCrafty1804 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/1yckal6wg8hf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miezct/openai_released_their_openweight_models/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miezct/openai_released_their_openweight_models/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T17:09:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1miwrli</id>
    <title>"What, you don't like your new SOTA model?"</title>
    <updated>2025-08-06T05:59:16+00:00</updated>
    <author>
      <name>/u/Friendly_Willingness</name>
      <uri>https://old.reddit.com/user/Friendly_Willingness</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miwrli/what_you_dont_like_your_new_sota_model/"&gt; &lt;img alt="&amp;quot;What, you don't like your new SOTA model?&amp;quot;" src="https://preview.redd.it/9yqb0l1n9chf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=726e03405370b5eb421009dfc38b1005ddf67ee0" title="&amp;quot;What, you don't like your new SOTA model?&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Friendly_Willingness"&gt; /u/Friendly_Willingness &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/9yqb0l1n9chf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miwrli/what_you_dont_like_your_new_sota_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miwrli/what_you_dont_like_your_new_sota_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T05:59:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1misyvc</id>
    <title>OpenAI, I don't feel SAFE ENOUGH</title>
    <updated>2025-08-06T02:35:22+00:00</updated>
    <author>
      <name>/u/Final_Wheel_7486</name>
      <uri>https://old.reddit.com/user/Final_Wheel_7486</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1misyvc/openai_i_dont_feel_safe_enough/"&gt; &lt;img alt="OpenAI, I don't feel SAFE ENOUGH" src="https://preview.redd.it/af6jm3nt9bhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fb88d869e88cfd2f93a6e76c7ac3ddf342a2db09" title="OpenAI, I don't feel SAFE ENOUGH" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Good timing btw&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Final_Wheel_7486"&gt; /u/Final_Wheel_7486 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/af6jm3nt9bhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1misyvc/openai_i_dont_feel_safe_enough/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1misyvc/openai_i_dont_feel_safe_enough/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T02:35:22+00:00</published>
  </entry>
</feed>
