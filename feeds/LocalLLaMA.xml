<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-03-25T06:40:44+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1jinm8p</id>
    <title>I took your guys advice and made a React Reasoning UI model! It has a new reasoning structure and uses state, for component generation! TESSA-T1 (on Huggingface, from the creator of UIGEN)</title>
    <updated>2025-03-24T10:37:08+00:00</updated>
    <author>
      <name>/u/United-Rush4073</name>
      <uri>https://old.reddit.com/user/United-Rush4073</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jinm8p/i_took_your_guys_advice_and_made_a_react/"&gt; &lt;img alt="I took your guys advice and made a React Reasoning UI model! It has a new reasoning structure and uses state, for component generation! TESSA-T1 (on Huggingface, from the creator of UIGEN)" src="https://external-preview.redd.it/aHhhb2FrcWQ1bXFlMRJZCnWIqpqA-PWEKDHLhCPlKPFJgchtistQtNSdyEex.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=22a548c77157d133a621e7c05b10b3d59179dee1" title="I took your guys advice and made a React Reasoning UI model! It has a new reasoning structure and uses state, for component generation! TESSA-T1 (on Huggingface, from the creator of UIGEN)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey! Thanks to you guys a few weeks ago, my UIGEN models were trending on HF, with over 15k+ downloads. Because of that, I had a lot of very nice people reach out to me, offering free compute and resources. So I was able to make a better model!&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/Tesslate/Tessa-T1-14B"&gt;Tessa-T1-14B&lt;/a&gt; is a reasoning model built on Qwen2.5 Coder. You can find all the size variants here: &lt;a href="https://huggingface.co/collections/Tesslate/tessa-t1-react-reasoning-model-67e0fb72ca23e04473885c0e"&gt;(32B, 14B, 7B, 3B)&lt;/a&gt;. It follows State, useref, useffect and a lot of react libraries like router. In the upcoming weeks I'll be releasing with shadcn. This model can be used in a multi-agent system to generate components or pages and make them work together.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The reasoning comes from a custom finetuned model but is more geared towards UI generation. You can tell this by how it backtracks and thinks about different design principles as the thought process. (Gestalt, etc)&lt;/li&gt; &lt;li&gt;The reasoning bounces between code and not code, and tries its best to check itself before generating.&lt;/li&gt; &lt;li&gt;For those who need it: &lt;a href="https://huggingface.co/Tesslate/Tessa-T1-14B-Q8_0-GGUF"&gt;GGUF&lt;/a&gt;&lt;/li&gt; &lt;li&gt;I had a lot of fun with this model. Just playing around with it and experimenting was really fun and unexpected.&lt;/li&gt; &lt;li&gt;Its very sensitive to temperature and chat template. I recommend the default parameters in LMSTUDIO.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Not just that, I'm also launching an update to &lt;a href="https://huggingface.co/collections/Tesslate/uigen-t15-reasoning-model-67e0fc3605add0af7c427c75"&gt;UIGEN-T1.5&lt;/a&gt;! Its a UI reasoning model that generates html css js tailwind, but I've upgraded the graphics a little bit. (You can check the model card for examples). This is part of my new model training pipeline (which will be available to the public once ready) where I can get data from unstructured sources and use it to create reasoning.&lt;/p&gt; &lt;p&gt;As always, I’d love to hear your feedback and see how you’re using it. Happy experimenting! (real question is can someone make a spinning balls demo on this).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/United-Rush4073"&gt; /u/United-Rush4073 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/idvt1kqd5mqe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jinm8p/i_took_your_guys_advice_and_made_a_react/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jinm8p/i_took_your_guys_advice_and_made_a_react/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T10:37:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiook5</id>
    <title>LLMs on a Steam Deck in Docker</title>
    <updated>2025-03-24T11:45:14+00:00</updated>
    <author>
      <name>/u/Everlier</name>
      <uri>https://old.reddit.com/user/Everlier</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiook5/llms_on_a_steam_deck_in_docker/"&gt; &lt;img alt="LLMs on a Steam Deck in Docker" src="https://external-preview.redd.it/cHhsYnZ6bnVrbXFlMWk0BDd4-QDMiZx1kTrcST9W7IN4hLEz2IEbJGuZDar2.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8c9af1e809a2ed2bd77854137b66776def0b0e69" title="LLMs on a Steam Deck in Docker" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Everlier"&gt; /u/Everlier &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/vdpn00oukmqe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiook5/llms_on_a_steam_deck_in_docker/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiook5/llms_on_a_steam_deck_in_docker/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T11:45:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1jjcqnm</id>
    <title>A riff - My analogy for LLMs</title>
    <updated>2025-03-25T06:04:00+00:00</updated>
    <author>
      <name>/u/tim_Andromeda</name>
      <uri>https://old.reddit.com/user/tim_Andromeda</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Some days LLMs impress me (floor me even), other days they seem like just a neat but flawed party trick. It’s been hard to wrap my head around. But the best analogy I’ve been able to think of is LLMs as a lossy compression of the internet, like a JPEG is to an image. when you zoom in on a JPEG, if you smooth the pixels everything becomes blurry and indistinct, but if you upscale it with an AI algorithm it will become distinct again, but with details that were not in the original data. LLMs, I’ve noticed are very similar. Great for high level concepts but the more you drill down, it’s like zooming in on that JPEG and that’s where the hallucinations lie, LLMs are trying to “upscale” the data for you, but it’s not at all obvious where that border lies between well represented information and hallucination, that is, when are you zooming in too much?&lt;/p&gt; &lt;p&gt;What do you think? Is this a good analogy? Have you had frustrating experiences with hallucinations? Has an LLM done anything that just floored you?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/tim_Andromeda"&gt; /u/tim_Andromeda &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjcqnm/a_riff_my_analogy_for_llms/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjcqnm/a_riff_my_analogy_for_llms/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jjcqnm/a_riff_my_analogy_for_llms/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-25T06:04:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1jig5re</id>
    <title>Meta released a paper last month that seems to have gone under the radar. ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization. This is a better solution than BitNet and means if Meta wanted (for 10% extra compute) they could give us extremely performant 2-bit models.</title>
    <updated>2025-03-24T02:07:26+00:00</updated>
    <author>
      <name>/u/jd_3d</name>
      <uri>https://old.reddit.com/user/jd_3d</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jig5re/meta_released_a_paper_last_month_that_seems_to/"&gt; &lt;img alt="Meta released a paper last month that seems to have gone under the radar. ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization. This is a better solution than BitNet and means if Meta wanted (for 10% extra compute) they could give us extremely performant 2-bit models." src="https://b.thumbs.redditmedia.com/9hRP5bjRzlFUKNIF0QROoq6Vx5TN7YGbabV11IZeJ3M.jpg" title="Meta released a paper last month that seems to have gone under the radar. ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization. This is a better solution than BitNet and means if Meta wanted (for 10% extra compute) they could give us extremely performant 2-bit models." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jd_3d"&gt; /u/jd_3d &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://arxiv.org/pdf/2502.02631"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jig5re/meta_released_a_paper_last_month_that_seems_to/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jig5re/meta_released_a_paper_last_month_that_seems_to/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T02:07:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1jijyx2</id>
    <title>I don't understand what an LLM exactly is anymore</title>
    <updated>2025-03-24T05:57:34+00:00</updated>
    <author>
      <name>/u/surveypoodle</name>
      <uri>https://old.reddit.com/user/surveypoodle</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;About a year ago when LLMs were kind of new, the most intuitive explanation I found was that it is predicting the next word or token, appending that to the input and repeating, and that the prediction itself is based on pretrainedf weights which comes from large amount of texts.&lt;/p&gt; &lt;p&gt;Now I'm seeing audio generation, image generation, image classification, segmentation and all kinds of things also under LLMs so I'm not sure what exactly is going on. Did an LLM suddenly become more generalized?&lt;/p&gt; &lt;p&gt;As an example, [SpatialLM](&lt;a href="https://manycore-research.github.io/SpatialLM/"&gt;https://manycore-research.github.io/SpatialLM/&lt;/a&gt;) says it processes 3D point cloud data and understands 3D scenes. I don't understand what this has anything to do with language models.&lt;/p&gt; &lt;p&gt;Can someone explain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/surveypoodle"&gt; /u/surveypoodle &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jijyx2/i_dont_understand_what_an_llm_exactly_is_anymore/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jijyx2/i_dont_understand_what_an_llm_exactly_is_anymore/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jijyx2/i_dont_understand_what_an_llm_exactly_is_anymore/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T05:57:34+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj28zx</id>
    <title>The legendary thank you letter.</title>
    <updated>2025-03-24T21:18:05+00:00</updated>
    <author>
      <name>/u/Foreign-Beginning-49</name>
      <uri>https://old.reddit.com/user/Foreign-Beginning-49</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Wife jokingly asks me should I use AI to write this thank you letter? I said yeah why not it's a harmless use case. Boilerplate thank you note is created by unnamed LLM(which one doesn't matter in this case) . Letter is sent out. Not expecting anything just a quick little gesture to conference goers. Suddenly wife's inbox blows up &amp;quot;oh my gosh this is the most wonderful thank you letter ever!&amp;quot; Gets shared around. Now folks are asking if they can share for other related events because they just love the way she worded it. I couldn't believe it at first we laughed then kind of felt a little weird about it. It's as if the aggregate training data which produced this small thankyou note hit deep into the neurons of the unsuspecting recipients. AI won here folks. I am all for retaining cognitive and creative sovereignty but when it comes to social boilerplate writing and social algorithms sometimes you gotta just vibe with these inscrutable matrices. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Foreign-Beginning-49"&gt; /u/Foreign-Beginning-49 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj28zx/the_legendary_thank_you_letter/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj28zx/the_legendary_thank_you_letter/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj28zx/the_legendary_thank_you_letter/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T21:18:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj1rcd</id>
    <title>ARC prize v2 launched</title>
    <updated>2025-03-24T20:58:17+00:00</updated>
    <author>
      <name>/u/m_mukhtar</name>
      <uri>https://old.reddit.com/user/m_mukhtar</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://youtu.be/M3b59lZYBW8?si=6663UPsbsvlGUE5e"&gt;https://youtu.be/M3b59lZYBW8?si=6663UPsbsvlGUE5e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;ARC agi challange just released thier new benchmark/test. lets see what &amp;quot;reasoning models&amp;quot; can do with this new test.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/m_mukhtar"&gt; /u/m_mukhtar &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj1rcd/arc_prize_v2_launched/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj1rcd/arc_prize_v2_launched/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj1rcd/arc_prize_v2_launched/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T20:58:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1jipzcb</id>
    <title>$2999 for Digits/Spark competitor from Asus</title>
    <updated>2025-03-24T12:55:25+00:00</updated>
    <author>
      <name>/u/DeltaSqueezer</name>
      <uri>https://old.reddit.com/user/DeltaSqueezer</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jipzcb/2999_for_digitsspark_competitor_from_asus/"&gt; &lt;img alt="$2999 for Digits/Spark competitor from Asus" src="https://external-preview.redd.it/D8QUMe074Ocrow6JjIZEcPidqg0czLoliY1NfSyw9QY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=80b2510d09eaa83e23a59efd002b6c05c8748954" title="$2999 for Digits/Spark competitor from Asus" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DeltaSqueezer"&gt; /u/DeltaSqueezer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.techradar.com/pro/asus-debuts-its-own-mini-ai-supercomputer-ascent-gx10-costs-usd2999-and-comes-with-nvidias-gb10-grace-blackwell-superchip"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jipzcb/2999_for_digitsspark_competitor_from_asus/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jipzcb/2999_for_digitsspark_competitor_from_asus/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T12:55:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj7aqi</id>
    <title>Gemma 3 x P102-100 squad.</title>
    <updated>2025-03-25T00:57:40+00:00</updated>
    <author>
      <name>/u/chitown160</name>
      <uri>https://old.reddit.com/user/chitown160</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj7aqi/gemma_3_x_p102100_squad/"&gt; &lt;img alt="Gemma 3 x P102-100 squad." src="https://preview.redd.it/a5argvrwdqqe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e677ef2f0ebddda34cfe8492a3b2671c8733e6aa" title="Gemma 3 x P102-100 squad." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Thanks to the release of Gemma 3 and browsing TechPowerUp along with informative posts by u/&lt;a href="https://www.reddit.com/user/Boricua-vet/"&gt;Boricua-vet&lt;/a&gt; , &lt;a href="/u/1eyedsnak3"&gt;u/1eyedsnak3&lt;/a&gt; and others , I purchased a discrete gpu(s) for the first time since having an ATI 9800 SE.&lt;/p&gt; &lt;p&gt;I believe this will deliver a cost effective solution for running fine tuned Gemma models (all options for running a fine tuned Gemma model on the cloud seem to be costly compare to an Open AI fine tune endpoint).&lt;/p&gt; &lt;p&gt;I am deciding if I should run them all (undervolted) on a 4 slot X299 or as pairs in ThinkCentre 520s.&lt;/p&gt; &lt;p&gt;Hopefully I can get JAX to run locally with these cards - if anyone has any experience or input using these with JAX, llama.cpp or VLLM please share!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/chitown160"&gt; /u/chitown160 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/a5argvrwdqqe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj7aqi/gemma_3_x_p102100_squad/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj7aqi/gemma_3_x_p102100_squad/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-25T00:57:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1jjblbt</id>
    <title>Implications for local LLM scene if Trump does a full Nvidia ban in China</title>
    <updated>2025-03-25T04:46:12+00:00</updated>
    <author>
      <name>/u/auradragon1</name>
      <uri>https://old.reddit.com/user/auradragon1</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;strong&gt;Edit: Getting downvoted. If you'd like to have interesting discussions here, upvote this post. Otherwise, I will delete this post soon and post it somewhere else.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I think this post should belong here because it's very much related to local LLMs. At this point, Chinese LLMs are by far, the biggest contributors to open source LLMs.&lt;/p&gt; &lt;p&gt;DeepSeek and Qwen, and other Chinese models are getting too good despite not having the latest Nvidia hardware. They have to use gimped Nvidia hopper GPUs with limited bandwidth. Or they're using lesser AI chips from Huawei that wasn't made using the latest TSMC node. Chinese companies have been banned from using TSMC N5, N3, and N2 nodes since late 2024. &lt;/p&gt; &lt;p&gt;I'm certain that Sam Altman, Elon, Bezos, Google founders, Zuckerberg are all lobbying Trump to do a fun Nvidia ban in China. Every single one of them showed up at Trump's inauguration and donated to his fund. This likely means not even gimped Nvidia GPUs can be sold in China. &lt;/p&gt; &lt;p&gt;US big tech companies can't get a high ROI if free/low cost Chinese LLMs are killing their profit margins.&lt;/p&gt; &lt;p&gt;When Deepseek R1 destroyed Nvidia's stock price, it wasn't because people thought the efficiency would lead to less Nvidia demand. No, it'd increase Nvidia demand. Instead, I believe Wall Street was worried that tech bros would lobby Trump to do a fun Nvidia ban in China.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/auradragon1"&gt; /u/auradragon1 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjblbt/implications_for_local_llm_scene_if_trump_does_a/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjblbt/implications_for_local_llm_scene_if_trump_does_a/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jjblbt/implications_for_local_llm_scene_if_trump_does_a/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-25T04:46:12+00:00</published>
  </entry>
  <entry>
    <id>t3_1jivmy8</id>
    <title>Drummer's Fallen Command A 111B v1 - A big, bad, unhinged tune. An evil Behemoth.</title>
    <updated>2025-03-24T16:59:10+00:00</updated>
    <author>
      <name>/u/TheLocalDrummer</name>
      <uri>https://old.reddit.com/user/TheLocalDrummer</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jivmy8/drummers_fallen_command_a_111b_v1_a_big_bad/"&gt; &lt;img alt="Drummer's Fallen Command A 111B v1 - A big, bad, unhinged tune. An evil Behemoth." src="https://external-preview.redd.it/S7UO3mIB4z9Uh8ynqgmYcTGby2xdntT106INn_3Vnao.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8b02dad91218e542d684307711478bfdc58133db" title="Drummer's Fallen Command A 111B v1 - A big, bad, unhinged tune. An evil Behemoth." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheLocalDrummer"&gt; /u/TheLocalDrummer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/TheDrummer/Fallen-Command-A-111B-v1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jivmy8/drummers_fallen_command_a_111b_v1_a_big_bad/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jivmy8/drummers_fallen_command_a_111b_v1_a_big_bad/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T16:59:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiwadm</id>
    <title>Think Tool Boosts Accuracy by 54%! (+ Ollama integration)</title>
    <updated>2025-03-24T17:24:38+00:00</updated>
    <author>
      <name>/u/Straight-Worker-4327</name>
      <uri>https://old.reddit.com/user/Straight-Worker-4327</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Anthropic just dropped a &lt;strong&gt;game-changer&lt;/strong&gt; for AI problem-solving: Claude’s new &lt;em&gt;“think” tool&lt;/em&gt; acts like a mental scratchpad, letting the AI pause mid-task to analyze data, verify policies, and avoid costly mistakes.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Key results from their benchmarks:&lt;/strong&gt;&lt;br /&gt; ✅ &lt;strong&gt;54% accuracy boost&lt;/strong&gt; in airline customer service tasks&lt;br /&gt; ✅ &lt;strong&gt;20%+ consistency gains&lt;/strong&gt; in multi-step workflows&lt;br /&gt; ✅ &lt;strong&gt;State-of-the-art coding performance&lt;/strong&gt; (0.623 SWE-Bench score)&lt;/p&gt; &lt;p&gt;I made a &lt;a href="https://www.youtube.com/watch?v=h_c5nVYFyIE"&gt;&lt;strong&gt;video breakdown&lt;/strong&gt;&lt;/a&gt; showing how it works + &lt;strong&gt;Ollama example code&lt;/strong&gt; to implement the tool. Pro tip: Pair it with domain-specific prompts (like their airline policy examples) for max gains.&lt;/p&gt; &lt;p&gt;Is this &lt;em&gt;actually&lt;/em&gt; a breakthrough, or just hype? 🤔 Early tests show big gains, but I’m curious:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Overkill for simple tasks?&lt;/strong&gt; (Anthropic admits it’s useless for one-shot tool calls)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Anyone benchmarked it locally?&lt;/strong&gt; Share your results—does it really cut errors in complex workflows?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Will OpenAI/others copy this?&lt;/strong&gt; (It’s just a JSON tool def, after all…)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Drop your takes below! 🚀&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Straight-Worker-4327"&gt; /u/Straight-Worker-4327 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiwadm/think_tool_boosts_accuracy_by_54_ollama/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiwadm/think_tool_boosts_accuracy_by_54_ollama/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiwadm/think_tool_boosts_accuracy_by_54_ollama/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T17:24:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1jioxj4</id>
    <title>Announcing TeapotLLM- an open-source ~800M model for hallucination-resistant Q&amp;A and document extraction, running entirely on CPU.</title>
    <updated>2025-03-24T11:59:40+00:00</updated>
    <author>
      <name>/u/zakerytclarke</name>
      <uri>https://old.reddit.com/user/zakerytclarke</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxj4/announcing_teapotllm_an_opensource_800m_model_for/"&gt; &lt;img alt="Announcing TeapotLLM- an open-source ~800M model for hallucination-resistant Q&amp;amp;A and document extraction, running entirely on CPU." src="https://external-preview.redd.it/3n5L3e5awOcQcEl4Nf4qqSOgiuX7eJUHzj2ZLltzndc.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fbd66c6cac4856e8128e418bbe7a6f3172256e6d" title="Announcing TeapotLLM- an open-source ~800M model for hallucination-resistant Q&amp;amp;A and document extraction, running entirely on CPU." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/zakerytclarke"&gt; /u/zakerytclarke &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/teapotai/teapotllm#evaluation"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxj4/announcing_teapotllm_an_opensource_800m_model_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxj4/announcing_teapotllm_an_opensource_800m_model_for/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T11:59:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1jis4yh</id>
    <title>Deepseek V3-0324</title>
    <updated>2025-03-24T14:36:30+00:00</updated>
    <author>
      <name>/u/realJoeTrump</name>
      <uri>https://old.reddit.com/user/realJoeTrump</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jis4yh/deepseek_v30324/"&gt; &lt;img alt="Deepseek V3-0324" src="https://external-preview.redd.it/MzE3eWRta2JmbnFlMZasEx-JuE69Xxg53D-Z6l5VVnhhzxAjpdJ-bz7IYhTK.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a946263616da361fcfb4f21438af02d13fd9bfd3" title="Deepseek V3-0324" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;WTF&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/realJoeTrump"&gt; /u/realJoeTrump &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/19vuv9ibfnqe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jis4yh/deepseek_v30324/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jis4yh/deepseek_v30324/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T14:36:30+00:00</published>
  </entry>
  <entry>
    <id>t3_1jjaall</id>
    <title>One shot website (DeepSeek V3.1)</title>
    <updated>2025-03-25T03:30:57+00:00</updated>
    <author>
      <name>/u/AlgorithmicKing</name>
      <uri>https://old.reddit.com/user/AlgorithmicKing</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjaall/one_shot_website_deepseek_v31/"&gt; &lt;img alt="One shot website (DeepSeek V3.1)" src="https://b.thumbs.redditmedia.com/R6zgrxZkRNRgKaT4490xfHc8TelVjx6-Zdu1BIxxatk.jpg" title="One shot website (DeepSeek V3.1)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://reddit.com/link/1jjaall/video/pn6ffizc9rqe1/player"&gt;https://reddit.com/link/1jjaall/video/pn6ffizc9rqe1/player&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Wanted to compare it to claude 3.7 but....&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/xs17iopf9rqe1.png?width=395&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b49874b1b6362c4ba2ed4e7f8cfaedd6a00d71ae"&gt;https://preview.redd.it/xs17iopf9rqe1.png?width=395&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b49874b1b6362c4ba2ed4e7f8cfaedd6a00d71ae&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Prompt:&lt;/p&gt; &lt;p&gt;create a homepage for a branding agency and make sure to add 100% of your creativity in it (I mean it: particles gradients, glows vfx etc.) in html&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AlgorithmicKing"&gt; /u/AlgorithmicKing &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjaall/one_shot_website_deepseek_v31/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjaall/one_shot_website_deepseek_v31/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jjaall/one_shot_website_deepseek_v31/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-25T03:30:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1jix2g7</id>
    <title>Qwen2.5-VL-32B-Instruct</title>
    <updated>2025-03-24T17:55:23+00:00</updated>
    <author>
      <name>/u/False_Care_2957</name>
      <uri>https://old.reddit.com/user/False_Care_2957</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"&gt; &lt;img alt="Qwen2.5-VL-32B-Instruct" src="https://b.thumbs.redditmedia.com/HcAA8XB1ZhY6C-KimtSV68cNZ3kUOZWKRsZCmScsHpE.jpg" title="Qwen2.5-VL-32B-Instruct" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/u7rpx7v8qoqe1.png?width=3081&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9e723b8f89af8b6dd13d8c3c7f21fe54269ef3a5"&gt;https://preview.redd.it/u7rpx7v8qoqe1.png?width=3081&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9e723b8f89af8b6dd13d8c3c7f21fe54269ef3a5&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Blog: &lt;a href="https://qwenlm.github.io/blog/qwen2.5-vl-32b/"&gt;https://qwenlm.github.io/blog/qwen2.5-vl-32b/&lt;/a&gt;&lt;br /&gt; HF: &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct"&gt;https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/False_Care_2957"&gt; /u/False_Care_2957 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T17:55:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj2yqt</id>
    <title>Deep seek V3 03 24 TESTED. Beats Sonnet &amp; Open AI 4-o</title>
    <updated>2025-03-24T21:47:27+00:00</updated>
    <author>
      <name>/u/Ok-Contribution9043</name>
      <uri>https://old.reddit.com/user/Ok-Contribution9043</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=7U0qKMD5H6A"&gt;https://www.youtube.com/watch?v=7U0qKMD5H6A&lt;/a&gt;&lt;/p&gt; &lt;p&gt;TLDR - beats sonnet and 4-o on a couple of our benchmarks, and meets/comes very close on others.&lt;/p&gt; &lt;p&gt;In general, this is a very strong model and I would not hesitate using it in production. Brilliant work by deep seek here. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Ok-Contribution9043"&gt; /u/Ok-Contribution9043 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj2yqt/deep_seek_v3_03_24_tested_beats_sonnet_open_ai_4o/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj2yqt/deep_seek_v3_03_24_tested_beats_sonnet_open_ai_4o/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj2yqt/deep_seek_v3_03_24_tested_beats_sonnet_open_ai_4o/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T21:47:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiqi81</id>
    <title>New deepseek v3 vs R1 (first is v3)</title>
    <updated>2025-03-24T13:20:54+00:00</updated>
    <author>
      <name>/u/cobalt1137</name>
      <uri>https://old.reddit.com/user/cobalt1137</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiqi81/new_deepseek_v3_vs_r1_first_is_v3/"&gt; &lt;img alt="New deepseek v3 vs R1 (first is v3)" src="https://preview.redd.it/cvnu636y1nqe1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7b35a3e96091f029004e4eb4290e5eae90de578a" title="New deepseek v3 vs R1 (first is v3)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cobalt1137"&gt; /u/cobalt1137 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/cvnu636y1nqe1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiqi81/new_deepseek_v3_vs_r1_first_is_v3/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiqi81/new_deepseek_v3_vs_r1_first_is_v3/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T13:20:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1jisuq4</id>
    <title>DeepSeek V3-0324 has caught up to Sonnet 3.7 in my code creativity benchmark - "Write a raytracer that renders an interesting scene with many colourful lightsources in python."</title>
    <updated>2025-03-24T15:06:11+00:00</updated>
    <author>
      <name>/u/cpldcpu</name>
      <uri>https://old.reddit.com/user/cpldcpu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"&gt; &lt;img alt="DeepSeek V3-0324 has caught up to Sonnet 3.7 in my code creativity benchmark - &amp;quot;Write a raytracer that renders an interesting scene with many colourful lightsources in python.&amp;quot;" src="https://external-preview.redd.it/UVEiW2axvGQT_-A-QrSCYJfIlHr0MZzVYvUIPeOZnEI.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5a8ffe19911392c13473b9c66e3fd7b50efa3454" title="DeepSeek V3-0324 has caught up to Sonnet 3.7 in my code creativity benchmark - &amp;quot;Write a raytracer that renders an interesting scene with many colourful lightsources in python.&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A while ago I set up a code creativity benchmark by asking various LLMs a very simple prompt:&lt;/p&gt; &lt;p&gt;&amp;gt; &lt;code&gt;Write a raytracer that renders an interesting scene with many colourful lightsources in python. Output a 800x600 image as a png&lt;/code&gt;&lt;/p&gt; &lt;p&gt;I only allowed one shot, no iterative prompting to solve broken code. What is interesting is that most LLMs generated code that created a very simple scene with a red, green and blue sphere, often also not aligned properly. Assumingly, the simple RGB example is something that is often represented in pretraining data.&lt;/p&gt; &lt;p&gt;Yet, somehow Sonnet 3.5 and especially Sonnet 3.7 created programs that generated more complex and varied scenes, using nicer colors. At the same time the filesize also increased. Anthropic had found some way to get the model to increase the creativity in coding and create more asthetic outcomes - no idea how to measure this other than looking at the images. (Speculation about how they did it and more ideas how to measure this are welcome in the comments)&lt;/p&gt; &lt;p&gt;Today I tested DeepSeek V3 0324 and it has definitely caught up to 3.7, a huge improvement over V3!&lt;/p&gt; &lt;p&gt;Benchmark data and more information &lt;a href="https://github.com/cpldcpu/llmbenchmark/blob/master/raytracer/Readme.md"&gt;here&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/4nsm9rbaknqe1.png?width=1293&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da86b326644f473a6814fc444b1d4b67a17941ee"&gt;Variance test where every LLM is prompted 4 times&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/9acauhqcknqe1.png?width=1302&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dcbebb2bfb5ce33f53e31e9e1c0facb013a5b9a8"&gt;Summary of all tested LLMs&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cpldcpu"&gt; /u/cpldcpu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T15:06:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj11ls</id>
    <title>Misguided Attention Eval - DeepSeek V3-0324 significantly improved over V3 to become best non-reasoning model</title>
    <updated>2025-03-24T20:29:48+00:00</updated>
    <author>
      <name>/u/cpldcpu</name>
      <uri>https://old.reddit.com/user/cpldcpu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj11ls/misguided_attention_eval_deepseek_v30324/"&gt; &lt;img alt="Misguided Attention Eval - DeepSeek V3-0324 significantly improved over V3 to become best non-reasoning model" src="https://external-preview.redd.it/hCI99i_TREo1DsPSTlaYs3damdb5lZgT6asEOzNq1xk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=36a13f3b4390ccbdfc8cb861939ea3a10c7fb6ed" title="Misguided Attention Eval - DeepSeek V3-0324 significantly improved over V3 to become best non-reasoning model" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;The original DeepSeek V3 did not perform that well on the Misguided Attention eval, however the update scaled up the ranks to be the best non-reasoning model, ahead of Sonnet-3.7 (non-thinking). &lt;/p&gt; &lt;p&gt;It's quite astonishing that it is solving some prompts that were previously only solved by reasoning models (e.g. jugs 4 liters). It seems that V3-0324 has learned to detect reasoning loops and break out of them. This is a capability that also many reasoning models lack. It is not clear whether there has been data contamination or this is a general ability. I will post some examples in the comments.&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/39yfh9f64pqe1.png?width=1205&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=511425a7b173b6bdd87c0473febc3ca1941d47cb"&gt;https://preview.redd.it/39yfh9f64pqe1.png?width=1205&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=511425a7b173b6bdd87c0473febc3ca1941d47cb&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/2421xqtl4pqe1.png?width=4170&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=58c7aec9277a736ccfe4163be86c565c7ab74857"&gt;Darker = higher number of correct responses for that specific prompt.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/cpldcpu/MisguidedAttention"&gt;Misguided Attention&lt;/a&gt; is a collection of prompts to challenge the reasoning abilities of large language models in presence of misguiding information.&lt;/p&gt; &lt;p&gt;Thanks to numerous community contributions I was able to to increase the number of prompts to 52. Thanks a lot to all contributors! More contributions are always valuable to fight saturation of the benchmark.&lt;/p&gt; &lt;p&gt;In addition, I improved the automatic evaluation so that fewer manual interventions ware required.&lt;/p&gt; &lt;p&gt;Below, you can see the first results from the long dataset evaluation - more will be added over time. R1 took the lead here and we can also see the impressive improvement that finetuning llama-3.3 with deepseek traces brought. I expect that o1 would beat r1 based on the results from the small eval. Currently no o1 long eval is planned due to excessive API costs.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cpldcpu"&gt; /u/cpldcpu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj11ls/misguided_attention_eval_deepseek_v30324/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj11ls/misguided_attention_eval_deepseek_v30324/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj11ls/misguided_attention_eval_deepseek_v30324/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T20:29:48+00:00</published>
  </entry>
  <entry>
    <id>t3_1jip611</id>
    <title>Deepseek releases new V3 checkpoint (V3-0324)</title>
    <updated>2025-03-24T12:12:24+00:00</updated>
    <author>
      <name>/u/paf1138</name>
      <uri>https://old.reddit.com/user/paf1138</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jip611/deepseek_releases_new_v3_checkpoint_v30324/"&gt; &lt;img alt="Deepseek releases new V3 checkpoint (V3-0324)" src="https://external-preview.redd.it/L_MDAztp6gi49dQUv9vk2IeXw1OjSoBT_ooENnggvOg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=94d961b0b48a76bd398ef8e9a387f6a5087e577d" title="Deepseek releases new V3 checkpoint (V3-0324)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/paf1138"&gt; /u/paf1138 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jip611/deepseek_releases_new_v3_checkpoint_v30324/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jip611/deepseek_releases_new_v3_checkpoint_v30324/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T12:12:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj9d5c</id>
    <title>Change log of DeepSeek-V3-0324</title>
    <updated>2025-03-25T02:40:34+00:00</updated>
    <author>
      <name>/u/OedoSoldier</name>
      <uri>https://old.reddit.com/user/OedoSoldier</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj9d5c/change_log_of_deepseekv30324/"&gt; &lt;img alt="Change log of DeepSeek-V3-0324" src="https://external-preview.redd.it/AO2sAF0_c_2mBe6UautksfrJRPPX3sFbs0Fu0kPn0C0.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=aa0a8cd368da789c05b75a810cf0a1e21413b8f2" title="Change log of DeepSeek-V3-0324" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/75pe0hzi0rqe1.png?width=1283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=48b2d3b67c5b490814a18c0ab7f6e8a7bba71841"&gt;https://preview.redd.it/75pe0hzi0rqe1.png?width=1283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=48b2d3b67c5b490814a18c0ab7f6e8a7bba71841&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://api-docs.deepseek.com/updates"&gt;https://api-docs.deepseek.com/updates&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/OedoSoldier"&gt; /u/OedoSoldier &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj9d5c/change_log_of_deepseekv30324/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj9d5c/change_log_of_deepseekv30324/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj9d5c/change_log_of_deepseekv30324/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-25T02:40:34+00:00</published>
  </entry>
  <entry>
    <id>t3_1jjalaj</id>
    <title>Deepseek-v3-0324 on Aider</title>
    <updated>2025-03-25T03:47:28+00:00</updated>
    <author>
      <name>/u/Harrycognito</name>
      <uri>https://old.reddit.com/user/Harrycognito</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjalaj/deepseekv30324_on_aider/"&gt; &lt;img alt="Deepseek-v3-0324 on Aider" src="https://preview.redd.it/ssol9q8ecrqe1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=24a68d0ca221d1deace8a0c0efcbb4bc1ad3d0a5" title="Deepseek-v3-0324 on Aider" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Harrycognito"&gt; /u/Harrycognito &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/ssol9q8ecrqe1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jjalaj/deepseekv30324_on_aider/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jjalaj/deepseekv30324_on_aider/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-25T03:47:28+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj3w03</id>
    <title>New DeepSeek benchmark scores</title>
    <updated>2025-03-24T22:25:46+00:00</updated>
    <author>
      <name>/u/Charuru</name>
      <uri>https://old.reddit.com/user/Charuru</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj3w03/new_deepseek_benchmark_scores/"&gt; &lt;img alt="New DeepSeek benchmark scores" src="https://preview.redd.it/smu0dyp3rpqe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a68417184573d77643f9e46e4be7a04e47760398" title="New DeepSeek benchmark scores" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Charuru"&gt; /u/Charuru &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/smu0dyp3rpqe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj3w03/new_deepseek_benchmark_scores/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj3w03/new_deepseek_benchmark_scores/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T22:25:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1jj6i4m</id>
    <title>Deepseek v3</title>
    <updated>2025-03-25T00:19:31+00:00</updated>
    <author>
      <name>/u/TheLogiqueViper</name>
      <uri>https://old.reddit.com/user/TheLogiqueViper</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/"&gt; &lt;img alt="Deepseek v3" src="https://preview.redd.it/xaic503gbqqe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=616bfd3de239ef7db7a2416bc9be3a95051f9c0b" title="Deepseek v3" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheLogiqueViper"&gt; /u/TheLogiqueViper &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/xaic503gbqqe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-25T00:19:31+00:00</published>
  </entry>
</feed>
