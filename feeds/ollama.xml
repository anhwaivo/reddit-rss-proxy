<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/ollama/.rss</id>
  <title>ollama</title>
  <updated>2025-04-12T09:48:43+00:00</updated>
  <link href="https://old.reddit.com/r/ollama/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Atom feed for r/ollama</subtitle>
  <entry>
    <id>t3_1jvbapm</id>
    <title>Hi. I'm new to programming. Can someone tell me which model here is the most powerful model here for deepcoder?</title>
    <updated>2025-04-09T17:20:10+00:00</updated>
    <author>
      <name>/u/Love_of_Mango</name>
      <uri>https://old.reddit.com/user/Love_of_Mango</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1jvbapm/hi_im_new_to_programming_can_someone_tell_me/"&gt; &lt;img alt="Hi. I'm new to programming. Can someone tell me which model here is the most powerful model here for deepcoder?" src="https://preview.redd.it/irzdhpvteute1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ec6cefd630daa8469a49da5200e7b223a0d9871d" title="Hi. I'm new to programming. Can someone tell me which model here is the most powerful model here for deepcoder?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;There are multiple models. The &amp;quot;latest&amp;quot; is 9gb. The 14b is 9gb. But there are others that are 30gb. Can someone let me know which one I need to use that is the latest and the most powerful model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Love_of_Mango"&gt; /u/Love_of_Mango &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/irzdhpvteute1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvbapm/hi_im_new_to_programming_can_someone_tell_me/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jvbapm/hi_im_new_to_programming_can_someone_tell_me/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-09T17:20:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1jvrkes</id>
    <title>New to LLMs – Need Help Setting Up a Q&amp;A System for Onboardin</title>
    <updated>2025-04-10T06:44:57+00:00</updated>
    <author>
      <name>/u/dashgirl21</name>
      <uri>https://old.reddit.com/user/dashgirl21</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have onboarding documents for bringing Photoshop editors onto projects. I’d like to use a language model (LLM) to answer their questions based on those documents. If an answer isn’t available in the documents, I want the question to be redirected to me so I can respond manually. Later, I’d like to feed this new answer back into the LLM so it can learn from it. I'm new to working with LLMs, so I’d really appreciate any suggestions or guidance on how to implement this.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/dashgirl21"&gt; /u/dashgirl21 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvrkes/new_to_llms_need_help_setting_up_a_qa_system_for/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvrkes/new_to_llms_need_help_setting_up_a_qa_system_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jvrkes/new_to_llms_need_help_setting_up_a_qa_system_for/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T06:44:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1jvun07</id>
    <title>Replicating ollama's consistent outputs in vLLM</title>
    <updated>2025-04-10T10:29:26+00:00</updated>
    <author>
      <name>/u/OPlUMMaster</name>
      <uri>https://old.reddit.com/user/OPlUMMaster</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I haven't read through the depths of documentations and the code repo for Ollama. So, don't know if it's already stated or mentioned somewhere.&lt;br /&gt; Is there a way to replicate the outputs that Ollama gives in vLLM? I am facing issues that somewhere the parameters just need to be changed based on the asked task or a lot more in the configuration. But in Ollama almost every time, though with some hallucinations the outputs are consistently good, readable and makes sense. In vLLM I sometimes run into the problem of repetition, verbose or just not good outputs. &lt;/p&gt; &lt;p&gt;So, what can I do that will help me replicate ollama but in vLLM?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/OPlUMMaster"&gt; /u/OPlUMMaster &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvun07/replicating_ollamas_consistent_outputs_in_vllm/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvun07/replicating_ollamas_consistent_outputs_in_vllm/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jvun07/replicating_ollamas_consistent_outputs_in_vllm/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T10:29:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwa33y</id>
    <title>best LLM for my PC ?</title>
    <updated>2025-04-10T22:01:55+00:00</updated>
    <author>
      <name>/u/Mystic-Coyote-28</name>
      <uri>https://old.reddit.com/user/Mystic-Coyote-28</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi, I have a pc with: - intel core i5 144400F CPU - 16GB DDR5-5200 RGB Ram - Nvidia GeForce RTX 4060- 8 GB &lt;/p&gt; &lt;p&gt;I was wondering what's the smartest LLM I can run at a decent speed. I dislike Deepseek-R1, way too verbose. I'm looking for a model that's good at reasoning and coding. &lt;/p&gt; &lt;p&gt;Also would I be able to run something like Stable Diffusion XL on this setup? &lt;/p&gt; &lt;p&gt;Thnx :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Mystic-Coyote-28"&gt; /u/Mystic-Coyote-28 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwa33y/best_llm_for_my_pc/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwa33y/best_llm_for_my_pc/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwa33y/best_llm_for_my_pc/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T22:01:55+00:00</published>
  </entry>
  <entry>
    <id>t3_1jvpgns</id>
    <title>Google releases Agent ADK framework</title>
    <updated>2025-04-10T04:24:24+00:00</updated>
    <author>
      <name>/u/mehul_gupta1997</name>
      <uri>https://old.reddit.com/user/mehul_gupta1997</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Google has launched Agent ADK, which is open-sourced and supports a number of tools, MCP and LLMs for AI agent creation &lt;a href="https://youtu.be/QQcCjKzpF68?si=KQygwExRxKC8-bkI"&gt;https://youtu.be/QQcCjKzpF68?si=KQygwExRxKC8-bkI&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mehul_gupta1997"&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvpgns/google_releases_agent_adk_framework/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvpgns/google_releases_agent_adk_framework/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jvpgns/google_releases_agent_adk_framework/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T04:24:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1jvsw3f</id>
    <title>Just did a deep dive into Google's Agent Development Kit (ADK). Here are some thoughts, nitpicks, and things I loved (unbiased)</title>
    <updated>2025-04-10T08:24:05+00:00</updated>
    <author>
      <name>/u/Any-Cockroach-3233</name>
      <uri>https://old.reddit.com/user/Any-Cockroach-3233</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;ol&gt; &lt;li&gt;The CLI is excellent. adk web, adk run, and api_server make it super smooth to start building and debugging. It feels like a proper developer-first tool. Love this part.&lt;/li&gt; &lt;li&gt;The docs have some unnecessary setup steps—like creating folders manually - that add friction for no real benefit.&lt;/li&gt; &lt;li&gt;Support for multiple model providers is impressive. Not just Gemini, but also GPT-4o, Claude Sonnet, LLaMA, etc, thanks to LiteLLM. Big win for flexibility.&lt;/li&gt; &lt;li&gt;Async agents and conversation management introduce unnecessary complexity. It’s powerful, but the developer experience really suffers here.&lt;/li&gt; &lt;li&gt;Artifact management is a great addition. Being able to store/load files or binary data tied to a session is genuinely useful for building stateful agents.&lt;/li&gt; &lt;li&gt;The different types of agents feel a bit overengineered. LlmAgent works but could’ve stuck to a cleaner interface. Sequential, Parallel, and Loop agents are interesting, but having three separate interfaces instead of a unified workflow concept adds cognitive load. Custom agents are nice in theory, but I’d rather just plug in a Python function.&lt;/li&gt; &lt;li&gt;AgentTool is a standout. Letting one agent use another as a tool is a smart, modular design.&lt;/li&gt; &lt;li&gt;Eval support is there, but again, the DX doesn’t feel intuitive or smooth.&lt;/li&gt; &lt;li&gt;Guardrail callbacks are a great idea, but their implementation is more complex than it needs to be. This could be simplified without losing flexibility.&lt;/li&gt; &lt;li&gt;Session state management is one of the weakest points right now. It’s just not easy to work with.&lt;/li&gt; &lt;li&gt;Deployment options are solid. Being able to deploy via Agent Engine (GCP handles everything) or use Cloud Run (for control over infra) gives developers the right level of control.&lt;/li&gt; &lt;li&gt;Callbacks, in general, feel like a strong foundation for building event-driven agent applications. There’s a lot of potential here.&lt;/li&gt; &lt;li&gt;Minor nitpick: the artifacts documentation currently points to a 404.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Final thoughts&lt;/p&gt; &lt;p&gt;Frameworks like ADK are most valuable when they empower beginners and intermediate developers to build confidently. But right now, the developer experience feels like it's optimized for advanced users only. The ideas are strong, but the complexity and boilerplate may turn away the very people who’d benefit most. A bit of DX polish could make ADK the go-to framework for building agentic apps at scale.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any-Cockroach-3233"&gt; /u/Any-Cockroach-3233 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvsw3f/just_did_a_deep_dive_into_googles_agent/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jvsw3f/just_did_a_deep_dive_into_googles_agent/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jvsw3f/just_did_a_deep_dive_into_googles_agent/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T08:24:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwdnvb</id>
    <title>Find the missing number</title>
    <updated>2025-04-11T00:55:52+00:00</updated>
    <author>
      <name>/u/CalendarSpecific1088</name>
      <uri>https://old.reddit.com/user/CalendarSpecific1088</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am just starting out on learning about LLMs. I had a question. Here's the bash script I'm running:&lt;/p&gt; &lt;p&gt;&lt;code&gt;ollama list | grep -v NAME | cut -f 1 -d ':' | uniq |while read llm; do echo &amp;quot;$llm&amp;quot;; seq 1 19999 | sed 's/19997//' | sort -r | ollama run $llm &amp;quot;In the provided random ly ordered sequence, what's the missing number?&amp;quot;; done&lt;/code&gt;&lt;/p&gt; &lt;p&gt;.. not one LLM I've tested (granted, somewhat short list) gets it right. I could use either A) A pointer at a model that can perform this kind of test correctly, or B) a better understanding of why I can't arrive at the answer? Thanks in advance!!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/CalendarSpecific1088"&gt; /u/CalendarSpecific1088 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwdnvb/find_the_missing_number/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwdnvb/find_the_missing_number/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwdnvb/find_the_missing_number/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T00:55:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1jw6s0f</id>
    <title>Rails have arrived!</title>
    <updated>2025-04-10T19:41:41+00:00</updated>
    <author>
      <name>/u/Any_Praline_8178</name>
      <uri>https://old.reddit.com/user/Any_Praline_8178</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1jw6s0f/rails_have_arrived/"&gt; &lt;img alt="Rails have arrived!" src="https://preview.redd.it/nr3jrv891ute1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=023d4f9b7c49f79dde46248cc3f25167f3a38122" title="Rails have arrived!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any_Praline_8178"&gt; /u/Any_Praline_8178 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/nr3jrv891ute1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jw6s0f/rails_have_arrived/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jw6s0f/rails_have_arrived/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T19:41:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwcnd8</id>
    <title>Jarvis for Windows</title>
    <updated>2025-04-11T00:03:19+00:00</updated>
    <author>
      <name>/u/macmac4201</name>
      <uri>https://old.reddit.com/user/macmac4201</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Is there any way i can use ollama to control windows? I wanna use my voice for commands like &amp;quot;open discord&amp;quot;, &amp;quot;check for windows updates&amp;quot;, or &amp;quot;turn off first display&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/macmac4201"&gt; /u/macmac4201 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwcnd8/jarvis_for_windows/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwcnd8/jarvis_for_windows/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwcnd8/jarvis_for_windows/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T00:03:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwhf21</id>
    <title>Build new image from local ollama</title>
    <updated>2025-04-11T04:20:35+00:00</updated>
    <author>
      <name>/u/LynaXia0</name>
      <uri>https://old.reddit.com/user/LynaXia0</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hello community.&lt;/p&gt; &lt;p&gt;Currently I have a configured ollama with few models already downloaded locally as part of an initial development.&lt;/p&gt; &lt;p&gt;I want to dockerize this to a new ollama image since pulling new image would require re-setup the whole downloaded models, environment variables and so on. &lt;/p&gt; &lt;p&gt;Is it possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/LynaXia0"&gt; /u/LynaXia0 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwhf21/build_new_image_from_local_ollama/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwhf21/build_new_image_from_local_ollama/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwhf21/build_new_image_from_local_ollama/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T04:20:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1jw8olt</id>
    <title>A ⚡️ fast function calling LLM that can chat. Plug in your tools and it accurately gathers information from users before making function calls.</title>
    <updated>2025-04-10T21:00:55+00:00</updated>
    <author>
      <name>/u/AdditionalWeb107</name>
      <uri>https://old.reddit.com/user/AdditionalWeb107</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1jw8olt/a_fast_function_calling_llm_that_can_chat_plug_in/"&gt; &lt;img alt="A ⚡️ fast function calling LLM that can chat. Plug in your tools and it accurately gathers information from users before making function calls." src="https://external-preview.redd.it/bzE5c3dydGNuMnVlMackKEA0spRC5MKdm_uUOg-DK6PAa_0DkYFqanGkTqRz.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=023703a9c31428e499cfa47041f3a66531374520" title="A ⚡️ fast function calling LLM that can chat. Plug in your tools and it accurately gathers information from users before making function calls." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Excited to have recently released &lt;a href="https://huggingface.co/katanemo/Arch-Function-Chat-3B"&gt;Arch-Function-Chat&lt;/a&gt; A collection of fast, device friendly LLMs that achieve performance on-par with GPT-4 on function calling, now trained to chat. Why chat? To help gather accurate information from the user before triggering a tools call (manage context, handle progressive disclosure, and also respond to users in lightweight dialogue on execution of tools results).&lt;/p&gt; &lt;p&gt;The model is out on HF, and the work to integrate it in &lt;a href="https://github.com/katanemo/archgw"&gt;https://github.com/katanemo/archgw&lt;/a&gt; should be completed by Monday - we are also adding to support to integrate with tools definitions as captured via MCP in the upcoming week, so combining two releases in one. Happy building 🙏&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AdditionalWeb107"&gt; /u/AdditionalWeb107 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/atdhyrtcn2ue1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jw8olt/a_fast_function_calling_llm_that_can_chat_plug_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jw8olt/a_fast_function_calling_llm_that_can_chat_plug_in/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T21:00:55+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwkf5a</id>
    <title>Ollama not using GPU, need help.</title>
    <updated>2025-04-11T07:47:44+00:00</updated>
    <author>
      <name>/u/StarWingOwl</name>
      <uri>https://old.reddit.com/user/StarWingOwl</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;So I've been running models locally on my 7900GRE machine, and they were working fine, so I decided to try getting small models working on my laptop (which is pretty old). I updated my CUDA drivers, and my graphics drivers. I installed ollama and gemma3:4b because I only have 4GB VRAM, and it should fit, but it was only running on my CPU and integrated graphics (the GPU utilization in the nvidia control panel wasn't spiking), so I tried the 1b model, and even that didn't use my GPU. I tried disabling the integrated graphics, and it ran even slower, so I knew that it was using that at least, but I don't know why it's not using my GPU. any idea what I can do? should I try running the linux ollama through wsl2 or something? Is this even possible?&lt;br /&gt; For context the laptop specs are : CPU-intel xeon E3 v5, GPU-Nvidia Quadro M2200, 64GB RAM.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/StarWingOwl"&gt; /u/StarWingOwl &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwkf5a/ollama_not_using_gpu_need_help/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwkf5a/ollama_not_using_gpu_need_help/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwkf5a/ollama_not_using_gpu_need_help/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T07:47:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1jx08x3</id>
    <title>Here are my unbiased thoughts about Firebase Studio</title>
    <updated>2025-04-11T20:49:34+00:00</updated>
    <author>
      <name>/u/Any-Cockroach-3233</name>
      <uri>https://old.reddit.com/user/Any-Cockroach-3233</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Just tested out Firebase Studio, a cloud-based AI development environment, by building Flappy Bird.&lt;/p&gt; &lt;p&gt;If you are interested in watching the video then it's in the comments&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I wasn't able to generate the game with zero-shot prompting. Faced multiple errors but was able to resolve them&lt;/li&gt; &lt;li&gt;The code generation was very fast&lt;/li&gt; &lt;li&gt;I liked the VS Code themed IDE, where I can code&lt;/li&gt; &lt;li&gt;I would have liked the option to test the responsiveness of the application on the studio UI itself&lt;/li&gt; &lt;li&gt;The results were decent and might need more manual work to improve the quality of the output&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What are your thoughts on Firebase Studio?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any-Cockroach-3233"&gt; /u/Any-Cockroach-3233 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx08x3/here_are_my_unbiased_thoughts_about_firebase/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx08x3/here_are_my_unbiased_thoughts_about_firebase/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jx08x3/here_are_my_unbiased_thoughts_about_firebase/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T20:49:34+00:00</published>
  </entry>
  <entry>
    <id>t3_1jw1pfm</id>
    <title>Tried a new model but I misspelled strawberry, then this happened.</title>
    <updated>2025-04-10T16:11:28+00:00</updated>
    <author>
      <name>/u/tahaan</name>
      <uri>https://old.reddit.com/user/tahaan</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;me@fedora ~&amp;gt; ollama run deepcoder&lt;br /&gt; pulling manifest &lt;br /&gt; pulling a814bd1f5db7... 100% ▕████████████████████████████████████████████████████████████████████████▏ 9.0 GB &lt;br /&gt; pulling 369ca498f347... 100% ▕████████████████████████████████████████████████████████████████████████▏ 387 B &lt;br /&gt; pulling 834c38322a81... 100% ▕████████████████████████████████████████████████████████████████████████▏ 1.1 KB &lt;br /&gt; pulling ceaa5f78afb8... 100% ▕████████████████████████████████████████████████████████████████████████▏ 33 B &lt;br /&gt; pulling 99307daad14c... 100% ▕████████████████████████████████████████████████████████████████████████▏ 488 B &lt;br /&gt; verifying sha256 digest &lt;br /&gt; writing manifest &lt;br /&gt; success &lt;br /&gt; &amp;gt;&amp;gt;&amp;gt; How many Rs in straberry?&lt;br /&gt; &amp;lt;think&amp;gt;&lt;br /&gt; Okay, so I'm trying to figure out how many &amp;quot;Rs&amp;quot; are in the word &amp;quot;strawberry.&amp;quot; Wait, no, actually, the user wrote &amp;quot;straberry.&amp;quot; Hmm, &lt;br /&gt; that's a typo. The correct spelling is &amp;quot;strawberry,&amp;quot; but maybe they meant &amp;quot;strawberry&amp;quot; and just mistyped it as &amp;quot;straberry.&amp;quot; I'll &lt;br /&gt; proceed with &amp;quot;strawberry&amp;quot; because that's the right word. &lt;/p&gt; &lt;p&gt;Alright, so first step: write down the word. Let me spell it out to visualize each letter. S-T-R-A-W-B-E-R-R-Y. Wait, no, that's &lt;br /&gt; not quite right. The correct spelling is S-T-R-A-W-B-E-R-R-Y? No, wait again. Actually, &amp;quot;strawberry&amp;quot; has two R's and two B's? Or &lt;br /&gt; is it one R? Let me make sure. &lt;/p&gt; &lt;p&gt;Wait, I think I'm mixing up the letters. Let's break it down letter by letter: S-T-R-A-W-B-E-R-R-Y. Wait, no, that can't be right &lt;br /&gt; because &amp;quot;strawberry&amp;quot; doesn't have a double R. It should be S-T-R-A-W-B-E-R-R-Y? No, wait, I'm getting confused. &lt;/p&gt; &lt;p&gt;Wait, maybe it's better to just write the word out and count each letter carefully. Let me do that. &lt;/p&gt; &lt;p&gt;The correct spelling is S-T-R-A-W-B-E-R-R-Y? Wait no, &amp;quot;strawberry&amp;quot; is spelled as S-T-R-A-W-B-E-R-R-Y? No, wait again. I'm getting &lt;br /&gt; myself confused because sometimes I mix up letters when trying to spell quickly. &lt;/p&gt; &lt;p&gt;Wait, let's think about it phonetically. &amp;quot;Straw&amp;quot; is S-T-R-A-W, and &amp;quot;berry&amp;quot; is B-E-R-R-Y. So putting them together as &amp;quot;strawberry,&amp;quot; &lt;br /&gt; the spelling would be S-T-R-A-W-B-E-R-R-Y? Wait no, that can't be right because &amp;quot;strawberry&amp;quot; doesn't have two R's. Let me check. &lt;/p&gt; &lt;p&gt;Wait, I'm overcomplicating this. The correct spelling is S-T-R-A-W-B-E-R-R-Y? No, wait, no. It's actually S-T-R-A-W-B-E-R-R-Y? &lt;br /&gt; Wait, that can't be right because &amp;quot;strawberry&amp;quot; only has one R. Let me just write it out correctly. &lt;/p&gt; &lt;p&gt;S-T-R-A-W-B-E-R-R-Y? No, that would be too many letters. The correct spelling is S-T-R-A-W-B-E-R-R-Y? Wait, no. I'm getting stuck &lt;br /&gt; here. &lt;/p&gt; &lt;p&gt;Wait, maybe I should look up the correct spelling to avoid confusion. But since this is a thought process simulation, I'll proceed &lt;br /&gt; as if I'm figuring it out without external help. &lt;/p&gt; &lt;p&gt;So, &amp;quot;straw&amp;quot; is S-T-R-A-W and &amp;quot;berry&amp;quot; is B-E-R-R-Y. So combined, it's S-T-R-A-W-B-E-R-R-Y? Wait, that would make the word &lt;br /&gt; &amp;quot;strawbery,&amp;quot; which isn't correct. The correct spelling must be S-T-R-A-W-B-E-R-R-Y? No, no. Maybe I'm missing something. &lt;/p&gt; &lt;p&gt;Wait a minute, maybe &amp;quot;strawberry&amp;quot; is spelled as S-T-R-A-W-B-E-R-R-Y, but that seems too long. Let me count the letters: S (1), T &lt;br /&gt; (2), R (3), A (4), W (5), B (6), E (7), R (8), R (9), Y (10). Wait, no, &amp;quot;strawberry&amp;quot; doesn't have 10 letters. It should be fewer. &lt;/p&gt; &lt;p&gt;Wait, I'm making a mistake here. Let me try again. S-T-R-A-W-B-E-R-R-Y is actually incorrect because the correct spelling is &lt;br /&gt; &amp;quot;strawberry,&amp;quot; which has one R and two B's? No, wait, no. &amp;quot;Strawberry&amp;quot; has an R after the W and before the E. &lt;/p&gt; &lt;p&gt;Wait, I'm getting myself confused. Maybe it's better to write it as S-T-R-A-W-B-E-R-R-Y but that seems off. Alternatively, maybe &lt;br /&gt; it's S-T-R-A-W-B-E-R-Y? No, that would be &amp;quot;strawbery,&amp;quot; which isn't right either. &lt;/p&gt; &lt;p&gt;I think the correct spelling is S-T-R-A-W-B-E-R-R-Y, but I'm not sure. Wait, no, &amp;quot;strawberry&amp;quot; has one R after the W and then &lt;br /&gt; another R before Y? Or is it just one R? &lt;/p&gt; &lt;p&gt;Wait, perhaps I should think about the pronunciation. &amp;quot;Strawberry&amp;quot; sounds like it has a single R somewhere. Let me try writing it: &lt;br /&gt; S-T-R-A-W-B-E-R-Y. Yes, that seems right. So letters are S (1), T (2), R (3), A (4), W (5), B (6), E (7), R (8), Y (9). Wait, so &lt;br /&gt; there's two R's? Or is it one? &lt;/p&gt; &lt;p&gt;Wait no, &amp;quot;strawberry&amp;quot; has an R after the W and then another R before Y. So that would be two R's. But I'm not sure because &lt;br /&gt; sometimes people might mispronounce it. &lt;/p&gt; &lt;p&gt;Alternatively, maybe I'm overcomplicating. The user wrote &amp;quot;straberry,&amp;quot; which is a typo for &amp;quot;strawberry.&amp;quot; So focusing on &lt;br /&gt; &amp;quot;strawberry,&amp;quot; how many R's does it have? &lt;/p&gt; &lt;p&gt;Wait, no, &amp;quot;strawberry&amp;quot; has two R's? Or one? Let me think about the word: S-T-R-A-W-B-E-R-R-Y? No, that can't be right because I &lt;br /&gt; don't recall &amp;quot;strawberry&amp;quot; having double R's. It should be S-T-R-A-W-B-E-R-Y, which would have only one R. &lt;/p&gt; &lt;p&gt;Wait, but when you say &amp;quot;strawberry,&amp;quot; you pronounce it with a single R sound after the W and before the E. So that would mean &lt;br /&gt; there's only one R in the spelling. &lt;/p&gt; &lt;p&gt;Wait, no. Let me get this straight: S-T-R-A-W-B-E-R-R-Y? No, I think the correct spelling is &amp;quot;strawberry&amp;quot; with one R. Wait, no, &lt;br /&gt; actually, it's spelled with two L's or something else? &lt;/p&gt; &lt;p&gt;No, wait, no. The confusion might be between &amp;quot;straw&amp;quot; and &amp;quot;strawberry.&amp;quot; &amp;quot;Straw&amp;quot; is S-T-R-A-W, and &amp;quot;strawberry&amp;quot; adds the &amp;quot;berry&amp;quot; &lt;br /&gt; part, which is B-E-R-R-Y. So combining them, it would be S-T-R-A-W-B-E-R-R-Y? But that seems too long. &lt;/p&gt; &lt;p&gt;Wait, no, maybe it's S-T-R-A-W-B-E-R-R-Y, but actually, I think the correct spelling is &amp;quot;strawberry&amp;quot; with one R after the W and &lt;br /&gt; another R before Y. So two R's in total. &lt;/p&gt; &lt;p&gt;But wait, when I write it out: S-T-R-A-W-B-E-R-R-Y, that would be 10 letters, which seems excessive. Maybe I'm missing something. &lt;br /&gt; Let me count again. &lt;/p&gt; &lt;p&gt;Wait, no, &amp;quot;strawberry&amp;quot; is spelled with one R. Wait, actually, no. The correct spelling is S-T-R-A-W-B-E-R-R-Y? No, I think it's &lt;br /&gt; S-T-R-A-W-B-E-R-R-Y, but that can't be right because &amp;quot;strawberry&amp;quot; only has nine letters. &lt;/p&gt; &lt;p&gt;Wait, perhaps the confusion comes from the fact that &amp;quot;straw&amp;quot; ends with W and &amp;quot;berry&amp;quot; starts with B. So when combined, it's &lt;br /&gt; S-T-R-A-W-B-E-R-R-Y? No, I'm getting myself stuck here. &lt;/p&gt; &lt;p&gt;Maybe a better approach is to write out each letter step by step: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;S&lt;br /&gt;&lt;/li&gt; &lt;li&gt;T&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;A&lt;br /&gt;&lt;/li&gt; &lt;li&gt;W&lt;br /&gt;&lt;/li&gt; &lt;li&gt;B&lt;br /&gt;&lt;/li&gt; &lt;li&gt;E&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;Y&lt;br /&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Wait, that's 10 letters with two R's at positions 8 and 9. But I don't think &amp;quot;strawberry&amp;quot; is spelled like that. Maybe it's &lt;br /&gt; S-T-R-A-W-B-E-R-Y, which would be nine letters with one R. &lt;/p&gt; &lt;p&gt;I'm getting confused here. Let me try a different approach. The word &amp;quot;strawberry&amp;quot; can be broken down into &amp;quot;straw&amp;quot; + &amp;quot;berry.&amp;quot; &lt;br /&gt; &amp;quot;Straw&amp;quot; is S-T-R-A-W, and &amp;quot;berry&amp;quot; is B-E-R-R-Y. So combining them would give S-T-R-A-W-B-E-R-R-Y, which has two R's. &lt;/p&gt; &lt;p&gt;Wait, but I think the correct spelling of &amp;quot;strawberry&amp;quot; only has one R in the middle. Maybe it's S-T-R-A-W-B-E-R-Y? That way, &lt;br /&gt; there's only one R after the W and before the E. &lt;/p&gt; &lt;p&gt;But when I look at it that way, I'm not sure if that's correct. Alternatively, perhaps &amp;quot;strawberry&amp;quot; is spelled with two R's: one &lt;br /&gt; in &amp;quot;straw&amp;quot; and another in &amp;quot;berry.&amp;quot; But &amp;quot;straw&amp;quot; doesn't have an R; it's S-T-R-A-W, so the R is part of &amp;quot;straw,&amp;quot; and then &amp;quot;berry&amp;quot; &lt;br /&gt; has a double R? Wait no, &amp;quot;berry&amp;quot; is B-E-R-R-Y, which does have two R's. &lt;/p&gt; &lt;p&gt;Wait, but when you combine them, it's S-T-R-A-W-B-E-R-R-Y. So that would make the entire word &amp;quot;strawbery,&amp;quot; which isn't right. The &lt;br /&gt; correct spelling must be &amp;quot;strawberry,&amp;quot; which I think has one R after the W and then another R in &amp;quot;berry.&amp;quot; Wait, no, &amp;quot;berry&amp;quot; is &lt;br /&gt; spelled with two R's: B-E-R-R-Y. &lt;/p&gt; &lt;p&gt;So putting it all together, &amp;quot;strawberry&amp;quot; would have the R from &amp;quot;straw&amp;quot; (position 3) and the two R's from &amp;quot;berry,&amp;quot; making a total &lt;br /&gt; of three R's? No, that can't be right because I don't think the word is spelled that way. &lt;/p&gt; &lt;p&gt;Wait no, maybe I'm overcomplicating. Let me just write out the correct spelling: S-T-R-A-W-B-E-R-R-Y. Wait, but that would mean &lt;br /&gt; &amp;quot;straw&amp;quot; plus &amp;quot;berry,&amp;quot; which would have two R's in total: one from &amp;quot;straw&amp;quot; and two from &amp;quot;berry.&amp;quot; But no, &amp;quot;straw&amp;quot; doesn't have an R; &lt;br /&gt; it's S-T-R-A-W, so the R is part of &amp;quot;straw.&amp;quot; &lt;/p&gt; &lt;p&gt;Wait, I'm getting myself confused. Let me just look up the correct spelling to clarify. &lt;/p&gt; &lt;p&gt;Upon checking, &amp;quot;strawberry&amp;quot; is spelled with one R in the middle: S-T-R-A-W-B-E-R-R-Y? No, wait, no. The correct spelling is &lt;br /&gt; S-T-R-A-W-B-E-R-R-Y? Wait, no, that's not right. Actually, the correct spelling is &amp;quot;strawberry,&amp;quot; which has two R's: one after the &lt;br /&gt; W and another in the &amp;quot;berry&amp;quot; part. &lt;/p&gt; &lt;p&gt;Wait, but I think it's spelled with only one R in the middle. Let me see: &lt;/p&gt; &lt;p&gt;S-T-R-A-W-B-E-R-R-Y would be 10 letters, but I don't think that's correct. The actual spelling is S-T-R-A-W-B-E-R-R-Y? No, wait, &lt;br /&gt; no. It's actually &amp;quot;strawberry&amp;quot; with one R: S-T-R-A-W-B-E-R-Y. &lt;/p&gt; &lt;p&gt;Wait, no, that doesn't sound right. When you say &amp;quot;strawberry,&amp;quot; you can hear two R sounds: one after the W and another in &amp;quot;berry.&amp;quot; &lt;br /&gt; So perhaps it's spelled with two R's. &lt;/p&gt; &lt;p&gt;But when I write it out, &amp;quot;strawberry&amp;quot; is S-T-R-A-W-B-E-R-R-Y? No, that seems too long. Wait, no, &amp;quot;strawberry&amp;quot; is spelled as &lt;br /&gt; S-T-R-A-W-B-E-R-R-Y, but that would be incorrect because the correct spelling only has one R in the middle. &lt;/p&gt; &lt;p&gt;Wait, I'm really confused now. Maybe a better way is to count the letters: &lt;/p&gt; &lt;p&gt;S (1)&lt;br /&gt; T (2)&lt;br /&gt; R (3)&lt;br /&gt; A (4)&lt;br /&gt; W (5)&lt;br /&gt; B (6)&lt;br /&gt; E (7)&lt;br /&gt; R (8)&lt;br /&gt; Y (9) &lt;/p&gt; &lt;p&gt;So that's nine letters with one R at position 8. &lt;/p&gt; &lt;p&gt;Wait, but then where does the second R come in? Maybe I'm missing something. Alternatively, perhaps &amp;quot;strawberry&amp;quot; is spelled &lt;br /&gt; S-T-R-A-W-B-E-R-Y, which only has one R. &lt;/p&gt; &lt;p&gt;But when you say it, you can hear two R sounds: one after the W and another in &amp;quot;berry.&amp;quot; So maybe the spelling reflects that with &lt;br /&gt; two R's: S-T-R-A-W-B-E-R-R-Y? But I don't think that's correct because I've never seen it spelled that way. &lt;/p&gt; &lt;p&gt;Wait, actually, no. The correct spelling of &amp;quot;strawberry&amp;quot; is S-T-R-A-W-B-E-R-R-Y. Wait, but that can't be right because it would &lt;br /&gt; have two R's in the middle, which doesn't sound right. &lt;/p&gt; &lt;p&gt;I think I'm making a mistake here. Let me just confirm: &amp;quot;Strawberry&amp;quot; is spelled with one R after the W and another R in the &lt;br /&gt; &amp;quot;berry&amp;quot; part? No, &amp;quot;berry&amp;quot; only has one R. Wait no, &amp;quot;berry&amp;quot; is B-E-R-R-Y, which has two R's. &lt;/p&gt; &lt;p&gt;Wait, so if I break it down: &lt;/p&gt; &lt;p&gt;- Straw: S-T-R-A-W&lt;br /&gt; - Berry: B-E-R-R-Y &lt;/p&gt; &lt;p&gt;So combining them would give S-T-R-A-W-B-E-R-R-Y, which has three R's? No, that can't be right because &amp;quot;straw&amp;quot; already ends with W &lt;br /&gt; and doesn't have an R. Wait no, &amp;quot;straw&amp;quot; is S-T-R-A-W, so the R is in there. &lt;/p&gt; &lt;p&gt;So combining &amp;quot;straw&amp;quot; (which has one R) and &amp;quot;berry&amp;quot; (which has two R's), but when you combine them into &amp;quot;strawberry,&amp;quot; do you keep &lt;br /&gt; all the letters? No, I think you just add &amp;quot;berry&amp;quot; to &amp;quot;straw,&amp;quot; so it becomes S-T-R-A-W-B-E-R-R-Y. But that would mean three R's in &lt;br /&gt; total: one from &amp;quot;straw&amp;quot; and two from &amp;quot;berry.&amp;quot; But I don't think that's correct because the word doesn't sound like it has three R &lt;br /&gt; sounds. &lt;/p&gt; &lt;p&gt;Wait, no. When you say &amp;quot;strawberry,&amp;quot; you pronounce it with a single R sound after the W, not multiple. So perhaps the spelling &lt;br /&gt; only includes one R in the middle, making it S-T-R-A-W-B-E-R-Y, which would have two R's: one at position 3 (from &amp;quot;straw&amp;quot;) and &lt;br /&gt; another at position 8 (from &amp;quot;berry&amp;quot;). Wait no, that can't be because &amp;quot;straw&amp;quot; is spelled with an R already. &lt;/p&gt; &lt;p&gt;Wait, I'm really confused now. Let me just accept that I might not remember the exact spelling and proceed to count based on a &lt;br /&gt; standard source. &lt;/p&gt; &lt;p&gt;Upon checking, the correct spelling of &amp;quot;strawberry&amp;quot; is S-T-R-A-W-B-E-R-R-Y, which has two R's: one after the W and another in the &lt;br /&gt; middle before the last Y. Wait no, that can't be right because I think it only has one R in the middle. &lt;/p&gt; &lt;p&gt;Wait, perhaps I'm overcomplicating. Let me just look up the correct spelling: &lt;/p&gt; &lt;p&gt;The correct spelling of &amp;quot;strawberry&amp;quot; is S-T-R-A-W-B-E-R-R-Y? No, actually, it's spelled as S-T-R-A-W-B-E-R-R-Y? Wait no, that's &lt;br /&gt; incorrect. The correct spelling is S-T-R-A-W-B-E-R-Y, which has one R after the W and another R in the &amp;quot;berry&amp;quot; part. &lt;/p&gt; &lt;p&gt;Wait, but that would mean two R's: one at position 3 (from &amp;quot;straw&amp;quot;) and another at position 8 (from &amp;quot;berry&amp;quot;). So total of two R's. &lt;/p&gt; &lt;p&gt;But when I write it out: &lt;/p&gt; &lt;p&gt;S T R A W B E R Y &lt;/p&gt; &lt;p&gt;That's S(1), T(2), R(3), A(4), W(5), B(6), E(7), R(8), Y(9). So that's nine letters with two R's at positions 3 and 8. &lt;/p&gt; &lt;p&gt;Wait, but &amp;quot;berry&amp;quot; is spelled as B-E-R-R-Y, so when combined with &amp;quot;straw,&amp;quot; does it become S-T-R-A-W-B-E-R-R-Y? That would be: &lt;/p&gt; &lt;p&gt;S(1), T(2), R(3), A(4), W(5), B(6), E(7), R(8), R(9), Y(10). So that's ten letters with two R's at positions 3 and 8, but &lt;br /&gt; actually, it would have an extra R from &amp;quot;berry,&amp;quot; making it three R's? No, I'm getting myself more confused. &lt;/p&gt; &lt;p&gt;Wait no, the correct spelling is S-T-R-A-W-B-E-R-R-Y. Wait, no, that can't be right because &amp;quot;straw&amp;quot; ends with W and &amp;quot;berry&amp;quot; starts &lt;br /&gt; with B, so when combined, you just have S-T-R-A-W-B-E-R-R-Y? No, I think it's spelled as S-T-R-A-W-B-E-R-R-Y, which has two R's: &lt;br /&gt; one after the W (position 3) and another in the middle (position 8). Wait no, that would be three letters between W and B. &lt;/p&gt; &lt;p&gt;Wait, let me just write it correctly: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;So S(1), T(2), R(3), A(4), W(5), B(6), E(7), R(8), R(9), Y(10). So that's ten letters with two R's at positions 3 and 8, but &lt;br /&gt; actually, it's one R after the W (position 3) and another in &amp;quot;berry&amp;quot; which is at position 8. Wait no, &amp;quot;berry&amp;quot; is B-E-R-R-Y, so &lt;br /&gt; when combined with &amp;quot;straw,&amp;quot; you have S-T-R-A-W-B-E-R-R-Y, making two R's: one from &amp;quot;straw&amp;quot; and two from &amp;quot;berry,&amp;quot; but actually, the &lt;br /&gt; R in &amp;quot;straw&amp;quot; is already part of the word, so perhaps it's only one additional R. &lt;/p&gt; &lt;p&gt;Wait no, I'm really confused. Maybe I should just accept that &amp;quot;strawberry&amp;quot; has two R's in its spelling: one after the W and &lt;br /&gt; another in the middle before the Y. &lt;/p&gt; &lt;p&gt;So, to answer the original question: How many Rs are in &amp;quot;strawberry&amp;quot;? &lt;/p&gt; &lt;p&gt;Looking it up, the correct spelling is S-T-R-A-W-B-E-R-R-Y? No, actually, no. The correct spelling of &amp;quot;strawberry&amp;quot; has two R's: &lt;br /&gt; one after the W and another before the Y. &lt;/p&gt; &lt;p&gt;Wait, but when I write it out: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;That would be ten letters with three R's? Wait no, that can't be right because &amp;quot;straw&amp;quot; is S-T-R-A-W (one R) and &amp;quot;berry&amp;quot; is &lt;br /&gt; B-E-R-R-Y (two R's), but when combined, you don't duplicate the R from &amp;quot;straw.&amp;quot; So it should be S-T-R-A-W-B-E-R-R-Y? No, that &lt;br /&gt; would have two R's: one from &amp;quot;straw&amp;quot; and two from &amp;quot;berry,&amp;quot; making three R's total. But I think that's not correct because the &lt;br /&gt; actual spelling only has two R's. &lt;/p&gt; &lt;p&gt;Wait no, perhaps I'm overcomplicating. The correct spelling is S-T-R-A-W-B-E-R-Y, which has two R's: one after the W (position 3) &lt;br /&gt; and another in &amp;quot;berry&amp;quot; at position 8. &lt;/p&gt; &lt;p&gt;But wait, that would mean: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;S&lt;br /&gt;&lt;/li&gt; &lt;li&gt;T&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;A&lt;br /&gt;&lt;/li&gt; &lt;li&gt;W&lt;br /&gt;&lt;/li&gt; &lt;li&gt;B&lt;br /&gt;&lt;/li&gt; &lt;li&gt;E&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;Y&lt;br /&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;So nine letters with two R's: positions 3 and 8. &lt;/p&gt; &lt;p&gt;Wait no, &amp;quot;berry&amp;quot; is spelled as B-E-R-R-Y, so when combined with &amp;quot;straw,&amp;quot; it should be S-T-R-A-W-B-E-R-R-Y, which has three R's? &lt;br /&gt; No, that can't be right because the correct spelling only has two R's: one in &amp;quot;straw&amp;quot; and another in &amp;quot;berry.&amp;quot; &lt;/p&gt; &lt;p&gt;Wait, no. The word is &amp;quot;strawberry.&amp;quot; Let me write it correctly: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;Wait, that's ten letters with three R's? No, that can't be right because I think the correct spelling only has two R's. &lt;/p&gt; &lt;p&gt;Wait, perhaps I'm making a mistake here. The word is &amp;quot;strawberry,&amp;quot; which is spelled as S-T-R-A-W-B-E-R-R-Y? Wait no, that would &lt;br /&gt; have an extra R. &lt;/p&gt; &lt;p&gt;Actually, the correct spelling of &amp;quot;strawberry&amp;quot; has two R's: one after the W and another before the Y. &lt;/p&gt; &lt;p&gt;Wait, but when I break it down: &lt;/p&gt; &lt;p&gt;- &amp;quot;Straw&amp;quot; is S-T-R-A-W (one R)&lt;br /&gt; - &amp;quot;Berry&amp;quot; is B-E-R-R-Y (two R's) &lt;/p&gt; &lt;p&gt;So combined, &amp;quot;strawberry&amp;quot; should have three R's? Wait no, because the R in &amp;quot;straw&amp;quot; and the R's in &amp;quot;berry&amp;quot; are separate. But when &lt;br /&gt; you combine them, it's S-T-R-A-W-B-E-R-R-Y, which has two R's after the W: one from &amp;quot;straw&amp;quot; and two from &amp;quot;berry,&amp;quot; making three R's &lt;br /&gt; total. &lt;/p&gt; &lt;p&gt;Wait no, that can't be right because I think the correct spelling only includes one R from &amp;quot;straw&amp;quot; and one R from &amp;quot;berry,&amp;quot; &lt;br /&gt; totaling two R's. &lt;/p&gt; &lt;p&gt;But when I write it out: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;That's S(1), T(2), R(3), A(4), W(5), B(6), E(7), R(8), R(9), Y(10). So that's ten letters with two R's at positions 3 and 8, but &lt;br /&gt; wait, no—actually, the correct spelling is S-T-R-A-W-B-E-R-R-Y? No, I think it's spelled as S-T-R-A-W-B-E-R-R-Y, which has three &lt;br /&gt; R's: one from &amp;quot;straw&amp;quot; (position 3) and two from &amp;quot;berry&amp;quot; (positions 8 and 9). Wait no, that would be incorrect because &amp;quot;berry&amp;quot; is &lt;br /&gt; B-E-R-R-Y, so when combined with &amp;quot;straw,&amp;quot; it should have the R from &amp;quot;straw&amp;quot; and then the two R's from &amp;quot;berry,&amp;quot; making three R's in &lt;br /&gt; total. &lt;/p&gt; &lt;p&gt;But I'm getting confused. Let me check a reliable source. Upon checking, the correct spelling of &amp;quot;strawberry&amp;quot; is &lt;br /&gt; S-T-R-A-W-B-E-R-R-Y? Wait no, that can't be right because the correct spelling has only two R's: one after the W and another &lt;br /&gt; before the Y. &lt;/p&gt; &lt;p&gt;Wait, perhaps I'm overcomplicating. The word &amp;quot;strawberry&amp;quot; has two Rs: one in &amp;quot;straw&amp;quot; (the third letter) and another in &amp;quot;berry&amp;quot; &lt;br /&gt; (the eighth letter). So total of two Rs. &lt;/p&gt; &lt;p&gt;But when written out: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;That's S(1), T(2), R(3), A(4), W(5), B(6), E(7), R(8), R(9), Y(10). Wait, that's three Rs: at positions 3, 8, and 9? No, that &lt;br /&gt; can't be right because &amp;quot;berry&amp;quot; is B-E-R-R-Y, so when combined with &amp;quot;straw,&amp;quot; it should have an extra R. &lt;/p&gt; &lt;p&gt;Wait no, maybe I'm wrong. Let me just accept that the correct spelling has two Rs: one after the W and another before the Y. So in &lt;br /&gt; total, two Rs. &lt;/p&gt; &lt;p&gt;But to be precise, let's break down the word: &lt;/p&gt; &lt;p&gt;- &amp;quot;Straw&amp;quot; is S-T-R-A-W (R at position 3)&lt;br /&gt; - &amp;quot;Berry&amp;quot; is B-E-R-R-Y (Rs at positions 8 and 9) &lt;/p&gt; &lt;p&gt;So combined, &amp;quot;strawberry&amp;quot; is S-T-R-A-W-B-E-R-R-Y, which has three Rs: one from &amp;quot;straw&amp;quot; and two from &amp;quot;berry.&amp;quot; Therefore, the total &lt;br /&gt; number of Rs in &amp;quot;strawberry&amp;quot; is three. &lt;/p&gt; &lt;p&gt;Wait no, that can't be right because I think the correct spelling only includes one R from &amp;quot;straw&amp;quot; and one R from &amp;quot;berry,&amp;quot; making &lt;br /&gt; it two Rs in total. The confusion arises because &amp;quot;berry&amp;quot; has two Rs, but when combined with &amp;quot;straw,&amp;quot; does it add another R? &lt;/p&gt; &lt;p&gt;No, actually, &amp;quot;strawberry&amp;quot; is spelled as S-T-R-A-W-B-E-R-R-Y, which includes the R from &amp;quot;straw&amp;quot; and the two Rs from &amp;quot;berry.&amp;quot; So &lt;br /&gt; that's three Rs in total. &lt;/p&gt; &lt;p&gt;Wait, no. Let me confirm by writing it out: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;Yes, that's three Rs: one at position 3 (from &amp;quot;straw&amp;quot;), and two more at positions 8 and 9 (from &amp;quot;berry&amp;quot;). Therefore, the word &lt;br /&gt; &amp;quot;strawberry&amp;quot; has three Rs. &lt;/p&gt; &lt;p&gt;But wait, no. The correct spelling of &amp;quot;strawberry&amp;quot; is S-T-R-A-W-B-E-R-Y, not with an extra R. Wait, that can't be right because &lt;br /&gt; &amp;quot;berry&amp;quot; ends with two Rs: B-E-R-R-Y. So when combined, it should have the R from &amp;quot;straw&amp;quot; and the two Rs from &amp;quot;berry,&amp;quot; making three &lt;br /&gt; Rs in total. &lt;/p&gt; &lt;p&gt;Wait, I'm getting conflicting information. Let me check a dictionary or reliable source. Upon checking, the correct spelling of &lt;br /&gt; &amp;quot;strawberry&amp;quot; is indeed S-T-R-A-W-B-E-R-R-Y, which has three Rs: one after the W and two before the Y. &lt;/p&gt; &lt;p&gt;But wait, no, that's not right. The word &amp;quot;strawberry&amp;quot; is spelled with two Rs: one in &amp;quot;straw&amp;quot; (the third letter) and another in &lt;br /&gt; &amp;quot;berry&amp;quot; (the eighth letter). Wait, but &amp;quot;berry&amp;quot; has two Rs: B-E-R-R-Y. So when combined, it should be S-T-R-A-W-B-E-R-R-Y, which &lt;br /&gt; includes three Rs. &lt;/p&gt; &lt;p&gt;Wait no, that's incorrect. The correct spelling is S-T-R-A-W-B-E-R-R-Y? No, I think the confusion comes from the fact that &lt;br /&gt; &amp;quot;strawberry&amp;quot; combines &amp;quot;straw&amp;quot; and &amp;quot;berry,&amp;quot; where &amp;quot;berry&amp;quot; has two Rs. Therefore, the full word should have three Rs: one from &lt;br /&gt; &amp;quot;straw&amp;quot; and two from &amp;quot;berry.&amp;quot; So yes, &amp;quot;strawberry&amp;quot; has three Rs. &lt;/p&gt; &lt;p&gt;But I'm not entirely sure. Let me write it out: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;That's S(1), T(2), R(3), A(4), W(5), B(6), E(7), R(8), R(9), Y(10). So positions 3, 8, and 9 are Rs. That makes three Rs in total. &lt;/p&gt; &lt;p&gt;Wait no, I think that's incorrect. The correct spelling of &amp;quot;strawberry&amp;quot; is S-T-R-A-W-B-E-R-R-Y? No, actually, it's spelled as &lt;br /&gt; S-T-R-A-W-B-E-R-R-Y with two Rs after the E: R and then another R before Y. So yes, three Rs in total. &lt;/p&gt; &lt;p&gt;Wait no, I'm making a mistake here. The word &amp;quot;strawberry&amp;quot; is spelled with two Rs: one from &amp;quot;straw&amp;quot; (the third letter) and another &lt;br /&gt; from &amp;quot;berry&amp;quot; (the eighth letter). Wait, but &amp;quot;berry&amp;quot; has two Rs, so when combined, it should have an additional R. &lt;/p&gt; &lt;p&gt;Wait no, let me think carefully. The word &amp;quot;straw&amp;quot; ends with W, and &amp;quot;berry&amp;quot; starts with B. When you combine them, it's &lt;br /&gt; &amp;quot;straw&amp;quot;+&amp;quot;berry&amp;quot; = &amp;quot;strawberry.&amp;quot; So the spelling is S-T-R-A-W-B-E-R-R-Y? No, that would be incorrect because &amp;quot;straw&amp;quot; already has an &lt;br /&gt; R, and &amp;quot;berry&amp;quot; adds two more Rs. &lt;/p&gt; &lt;p&gt;Wait no, I think the correct spelling only includes one R from &amp;quot;straw&amp;quot; and one R from &amp;quot;berry,&amp;quot; making it two Rs in total. The &lt;br /&gt; confusion comes from thinking that &amp;quot;berry&amp;quot; has two Rs, but when combined, the Rs are separate: one from &amp;quot;straw&amp;quot; and another from &lt;br /&gt; &amp;quot;berry.&amp;quot; &lt;/p&gt; &lt;p&gt;Wait no, actually, &amp;quot;berry&amp;quot; is B-E-R-R-Y, which has two Rs at the end. So when you add &amp;quot;straw&amp;quot; (S-T-R-A-W) to it, you get &lt;br /&gt; S-T-R-A-W-B-E-R-R-Y, which indeed has three Rs: one from &amp;quot;straw&amp;quot; and two from &amp;quot;berry.&amp;quot; &lt;/p&gt; &lt;p&gt;But I'm not entirely sure if that's correct. Let me confirm by checking a reliable source or dictionary. &lt;/p&gt; &lt;p&gt;Upon checking, the correct spelling of &amp;quot;strawberry&amp;quot; is indeed S-T-R-A-W-B-E-R-R-Y with three Rs: one after the W (from &amp;quot;straw&amp;quot;) &lt;br /&gt; and two before the Y (from &amp;quot;berry&amp;quot;). So the total number of Rs in &amp;quot;strawberry&amp;quot; is three. &lt;/p&gt; &lt;p&gt;Wait no, that can't be right. I think I'm overcomplicating it. The word &amp;quot;strawberry&amp;quot; comes from &amp;quot;straw&amp;quot; + &amp;quot;berry,&amp;quot; where &amp;quot;straw&amp;quot; &lt;br /&gt; has one R and &amp;quot;berry&amp;quot; has two Rs. So when combined, the total number of Rs in the new word should be three. &lt;/p&gt; &lt;p&gt;But wait, no. Actually, when you combine them, the R at the end of &amp;quot;straw&amp;quot; and the beginning of &amp;quot;berry&amp;quot; might merge or not. Wait, &lt;br /&gt; no, because &amp;quot;straw&amp;quot; ends with W, so adding &amp;quot;berry&amp;quot; after it doesn't affect the Rs in &amp;quot;straw.&amp;quot; So &amp;quot;straw&amp;quot; has one R, and &amp;quot;berry&amp;quot; &lt;br /&gt; has two Rs, making a total of three Rs in &amp;quot;strawberry.&amp;quot; &lt;/p&gt; &lt;p&gt;Wait, but I think that's incorrect. The correct spelling is S-T-R-A-W-B-E-R-R-Y with three Rs: one after the W (from &amp;quot;straw&amp;quot;) and &lt;br /&gt; two before the Y (from &amp;quot;berry&amp;quot;). So yes, three Rs. &lt;/p&gt; &lt;p&gt;But actually, when you write it out: &lt;/p&gt; &lt;p&gt;S T R A W B E R R Y &lt;/p&gt; &lt;p&gt;That's 10 letters. Let me count them: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;S&lt;br /&gt;&lt;/li&gt; &lt;li&gt;T&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;A&lt;br /&gt;&lt;/li&gt; &lt;li&gt;W&lt;br /&gt;&lt;/li&gt; &lt;li&gt;B&lt;br /&gt;&lt;/li&gt; &lt;li&gt;E&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;R&lt;br /&gt;&lt;/li&gt; &lt;li&gt;Y&lt;br /&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Yes, positions 3, 8, and 9 are Rs. So that's three Rs in total. &lt;/p&gt; &lt;p&gt;Wait no, I think the correct spelling only includes two Rs: one from &amp;quot;straw&amp;quot; (position 3) and another from &amp;quot;berry&amp;quot; (position 8). &lt;br /&gt; Wait, but &amp;quot;berry&amp;quot; is B-E-R-R-Y, so after E comes R, then another R before Y. So when you combine them, it's S-T-R-A-W-B-E-R-R-Y, &lt;br /&gt; which indeed has Rs at positions 3, 8, and 9. &lt;/p&gt; &lt;p&gt;Therefore, the word &amp;quot;strawberry&amp;quot; has three Rs in total.&lt;br /&gt; &amp;lt;/think&amp;gt; &lt;/p&gt; &lt;p&gt;The word &amp;quot;strawberry&amp;quot; is spelled as S-T-R-A-W-B-E-R-R-Y. It contains three instances of the letter 'R': one after the 'A' (from &lt;br /&gt; &amp;quot;straw&amp;quot;) and two before the 'Y' (from &amp;quot;berry&amp;quot;). Therefore, there are three Rs in &amp;quot;strawberry.&amp;quot; &lt;/p&gt; &lt;p&gt;**Answer:** There are three Rs in the word &amp;quot;strawberry.&amp;quot; &lt;/p&gt; &lt;p&gt;&amp;gt;&amp;gt;&amp;gt; Send a message (/? for help) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/tahaan"&gt; /u/tahaan &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jw1pfm/tried_a_new_model_but_i_misspelled_strawberry/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jw1pfm/tried_a_new_model_but_i_misspelled_strawberry/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jw1pfm/tried_a_new_model_but_i_misspelled_strawberry/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-10T16:11:28+00:00</published>
  </entry>
  <entry>
    <id>t3_1jx0ayv</id>
    <title>Ollama and Langflow integration</title>
    <updated>2025-04-11T20:52:05+00:00</updated>
    <author>
      <name>/u/Feeling-Concert7878</name>
      <uri>https://old.reddit.com/user/Feeling-Concert7878</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Feeling-Concert7878"&gt; /u/Feeling-Concert7878 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/langflow/comments/1jvl23l/ollama_and_langflow_integration/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx0ayv/ollama_and_langflow_integration/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jx0ayv/ollama_and_langflow_integration/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T20:52:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwoohl</id>
    <title>Summarize Videos Using AI with Gemma 3, LangChain and Streamlit</title>
    <updated>2025-04-11T12:30:26+00:00</updated>
    <author>
      <name>/u/Flashy-Thought-5472</name>
      <uri>https://old.reddit.com/user/Flashy-Thought-5472</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1jwoohl/summarize_videos_using_ai_with_gemma_3_langchain/"&gt; &lt;img alt="Summarize Videos Using AI with Gemma 3, LangChain and Streamlit" src="https://external-preview.redd.it/UtUDBVw8IwCIwOf5n-_Yuqu3W4V18jWndui4CmTV8LU.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=216d5429347985386b72e37e574811f09d797b7a" title="Summarize Videos Using AI with Gemma 3, LangChain and Streamlit" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Flashy-Thought-5472"&gt; /u/Flashy-Thought-5472 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.youtube.com/watch?v=gDATAZEi5SE&amp;amp;list=PLp01ObP3udmq2quR-RfrX4zNut_t_kNot&amp;amp;index=16"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwoohl/summarize_videos_using_ai_with_gemma_3_langchain/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwoohl/summarize_videos_using_ai_with_gemma_3_langchain/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T12:30:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwv3lx</id>
    <title>Looking for Ollama-Based UI to Execute AI-Generated Code and Analyze Local CSV Files</title>
    <updated>2025-04-11T17:12:00+00:00</updated>
    <author>
      <name>/u/BatLevel3320</name>
      <uri>https://old.reddit.com/user/BatLevel3320</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I'm seeking a user interface that integrates with &lt;strong&gt;Ollama&lt;/strong&gt;, allowing AI-generated &lt;strong&gt;code to be executed&lt;/strong&gt; directly, particularly for analyzing &lt;strong&gt;CSV files&lt;/strong&gt; stored on the user's local machine. The ideal setup would enable a conversational interaction where the AI can read and process the CSV file, execute code (like generating plots or performing data analysis), and present the results within the chat interface.&lt;/p&gt; &lt;p&gt;I've experimented with several tools, including Open WebUI, PrivateGPT, and AnythingLLM. While these platforms support document uploads and utilize Retrieval-Augmented Generation (RAG) for context, they don't offer the capability to execute code generated by the AI on the uploaded files.&lt;/p&gt; &lt;p&gt;Does anyone know of a UI that facilitates this kind of interactive and executable data analysis with local files using Ollama? Any recommendations or guidance would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/BatLevel3320"&gt; /u/BatLevel3320 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwv3lx/looking_for_ollamabased_ui_to_execute_aigenerated/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwv3lx/looking_for_ollamabased_ui_to_execute_aigenerated/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwv3lx/looking_for_ollamabased_ui_to_execute_aigenerated/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T17:12:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1jww4sj</id>
    <title>RTX 5090 support? --GPU all</title>
    <updated>2025-04-11T17:55:05+00:00</updated>
    <author>
      <name>/u/Wonk_puffin</name>
      <uri>https://old.reddit.com/user/Wonk_puffin</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi all &lt;/p&gt; &lt;p&gt;Probably a naive question. &lt;/p&gt; &lt;p&gt;Just wondering. When I run Ollama in a docker container there's a --GPU all switch. When I try that I get CUDA image errors (when attaching files to the prompt as part of context) which I assume means either docker or Ollama doesn't support the 5090 yet, either directly or indirectly?&lt;/p&gt; &lt;p&gt;If I don't use the switch it all works fine even with 27bn to 70bn parameter models and reasonably fast so I assume the GPU is still involved in the processing / inference?&lt;/p&gt; &lt;p&gt;Any chance a guru can explain all this to me cus I don't get it? &lt;/p&gt; &lt;p&gt;Is there 5090 support coming that'll make all of the inferencing even faster?&lt;/p&gt; &lt;p&gt;Thanks 🙏🏻👍🏻.&lt;/p&gt; &lt;p&gt;Spec: AMD Ryzen 9 9950X, 64GB RAM, RTX 5090 32GB VRAM, Windows 11, very fast 4TB SSD.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Wonk_puffin"&gt; /u/Wonk_puffin &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jww4sj/rtx_5090_support_gpu_all/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jww4sj/rtx_5090_support_gpu_all/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jww4sj/rtx_5090_support_gpu_all/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T17:55:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwn21p</id>
    <title>Benchmark for coding performance of c. 14b models on ollama</title>
    <updated>2025-04-11T10:58:38+00:00</updated>
    <author>
      <name>/u/tdoris</name>
      <uri>https://old.reddit.com/user/tdoris</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;In response so some requests, I've updated rank_llms (free and open source benchmark suite for your local ollama models) and used it to test the performance of models around 14B size on coding problems.&lt;/p&gt; &lt;h1&gt;14B-Scale Model Comparison: Direct Head-to-Head Analysis&lt;/h1&gt; &lt;p&gt;This analysis shows the performance of similar-sized (~12-14B parameter) models on the coding101 promptset, based on actual head-to-head test results rather than mathematical projections.&lt;/p&gt; &lt;h1&gt;Overall Rankings&lt;/h1&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align="left"&gt;Rank&lt;/th&gt; &lt;th align="left"&gt;Model&lt;/th&gt; &lt;th align="left"&gt;Average Win Rate&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align="left"&gt;1&lt;/td&gt; &lt;td align="left"&gt;phi4:latest&lt;/td&gt; &lt;td align="left"&gt;0.756&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;2&lt;/td&gt; &lt;td align="left"&gt;deepseek-r1:14b&lt;/td&gt; &lt;td align="left"&gt;0.567&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;3&lt;/td&gt; &lt;td align="left"&gt;gemma3:12b&lt;/td&gt; &lt;td align="left"&gt;0.344&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;4&lt;/td&gt; &lt;td align="left"&gt;cogito:14b&lt;/td&gt; &lt;td align="left"&gt;0.333&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;h1&gt;Win Probability Matrix&lt;/h1&gt; &lt;p&gt;Probability of row model beating column model (based on head-to-head results):&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align="left"&gt;Model&lt;/th&gt; &lt;th align="left"&gt;phi4:latest&lt;/th&gt; &lt;th align="left"&gt;deepseek-r1:14b&lt;/th&gt; &lt;th align="left"&gt;gemma3:12b&lt;/th&gt; &lt;th align="left"&gt;cogito:14b&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align="left"&gt;&lt;strong&gt;phi4:latest&lt;/strong&gt;&lt;/td&gt; &lt;td align="left"&gt;-&lt;/td&gt; &lt;td align="left"&gt;0.800&lt;/td&gt; &lt;td align="left"&gt;0.800&lt;/td&gt; &lt;td align="left"&gt;0.667&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;&lt;strong&gt;deepseek-r1:14b&lt;/strong&gt;&lt;/td&gt; &lt;td align="left"&gt;0.200&lt;/td&gt; &lt;td align="left"&gt;-&lt;/td&gt; &lt;td align="left"&gt;0.733&lt;/td&gt; &lt;td align="left"&gt;0.767&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;&lt;strong&gt;gemma3:12b&lt;/strong&gt;&lt;/td&gt; &lt;td align="left"&gt;0.200&lt;/td&gt; &lt;td align="left"&gt;0.267&lt;/td&gt; &lt;td align="left"&gt;-&lt;/td&gt; &lt;td align="left"&gt;0.567&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;&lt;strong&gt;cogito:14b&lt;/strong&gt;&lt;/td&gt; &lt;td align="left"&gt;0.333&lt;/td&gt; &lt;td align="left"&gt;0.233&lt;/td&gt; &lt;td align="left"&gt;0.433&lt;/td&gt; &lt;td align="left"&gt;-&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;h1&gt;Full detailed results are here: &lt;a href="https://github.com/tdoris/rank_llms/blob/master/coding_14b_models.md"&gt;https://github.com/tdoris/rank_llms/blob/master/coding_14b_models.md&lt;/a&gt;&lt;/h1&gt; &lt;p&gt;Check out the rank_llms repo on github to run your own tests on the models that best fit your hardware: &lt;a href="https://github.com/tdoris/rank_llms"&gt;https://github.com/tdoris/rank_llms&lt;/a&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/tdoris"&gt; /u/tdoris &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwn21p/benchmark_for_coding_performance_of_c_14b_models/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwn21p/benchmark_for_coding_performance_of_c_14b_models/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwn21p/benchmark_for_coding_performance_of_c_14b_models/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T10:58:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1jx3h0y</id>
    <title>Prompt-engineering tools with Ollama support?</title>
    <updated>2025-04-11T23:16:36+00:00</updated>
    <author>
      <name>/u/juzef</name>
      <uri>https://old.reddit.com/user/juzef</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi! &lt;/p&gt; &lt;p&gt;I am fooling around with ollama/lmstudio and some local models for data extraction tasks with few different models. I want to test different prompts on approximately 20-40 data payloads + compare the results, and I am really struggling to find a tool that would enable me to do that effectively.&lt;/p&gt; &lt;p&gt;There are some interesting ones, like &lt;a href="http://promptsmith.dev"&gt;promptsmith.dev&lt;/a&gt;, &lt;a href="http://agenta.ai"&gt;agenta.ai&lt;/a&gt; or &lt;a href="http://promptmetheus.com"&gt;promptmetheus.com&lt;/a&gt;, but they aren't really made with ollama in mind.&lt;/p&gt; &lt;p&gt;Is there anything out there that works with ollama? Tbf, it feels like my research was surface-level, so maybe there's something out there that I missed, thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/juzef"&gt; /u/juzef &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx3h0y/promptengineering_tools_with_ollama_support/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx3h0y/promptengineering_tools_with_ollama_support/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jx3h0y/promptengineering_tools_with_ollama_support/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T23:16:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1jx6eto</id>
    <title>Pull only Modelfile from Huggingface?</title>
    <updated>2025-04-12T01:49:56+00:00</updated>
    <author>
      <name>/u/LittleBlueLaboratory</name>
      <uri>https://old.reddit.com/user/LittleBlueLaboratory</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have this problem. The problem is digest mismatch. I get this error nearly every time I download a model: 'Error: digest mismatch, file must be downloaded again'&lt;/p&gt; &lt;p&gt;It is usually resolved by doing an 'ollama pull huggingface-model' again until it succeeds. However my ISP has a data cap and downloading the same model over and over again only for it to fail over and over again is just not acceptable. I get around this by downloading the model manually from huggingface once and then I can use 'ollama create' as often as I need to without using up my precious data cap.&lt;/p&gt; &lt;p&gt;My problem is tracking down all the parameters and templates for the Modelfile each and every time I get a new model to try out. Nearly every time an 'ollama pull' succeeds it runs way better than when I do an 'ollama create' because I missed something or mistyped it. It just has all the right parameters from the start. Is there a better way to get all of this info? I would dearly love a way to pull just the modelfile from huggingface and then I can use that with 'ollama create' and my previously downloaded files.&lt;/p&gt; &lt;p&gt;Any help or guidance would be appreciated. Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/LittleBlueLaboratory"&gt; /u/LittleBlueLaboratory &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx6eto/pull_only_modelfile_from_huggingface/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx6eto/pull_only_modelfile_from_huggingface/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jx6eto/pull_only_modelfile_from_huggingface/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-12T01:49:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1jxdagn</id>
    <title>Reversed globbing related questions</title>
    <updated>2025-04-12T09:16:00+00:00</updated>
    <author>
      <name>/u/tahaan</name>
      <uri>https://old.reddit.com/user/tahaan</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have a topic that I still have not found a single model that can answer correctly. I have tried many times, and tried really hard to lead the models to the answer, without actually giving it away. An example of the problem is as below:&lt;/p&gt; &lt;p&gt;A user can have access to a table, eg &lt;code&gt;website.wp_users&lt;/code&gt; in MySQL through any of the following&lt;/p&gt; &lt;pre&gt;&lt;code&gt;GRANT SELECT ON *.* TO 'myuser'@'localhost'; GRANT SELECT ON *.wp_users TO 'myuser'@'localhost'; GRANT SELECT ON website.* TO 'myuser'@'localhost'; GRANT SELECT ON mydb.wp_users TO 'myuser'@'localhost'; GRANT SELECT ON mydb.wp_u* TO 'myuser'@'localhost'; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The challenge is: Write a program that will be used by auditors to list all users who have access to a specified table.&lt;/p&gt; &lt;p&gt;With sufficient guidance, the LLMs all get the first 4 right, but even getting them to write a single query, function, or program, to do them all, is nearly impossible. That is fine, I can combine the code.&lt;/p&gt; &lt;p&gt;But I have yet to find an LLM that can get the last one right. The really large models (eg the ones running in the cloud only) can give some answers, but they never figure it out properly.&lt;/p&gt; &lt;p&gt;The only correct answer is to list all the grants that have a wildcard and to try and glob them to see if they match the specified table. Some version of the following algorithm:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;1. wildcard_grants = get_wildcard_grants(my_database) 2. specified_table = &amp;quot;tablename&amp;quot; 2. for each grant in wildcard_grants: 2.1 granted_tables = get_tables_from_grant(grant) 2.2 match = test_wildcard_glob(specified_table, granted_tables) 2.3 if match == True: 2.3.1 print(&amp;quot;Grant found for user&amp;quot;, get_user_from_grant(grant), format_as_text(grant)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have done everything except to tell the models to actually iterate over all grants and test all of them for a globbing match.&lt;/p&gt; &lt;p&gt;Another example:&lt;/p&gt; &lt;p&gt;A backup validation program has a configuration file that lets the user specifiy one or more file paths that can have wildcards. The program will perform a series of checks against the most recent backup for the server and extract the manifest of the backup, and then check the manifest to confirm that the backup contains the specified file(s). Note that this program doesn't actually restore the backup. &lt;/p&gt; &lt;p&gt;For example the test files list might include the following two items&lt;/p&gt; &lt;pre&gt;&lt;code&gt;/etc/ssh/ssh* /var/lib/mysql/*ndx &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It is essentially the same problem, and the LLMs don't get it right.&lt;/p&gt; &lt;p&gt;TL:DR I find it interesting that this remains beyond the reach of LLMs. It shows us how far the models still have to go to actually be able to reason. Ie your job is still safe :-)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/tahaan"&gt; /u/tahaan &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jxdagn/reversed_globbing_related_questions/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jxdagn/reversed_globbing_related_questions/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jxdagn/reversed_globbing_related_questions/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-12T09:16:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1jwsyxt</id>
    <title>LLPlayer - A media player with real-time subtitles and translation, by Ollama API &amp; OpenAI Whisper</title>
    <updated>2025-04-11T15:43:09+00:00</updated>
    <author>
      <name>/u/umlx</name>
      <uri>https://old.reddit.com/user/umlx</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1jwsyxt/llplayer_a_media_player_with_realtime_subtitles/"&gt; &lt;img alt="LLPlayer - A media player with real-time subtitles and translation, by Ollama API &amp;amp; OpenAI Whisper" src="https://external-preview.redd.it/gSgAWiRQlCrSzHZYbv0ZHzu7CVcbBI_hJ-bIvAK5q0w.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4541a27930d456e4d2649d2568302e6570c8a6b2" title="LLPlayer - A media player with real-time subtitles and translation, by Ollama API &amp;amp; OpenAI Whisper" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hello, I'm working on a video player for Windows that can generate subtitles using OpenAI Whisper in real time and translate them, and I recently added support for translation using the Ollama API.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href="https://github.com/umlx5h/LLPlayer"&gt;https://github.com/umlx5h/LLPlayer&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This player may be useful for language learning purposes because it allows real-time subtitle generation and translation even for online videos such as YouTube directly.&lt;/p&gt; &lt;p&gt;I've confirmed that the translation is more accurate than the usual Google or DeepL APIs, because the context of the subtitles is included and sent to LLM for translation.&lt;/p&gt; &lt;p&gt;I'd be happy to get your feedback. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/umlx"&gt; /u/umlx &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/umlx5h/LLPlayer"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jwsyxt/llplayer_a_media_player_with_realtime_subtitles/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jwsyxt/llplayer_a_media_player_with_realtime_subtitles/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-11T15:43:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1jx4lp4</id>
    <title>Ollama + openwebui + DeepSeek only referencing 3 files while replying</title>
    <updated>2025-04-12T00:13:45+00:00</updated>
    <author>
      <name>/u/miguel_caballero</name>
      <uri>https://old.reddit.com/user/miguel_caballero</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am using docker. &lt;/p&gt; &lt;p&gt;I have uploaded 40 pdf files to a new chat and asked to summarise each file.&lt;/p&gt; &lt;p&gt;I only get the summary of 3 of them.&lt;/p&gt; &lt;p&gt;I have also trying creating a knowledge group with all the files with the same output.&lt;/p&gt; &lt;p&gt;Deepseek has told me:&lt;/p&gt; &lt;p&gt;&amp;quot;To &lt;strong&gt;increase the number of files Open WebUI can reference&lt;/strong&gt; (beyond the default limit of 3), you need to modify the &lt;strong&gt;Retrieval-Augmented Generation (RAG)&lt;/strong&gt; settings. Here’s how to do it in different deployment scenarios:&amp;quot;&lt;/p&gt; &lt;p&gt;I have increases the RAG_MAX_FILES=10 with no luck.&lt;/p&gt; &lt;p&gt;What am I missing?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/miguel_caballero"&gt; /u/miguel_caballero &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx4lp4/ollama_openwebui_deepseek_only_referencing_3/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx4lp4/ollama_openwebui_deepseek_only_referencing_3/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jx4lp4/ollama_openwebui_deepseek_only_referencing_3/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-12T00:13:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1jx9hso</id>
    <title>3 Agent patterns are dominating agentic systems</title>
    <updated>2025-04-12T04:49:31+00:00</updated>
    <author>
      <name>/u/Any-Cockroach-3233</name>
      <uri>https://old.reddit.com/user/Any-Cockroach-3233</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;ol&gt; &lt;li&gt;&lt;p&gt;Simple Agents: These are the task rabbits of AI. They execute atomic, well-defined actions. E.g., &amp;quot;Summarize this doc,&amp;quot; &amp;quot;Send this email,&amp;quot; or &amp;quot;Check calendar availability.&amp;quot; &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Workflows: A more coordinated form. These agents follow a sequential plan, passing context between steps. Perfect for use cases like onboarding flows, data pipelines, or research tasks that need several steps done in order. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Teams: The most advanced structure. These involve:&lt;br /&gt; - A leader agent that manages overall goals and coordination&lt;br /&gt; - Multiple specialized member agents that take ownership of subtasks&lt;br /&gt; - The leader agent usually selects the member agent that is perfect for the job&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any-Cockroach-3233"&gt; /u/Any-Cockroach-3233 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx9hso/3_agent_patterns_are_dominating_agentic_systems/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1jx9hso/3_agent_patterns_are_dominating_agentic_systems/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1jx9hso/3_agent_patterns_are_dominating_agentic_systems/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-04-12T04:49:31+00:00</published>
  </entry>
</feed>
