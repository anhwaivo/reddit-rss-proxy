<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/ollama/.rss</id>
  <title>ollama</title>
  <updated>2025-02-21T09:48:55+00:00</updated>
  <link href="https://old.reddit.com/r/ollama/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Atom feed for r/ollama</subtitle>
  <entry>
    <id>t3_1itgqm2</id>
    <title>Blind Guy Looking For Help -- Open Source Robust NLU Engine Cominb Shortly.</title>
    <updated>2025-02-19T21:11:31+00:00</updated>
    <author>
      <name>/u/mdizak</name>
      <uri>https://old.reddit.com/user/mdizak</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey folks,&lt;/p&gt; &lt;p&gt;No idea if this is allowed, and although not Ollama specific, right in line with the self hosted, privacy focused AI stuff.&lt;/p&gt; &lt;p&gt;I'm lead on Cicero, mission statement at: &lt;a href="https://cicero.sh/mission"&gt;https://cicero.sh/mission&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Just about to open source the newly upgraded NLU engine coined Sophia. Specs and demo you can play with at &lt;a href="https://cicero.sh/sophia"&gt;https://cicero.sh/sophia&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Great if you have AI agentic workflows of any kind, and within a day or two will be open sourced under dual license. If you play with that demo, you will realize the POS tagger is terribl and mixes up verbs / nouns all the time. This has been fully resolved in the latest version.&lt;/p&gt; &lt;p&gt;I want a nice release though, because I deserve something good to finally happen. Years ago life decided to have some fun with me and all in the span of about 16 months I went suddenly and totally blind within a few weeks, my primary business colleague of 9 years was murdered via professional hit, was forced by immigration to move back to Canada resulting in the loss of my fiance and dogs of 7 years, toxic family decided gas lighting me for a while was a good idea, and other challenges. It's been thrilling, I tell ya.&lt;/p&gt; &lt;p&gt;So now I got Cicero, and although I make bold claims, I have the skill and experience to see it through. Of course, will be doing the right thing and open sourcing everything.&lt;/p&gt; &lt;p&gt;I'd like a nice release in the coming days of the NLU engine, and could really use a helping hand from a kind soul here. Just two quick things:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Need a logo. Asked Chat GPT and got this: &lt;a href="https://cicero.sh/cicero.png"&gt;https://cicero.sh/cicero.png&lt;/a&gt; -- no idea, how does that look? Is it decent, good to go? If it's not good, can you throw a quick prompt or two out for me and get me something usable?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;With the release of the NLU engine, also want to release first episode of a faceless podcast. I have no idea about the various free / open source text 2 video services, because why would I? Any kind soul willing to throw a couple prompts in and just get me something decent and short that I can play on loop for the video part? &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Would want to stick with the ancient Rome theme, Cicero was a great statesman and senator, great rags to success story, and although controversial was definitely a man for the people. I have no idea, maybe a landscape of an ancient Roman village or market or something, and maybe some kind of modern twist added but don't know how so maybe just classical would be cool. I have no idea, just something along with a still image I can use for thumbnails would be greatly appreciated.&lt;/p&gt; &lt;p&gt;If anyone could help with those two above points, would really appreciate it. In exchange, will get that NLU engine open sourced right away here, and continue working on awesome open source software for everyone, as everything will be open sourced within Cicero...&lt;/p&gt; &lt;p&gt;I don't expect this as it's way too much of an ask, but if anyone is willing to play with oneof those web design AI things that would be awesome. That design you see is from &lt;a href="https://apexpl.io/"&gt;https://apexpl.io/&lt;/a&gt; another project I developed that went nowhere, and I kid you not, that was 18 months, $12k USD and 6 designers. Unreal, eh?&lt;/p&gt; &lt;p&gt;Nothing fancy, no Javascript frameworks, just simple, clean HTML / CSS code that conveys the information in a concise and professional format. If anyone's willing to do that, and pass a couple messages back and forth with me while I complete integration, would be beyond grateful. Happy to link you as sponsor, add &amp;quot;designed by&amp;quot; link in footer, and contract out to you for all future design and other related work I need in the future once I get money rolling again as I plan on launching loads of sites.&lt;/p&gt; &lt;p&gt;Wow, way too long, sorry about that. If interested in the NLU engine release, just keep your eye on &lt;a href="/r/opensource"&gt;/r/opensource&lt;/a&gt; in the next 2 or 3 days and it'll show up. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mdizak"&gt; /u/mdizak &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itgqm2/blind_guy_looking_for_help_open_source_robust_nlu/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itgqm2/blind_guy_looking_for_help_open_source_robust_nlu/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itgqm2/blind_guy_looking_for_help_open_source_robust_nlu/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-19T21:11:31+00:00</published>
  </entry>
  <entry>
    <id>t3_1ita4ph</id>
    <title>deepseek and ollama to create knowledge graphs</title>
    <updated>2025-02-19T16:50:05+00:00</updated>
    <author>
      <name>/u/Short-Honeydew-7000</name>
      <uri>https://old.reddit.com/user/Short-Honeydew-7000</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1ita4ph/deepseek_and_ollama_to_create_knowledge_graphs/"&gt; &lt;img alt="deepseek and ollama to create knowledge graphs" src="https://external-preview.redd.it/4ijyY7Qu-05QDvrnzoIwg803mKYJkGjXXn0YyImxyhE.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6da44814a5c90a2b4de967ae82c0dd3e786dc7d2" title="deepseek and ollama to create knowledge graphs" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Short-Honeydew-7000"&gt; /u/Short-Honeydew-7000 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.cognee.ai/blog/deep-dives/deepseek-ollama-and-graphs"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1ita4ph/deepseek_and_ollama_to_create_knowledge_graphs/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1ita4ph/deepseek_and_ollama_to_create_knowledge_graphs/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-19T16:50:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1itvbx6</id>
    <title>Is this good?</title>
    <updated>2025-02-20T10:17:44+00:00</updated>
    <author>
      <name>/u/Sritanishq369</name>
      <uri>https://old.reddit.com/user/Sritanishq369</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1itvbx6/is_this_good/"&gt; &lt;img alt="Is this good?" src="https://preview.redd.it/0q7pw4ezr9ke1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b4504e830b78c141d9cd96bab80e76110502081e" title="Is this good?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Sritanishq369"&gt; /u/Sritanishq369 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/0q7pw4ezr9ke1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itvbx6/is_this_good/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itvbx6/is_this_good/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T10:17:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1itmqfo</id>
    <title>Run structured visual extraction locally with Ollama</title>
    <updated>2025-02-20T01:35:06+00:00</updated>
    <author>
      <name>/u/AutonomousScott</name>
      <uri>https://old.reddit.com/user/AutonomousScott</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/vlm-run/vlmrun-hub"&gt;https://github.com/vlm-run/vlmrun-hub&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AutonomousScott"&gt; /u/AutonomousScott &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itmqfo/run_structured_visual_extraction_locally_with/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itmqfo/run_structured_visual_extraction_locally_with/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itmqfo/run_structured_visual_extraction_locally_with/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T01:35:06+00:00</published>
  </entry>
  <entry>
    <id>t3_1isvd1h</id>
    <title>Ollama Deepseek-R1 AI writes my Obsidian notes by watching my screen (open source)</title>
    <updated>2025-02-19T03:05:26+00:00</updated>
    <author>
      <name>/u/louis3195</name>
      <uri>https://old.reddit.com/user/louis3195</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1isvd1h/ollama_deepseekr1_ai_writes_my_obsidian_notes_by/"&gt; &lt;img alt="Ollama Deepseek-R1 AI writes my Obsidian notes by watching my screen (open source)" src="https://external-preview.redd.it/NGI4NHl2aTBpMGtlMaEzGEUaUQonH8wQBp1lwNMA6DwRZxj8nxN2XpHfUUNy.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6aa25cc908b1aaf94262c3fa735cebef775b5e9c" title="Ollama Deepseek-R1 AI writes my Obsidian notes by watching my screen (open source)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/louis3195"&gt; /u/louis3195 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/1eo4wui0i0ke1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1isvd1h/ollama_deepseekr1_ai_writes_my_obsidian_notes_by/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1isvd1h/ollama_deepseekr1_ai_writes_my_obsidian_notes_by/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-19T03:05:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1itxdvg</id>
    <title>Role play master model and plateform</title>
    <updated>2025-02-20T12:30:23+00:00</updated>
    <author>
      <name>/u/Cassey1415</name>
      <uri>https://old.reddit.com/user/Cassey1415</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I'm looking for a model that can help me playing some roleplay game with or without friends, so D&amp;amp;D, cthulhu or that kind of stuff. If possible without censorship to have +18 gore or sexual stuffs.&lt;/p&gt; &lt;p&gt;Do you have any recommendation of models and plateform (or even subreddit oriented for that kind of stuff) ? Open Webui is not bad not very well oriented for that&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cassey1415"&gt; /u/Cassey1415 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itxdvg/role_play_master_model_and_plateform/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itxdvg/role_play_master_model_and_plateform/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itxdvg/role_play_master_model_and_plateform/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T12:30:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1itndet</id>
    <title>Rag With Your CSV File As A Script For Your Chatbot Using Ollama DeepSeekR1 and Llama Locally</title>
    <updated>2025-02-20T02:06:35+00:00</updated>
    <author>
      <name>/u/Spirited-Wind6803</name>
      <uri>https://old.reddit.com/user/Spirited-Wind6803</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi everyone. I just want to share with you this tutorial that I am: &lt;/p&gt; &lt;p&gt;Creating a CSV file as a script for my bot to handle unique business questions like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;&amp;quot;Does your business ship internationally?&amp;quot;&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;em&gt;&amp;quot;What is your return policy?&amp;quot;&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Link is here: &lt;a href="https://www.youtube.com/watch?v=fgEPXblIAcg"&gt;https://www.youtube.com/watch?v=fgEPXblIAcg&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I will show you how I use &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; and &lt;strong&gt;Ollama Deepseek-R1&lt;/strong&gt; to build a powerful chatbot backend that can answer customer queries efficiently and accurately tailor to your business policy. &lt;/p&gt; &lt;p&gt;I would love to hear your thoughts and feedback! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Spirited-Wind6803"&gt; /u/Spirited-Wind6803 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itndet/rag_with_your_csv_file_as_a_script_for_your/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itndet/rag_with_your_csv_file_as_a_script_for_your/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itndet/rag_with_your_csv_file_as_a_script_for_your/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T02:06:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1iu13iq</id>
    <title>Llama 3.1 8B Instruct - End of sentence token not working</title>
    <updated>2025-02-20T15:28:50+00:00</updated>
    <author>
      <name>/u/IllustriousBottle524</name>
      <uri>https://old.reddit.com/user/IllustriousBottle524</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am running Llama 3.1 8B locally (downloaded using Ollama whose documentation suggests the stop token is &amp;quot;&amp;lt;|eot_id|&amp;gt;&amp;quot;) using llama cpp. However,I can't get the EOS token working.&lt;/p&gt; &lt;p&gt;The model keeps generating until the max token limit is reached. I used&lt;/p&gt; &lt;pre&gt;&lt;code&gt;stop='&amp;lt;|eot_id|&amp;gt;' &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;as a parameter,yet it doesn't seem to work. I tried using &amp;quot;&amp;lt;|end_header_id|&amp;gt;&amp;quot; as well.&lt;/p&gt; &lt;p&gt;I dug deeper. Turns out,10 months ago people were encountering this and thus had to modify the GGUF files. However,Ollama's 2024 update fixed it so I don't think I need to do the same - &lt;a href="https://github.com/ollama/ollama/issues/3759#issuecomment-2104445225"&gt;https://github.com/ollama/ollama/issues/3759#issuecomment-2104445225&lt;/a&gt;&lt;/p&gt; &lt;p&gt;What am I missing? Sorry if this question is very fundamental but I am new to this.&lt;/p&gt; &lt;p&gt;P.S. Since I downloaded the model using Ollama,it is Llama 3.1 8B instruct 4bit quantized and instead of .gguf files,I just have Sha256 files.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/IllustriousBottle524"&gt; /u/IllustriousBottle524 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu13iq/llama_31_8b_instruct_end_of_sentence_token_not/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu13iq/llama_31_8b_instruct_end_of_sentence_token_not/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iu13iq/llama_31_8b_instruct_end_of_sentence_token_not/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T15:28:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1itj1l9</id>
    <title>PyVisionAI: Instantly Extract &amp; Describe Content from Documents with Vision LLMs(Now with Claude and homebrew)</title>
    <updated>2025-02-19T22:46:44+00:00</updated>
    <author>
      <name>/u/Electrical-Two9833</name>
      <uri>https://old.reddit.com/user/Electrical-Two9833</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;strong&gt;If you deal with documents and images and want to save time on parsing, analyzing, or describing them, PyVisionAI is for you.&lt;/strong&gt; It unifies multiple Vision LLMs (GPT-4 Vision, Claude Vision, or local Llama2-based models) under one workflow, so you can extract text and images from PDF, DOCX, PPTX, and HTML—even capturing fully rendered web pages—and generate human-like explanations for images or diagrams.&lt;/p&gt; &lt;h1&gt;Why It’s Useful&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;All-in-One&lt;/strong&gt;: Handle text extraction and image description across various file types—no juggling separate scripts or libraries.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Go with &lt;strong&gt;cloud-based&lt;/strong&gt; GPT-4/Claude for speed, or &lt;strong&gt;local&lt;/strong&gt; Llama models for privacy.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;CLI &amp;amp; Python Library&lt;/strong&gt;: Use simple terminal commands or integrate PyVisionAI right into your Python projects.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multiple OS Support&lt;/strong&gt;: Works on macOS (via Homebrew), Windows, and Linux (via pip).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;No More Dependency Hassles&lt;/strong&gt;: On macOS, just run one Homebrew command (plus a couple optional installs if you need advanced features).&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Quick macOS Setup (Homebrew)&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;brew tap mdgrey33/pyvisionai brew install pyvisionai # Optional: Needed for dynamic HTML extraction playwright install chromium # Optional: For Office documents (DOCX, PPTX) brew install --cask libreoffice &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This leverages Python 3.11+ automatically (as required by the Homebrew formula). If you’re on Windows or Linux, you can install via &lt;code&gt;pip install pyvisionai&lt;/code&gt; (Python 3.8+).&lt;/p&gt; &lt;h1&gt;Core Features (Confirmed by the READMEs)&lt;/h1&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Document Extraction&lt;/strong&gt; &lt;ul&gt; &lt;li&gt;PDFs, DOCXs, PPTXs, HTML (with JS), and images are all fair game.&lt;/li&gt; &lt;li&gt;Extract text, tables, and even generate screenshots of HTML.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Image Description&lt;/strong&gt; &lt;ul&gt; &lt;li&gt;Analyze diagrams, charts, photos, or scanned pages using GPT-4, Claude, or a &lt;strong&gt;local&lt;/strong&gt; Llama model via &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Customize your prompts to control the level of detail.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;CLI &amp;amp; Python API&lt;/strong&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: &lt;code&gt;file-extract&lt;/code&gt; for documents, &lt;code&gt;describe-image&lt;/code&gt; for images.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;code&gt;create_extractor(...)&lt;/code&gt; to handle large sets of files; &lt;code&gt;describe_image_*&lt;/code&gt; functions for quick references in code.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Performance &amp;amp; Reliability&lt;/strong&gt; &lt;ul&gt; &lt;li&gt;Parallel processing, thorough logging, and automatic retries for rate-limited APIs.&lt;/li&gt; &lt;li&gt;Test coverage sits above 80%, so it’s stable enough for production scenarios.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h1&gt;Sample Code&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;from pyvisionai import create_extractor, describe_image_claude # 1. Extract content from PDFs extractor = create_extractor(&amp;quot;pdf&amp;quot;, model=&amp;quot;gpt4&amp;quot;) # or &amp;quot;claude&amp;quot;, &amp;quot;llama&amp;quot; extractor.extract(&amp;quot;quarterly_reports/&amp;quot;, &amp;quot;analysis_out/&amp;quot;) # 2. Describe an image or diagram desc = describe_image_claude( &amp;quot;circuit.jpg&amp;quot;, prompt=&amp;quot;Explain what this circuit does, focusing on the components&amp;quot; ) print(desc) &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;Choose Your Model&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Cloud&lt;/strong&gt;:export OPENAI_API_KEY=&amp;quot;your-openai-key&amp;quot; # GPT-4 Vision export ANTHROPIC_API_KEY=&amp;quot;your-anthropic-key&amp;quot; # Claude Vision &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Local&lt;/strong&gt;:brew install ollama ollama pull llama2-vision # Then run: describe-image -i diagram.jpg -u llama &lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;System Requirements&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt; (Homebrew install): Python 3.11+&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Windows/Linux&lt;/strong&gt;: Python 3.8+ via &lt;code&gt;pip install pyvisionai&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;1GB+ Free Disk Space&lt;/strong&gt; (local models may require more)&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Want More?&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Official Site&lt;/strong&gt;: &lt;a href="https://pyvisionai.com/"&gt;pyvisionai.com&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href="https://github.com/MDGrey33/pyvisionai"&gt;MDGrey33/pyvisionai&lt;/a&gt; – open issues or PRs if you spot bugs!&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://github.com/MDGrey33/pyvisionai#readme"&gt;Full README &amp;amp; Usage&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Homebrew Formula&lt;/strong&gt;: &lt;a href="https://github.com/mdgrey33/homebrew-pyvisionai"&gt;mdgrey33/homebrew-pyvisionai&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Help Shape the Future of PyVisionAI&lt;/h1&gt; &lt;p&gt;If there’s a feature you need—maybe specialized document parsing, new prompt templates, or deeper local model integration—&lt;strong&gt;please ask or open a feature request&lt;/strong&gt; on GitHub. I want PyVisionAI to fit right into your workflow, whether you’re doing academic research, business analysis, or general-purpose data wrangling.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Give it a try and share your ideas!&lt;/strong&gt; I’d love to know how PyVisionAI can make your work easier.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Electrical-Two9833"&gt; /u/Electrical-Two9833 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itj1l9/pyvisionai_instantly_extract_describe_content/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itj1l9/pyvisionai_instantly_extract_describe_content/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itj1l9/pyvisionai_instantly_extract_describe_content/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-19T22:46:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1iu4az4</id>
    <title>Keeping two models alive in memory concurrently?</title>
    <updated>2025-02-20T17:40:03+00:00</updated>
    <author>
      <name>/u/I-cant_even</name>
      <uri>https://old.reddit.com/user/I-cant_even</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am trying to run two models concurrently, keep them fully loaded, and make them available to other processes. I have more than enough VRAM to handle it.&lt;/p&gt; &lt;p&gt;I essentially use the commands :&lt;/p&gt; &lt;p&gt;&amp;quot;export OLLAMA_KEEP_ALIVE=-1&amp;quot;&lt;/p&gt; &lt;p&gt;&amp;quot;ollama run 'model1' &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;quot;&lt;/p&gt; &lt;p&gt;&amp;quot;ollama run 'model2' &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;quot;&lt;/p&gt; &lt;p&gt;I then start sending requests from my other processes for both models. It works at first monitoring VRAM usage via nvidia-smi but after a few requests it appears to unload one of the models.&lt;/p&gt; &lt;p&gt;Do I need to pass the keep alive -1 flag every request I send? Is there something I'm missing?&lt;/p&gt; &lt;p&gt;Thanks for any pointers.&lt;/p&gt; &lt;p&gt;EDIT : Answer for my use case is :&lt;/p&gt; &lt;p&gt;&amp;quot;ollama run 'model1' &amp;gt; /dev/null --keepalive -1s 2&amp;gt;&amp;amp;1 &amp;amp;&amp;quot;&lt;/p&gt; &lt;p&gt;I can successfully keep both models loaded into memory this way without having to load them for requests.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/I-cant_even"&gt; /u/I-cant_even &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu4az4/keeping_two_models_alive_in_memory_concurrently/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu4az4/keeping_two_models_alive_in_memory_concurrently/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iu4az4/keeping_two_models_alive_in_memory_concurrently/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T17:40:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1itv7vn</id>
    <title>In Search of Alternatives to OpenAI ChatGPT</title>
    <updated>2025-02-20T10:09:47+00:00</updated>
    <author>
      <name>/u/RochelleAstraeus</name>
      <uri>https://old.reddit.com/user/RochelleAstraeus</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I'm looking for AI tools for customer service and internal documentation, but OpenAI and Gemini have privacy concerns. I found &amp;quot;&lt;strong&gt;PrivateModeAI&lt;/strong&gt;&amp;quot;, which uses confidential computing to keep data encrypted and doesn’t store or remember anything. It runs on open-source models like Llama v3.3. Has anyone tried it or know of other privacy-focused AI solutions?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/RochelleAstraeus"&gt; /u/RochelleAstraeus &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itv7vn/in_search_of_alternatives_to_openai_chatgpt/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itv7vn/in_search_of_alternatives_to_openai_chatgpt/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itv7vn/in_search_of_alternatives_to_openai_chatgpt/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T10:09:47+00:00</published>
  </entry>
  <entry>
    <id>t3_1itt7ho</id>
    <title>**"Why Does Ollama 3.3 Slow Down x60 After Multiple Loops? (A6000, 128GB RAM)"**</title>
    <updated>2025-02-20T07:45:07+00:00</updated>
    <author>
      <name>/u/notabotllm</name>
      <uri>https://old.reddit.com/user/notabotllm</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi ! &lt;/p&gt; &lt;p&gt;I am an MD -not a DS so be gentle with me. &lt;/p&gt; &lt;p&gt;I am processing 100's of medical files for data extraction on patients for a large study. For this, I am using vs code to run ollama 3.3 70b locally on A6000 48Gb VRAM, 128RAM. &lt;/p&gt; &lt;p&gt;I have to run multiple sequential loops, where each loop processes 100s of records. Between loops i save a csv file with the characteristic i am extracting on the patient. &lt;/p&gt; &lt;p&gt;Now here comes the problem:&lt;br /&gt; For each loop, there is a significant slowdown although the prompt is almost identical and texts are the same. &lt;/p&gt; &lt;p&gt;After 5 loops it slows from 1,5sec / patient record to +60 seconds per record. &lt;/p&gt; &lt;p&gt;Nothing has changed between loops. &lt;/p&gt; &lt;p&gt;If i restart my computer and run the next loop, then we're back up to speed. &lt;/p&gt; &lt;p&gt;Any suggestions? &lt;/p&gt; &lt;p&gt;Also, if you are interested in cancer research, I'd be very happy if we could work together somehow. &lt;/p&gt; &lt;p&gt;Sorry for my lack of knowledge&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Hi everyone!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I'm an MD, not a data scientist—so please be gentle with me.&lt;/p&gt; &lt;p&gt;I'm processing hundreds of medical files for data extraction in a large study. To do this, I'm running &lt;strong&gt;Ollama 3.3 (70B) locally on an A6000 (48GB VRAM) with 128GB RAM&lt;/strong&gt; using &lt;strong&gt;VS Code&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The process involves running multiple sequential loops, each handling hundreds of patient records. After each loop, I save a CSV file with the extracted characteristics.&lt;/p&gt; &lt;h1&gt;The Problem:&lt;/h1&gt; &lt;p&gt;With each loop, processing time slows down significantly, even though:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The prompt remains almost identical.&lt;/li&gt; &lt;li&gt;The texts are the same.&lt;/li&gt; &lt;li&gt;Nothing changes between loops.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Initially, processing takes &lt;strong&gt;~1.5 sec per patient record&lt;/strong&gt;, but after five loops, it slows to &lt;strong&gt;60+ sec per record&lt;/strong&gt;. However, if I restart my computer and start the next loop, speed returns to normal.&lt;/p&gt; &lt;h1&gt;Any ideas on what’s causing this or how to fix it?&lt;/h1&gt; &lt;p&gt;Also, if you're interested in &lt;strong&gt;cancer research&lt;/strong&gt;, I'd love to connect and collaborate!&lt;/p&gt; &lt;p&gt;Apologies for any gaps in my understanding—thanks for your help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/notabotllm"&gt; /u/notabotllm &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itt7ho/why_does_ollama_33_slow_down_x60_after_multiple/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itt7ho/why_does_ollama_33_slow_down_x60_after_multiple/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itt7ho/why_does_ollama_33_slow_down_x60_after_multiple/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T07:45:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1iu4os2</id>
    <title>Streaming and Tools in one call?</title>
    <updated>2025-02-20T17:55:36+00:00</updated>
    <author>
      <name>/u/hadoopfromscratch</name>
      <uri>https://old.reddit.com/user/hadoopfromscratch</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Is it possible to use streaming and tools in the same call?&lt;/p&gt; &lt;p&gt;Here is what I'm trying to do:&lt;/p&gt; &lt;p&gt;API call with stream=true works as expected:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl http://localhost:11434/v1/chat/completions -d '{&amp;quot;model&amp;quot;: &amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;, &amp;quot;messages&amp;quot;: [{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;Count to three.&amp;quot;}], &amp;quot;temperature&amp;quot;: 0, &amp;quot;stream&amp;quot;: true}' data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;1&amp;quot;},&amp;quot;finish_reason&amp;quot;:null}]} data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;,&amp;quot;},&amp;quot;finish_reason&amp;quot;:null}]} data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot; &amp;quot;},&amp;quot;finish_reason&amp;quot;:null}]} data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;2&amp;quot;},&amp;quot;finish_reason&amp;quot;:null}]} data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;,&amp;quot;},&amp;quot;finish_reason&amp;quot;:null}]} data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot; &amp;quot;},&amp;quot;finish_reason&amp;quot;:null}]} data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;3&amp;quot;},&amp;quot;finish_reason&amp;quot;:null}]} data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-921&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073443,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;&amp;quot;},&amp;quot;finish_reason&amp;quot;:&amp;quot;stop&amp;quot;}]} data: [DONE] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Same API call with tools added. Ollama starts ignoring stream=true:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;curl http://localhost:11434/v1/chat/completions -d '{&amp;quot;model&amp;quot;: &amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;, &amp;quot;messages&amp;quot;: [{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;Count to three.&amp;quot;}], &amp;quot;temperature&amp;quot;: 0, &amp;quot;stream&amp;quot;: true, &amp;quot;tools&amp;quot;: [{&amp;quot;type&amp;quot;: &amp;quot;function&amp;quot;, &amp;quot;function&amp;quot;: {&amp;quot;name&amp;quot;: &amp;quot;one&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;Return 1&amp;quot;, &amp;quot;parameters&amp;quot;: {}}}], &amp;quot;tool_choice&amp;quot;: &amp;quot;auto&amp;quot;}' data: {&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-667&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion.chunk&amp;quot;,&amp;quot;created&amp;quot;:1740073466,&amp;quot;model&amp;quot;:&amp;quot;mistral-small:24b-instruct-2501-q8_0&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;delta&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;One, two, three.&amp;quot;},&amp;quot;finish_reason&amp;quot;:&amp;quot;stop&amp;quot;}]} data: [DONE] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Is this expected? Please, help.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/hadoopfromscratch"&gt; /u/hadoopfromscratch &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu4os2/streaming_and_tools_in_one_call/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu4os2/streaming_and_tools_in_one_call/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iu4os2/streaming_and_tools_in_one_call/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T17:55:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1iu4rrm</id>
    <title>how to save the context of the conversation?</title>
    <updated>2025-02-20T17:58:58+00:00</updated>
    <author>
      <name>/u/karimelkh</name>
      <uri>https://old.reddit.com/user/karimelkh</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;before anything, i am completly AI beginner,&lt;/p&gt; &lt;p&gt;i am struggling in learning the ollama python api and save the context for engoing chat.&lt;/p&gt; &lt;p&gt;the whole point of this post to find a way to keep the context which the model will use to continue the conversation with the user using the &lt;code&gt;chat&lt;/code&gt; function.&lt;/p&gt; &lt;p&gt;is that even possible.&lt;/p&gt; &lt;p&gt;i found that the &lt;code&gt;generate&lt;/code&gt; function supports takes and returns the context, but it is deprecated and not working currently.&lt;/p&gt; &lt;p&gt;thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/karimelkh"&gt; /u/karimelkh &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu4rrm/how_to_save_the_context_of_the_conversation/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu4rrm/how_to_save_the_context_of_the_conversation/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iu4rrm/how_to_save_the_context_of_the_conversation/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T17:58:58+00:00</published>
  </entry>
  <entry>
    <id>t3_1itr0mu</id>
    <title>Don't be fooled: `ollama run llava "describe this image: ./art.jpg"`</title>
    <updated>2025-02-20T05:22:25+00:00</updated>
    <author>
      <name>/u/firesalamander</name>
      <uri>https://old.reddit.com/user/firesalamander</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I feel very silly.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;The image you've provided appears to be a digital artwork or illustration featuring an abstract design with geometric shapes and forms. There are blocks of color in shades of blue, green, and brown, which may suggest some sort of landscape or natural scene. The shapes and lines seem to overlap and intersect in a way that creates depth and dimensionality. The overall style is somewhat reminiscent of cubism or other forms of abstract art, where the focus is on the relationship between shapes and colors rather than on realistic representation.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Awesome! Wait a minute...&lt;/p&gt; &lt;p&gt;&lt;code&gt;sudo find / -name art.jpg&lt;/code&gt; = no results. 😂. Dang thing was hallucinating.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/firesalamander"&gt; /u/firesalamander &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itr0mu/dont_be_fooled_ollama_run_llava_describe_this/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itr0mu/dont_be_fooled_ollama_run_llava_describe_this/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itr0mu/dont_be_fooled_ollama_run_llava_describe_this/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T05:22:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1iu1j8u</id>
    <title>Let's test different models on counting e in Deepseek.</title>
    <updated>2025-02-20T15:47:24+00:00</updated>
    <author>
      <name>/u/HeadGr</name>
      <uri>https://old.reddit.com/user/HeadGr</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I found that quite fun, so far only Clause 3.5 was able to answer as expected.&lt;/p&gt; &lt;p&gt;Copilot and ChatGPT found three, mistral:7b-instruct-v0.3-q8_0 found &lt;strong&gt;2 of 6 total&lt;/strong&gt; chars.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/HeadGr"&gt; /u/HeadGr &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu1j8u/lets_test_different_models_on_counting_e_in/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu1j8u/lets_test_different_models_on_counting_e_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iu1j8u/lets_test_different_models_on_counting_e_in/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T15:47:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1itrikk</id>
    <title>I'm a college student and I made this app, I'm thinking of adding local LLM as a feature to it, what do you think?</title>
    <updated>2025-02-20T05:53:35+00:00</updated>
    <author>
      <name>/u/Ehsan1238</name>
      <uri>https://old.reddit.com/user/Ehsan1238</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1itrikk/im_a_college_student_and_i_made_this_app_im/"&gt; &lt;img alt="I'm a college student and I made this app, I'm thinking of adding local LLM as a feature to it, what do you think?" src="https://external-preview.redd.it/c3h2NTFwMXhnOGtlMZdiOP7V-NQ6wHNezKa1N-qqrV6AgpXO0VoWmPlOO6Ln.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=90f75fb526ea54847ba99777570f51ba685dfc3f" title="I'm a college student and I made this app, I'm thinking of adding local LLM as a feature to it, what do you think?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Ehsan1238"&gt; /u/Ehsan1238 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/4xivu02xg8ke1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itrikk/im_a_college_student_and_i_made_this_app_im/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itrikk/im_a_college_student_and_i_made_this_app_im/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T05:53:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1ity8vn</id>
    <title>Locally running DeepSeek model gives irrelevant answers</title>
    <updated>2025-02-20T13:16:40+00:00</updated>
    <author>
      <name>/u/RajSingh9999</name>
      <uri>https://old.reddit.com/user/RajSingh9999</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1ity8vn/locally_running_deepseek_model_gives_irrelevant/"&gt; &lt;img alt="Locally running DeepSeek model gives irrelevant answers" src="https://external-preview.redd.it/_A7GrFGQtwUPIZGfL44WzPCGr8rHhNVcfuAS2i_6Q3U.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c83b66829e2b59aa4977938e5619190106e8669d" title="Locally running DeepSeek model gives irrelevant answers" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am following &lt;a href="https://www.youtube.com/watch?v=vfpe2S22g4c"&gt;this video tutorial&lt;/a&gt; to chat with PDFs with deepseek R1. The github repo for this tutorial is this: &lt;a href="https://github.com/rishabkumar7/deepseek-ollama"&gt;https://github.com/rishabkumar7/deepseek-ollama&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The code runs without any error, but it gives irrelevant answers. For example, I uploaded S3Track (an object tracking approach) paper pdf: &lt;a href="https://export.arxiv.org/pdf/2305.09981v1.pdf"&gt;https://export.arxiv.org/pdf/2305.09981v1.pdf&lt;/a&gt;&lt;/p&gt; &lt;p&gt;And asked simple question that &amp;quot;What is the title of the paper.&amp;quot; But it just gave some irrelevant answers:&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/s0qj3l5pmake1.png?width=742&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=30d1f38d290247b746aa12b487b4514f7de330bb"&gt;https://preview.redd.it/s0qj3l5pmake1.png?width=742&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=30d1f38d290247b746aa12b487b4514f7de330bb&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Here is the full reply:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;think&amp;gt; Okay, so I need to figure out how to answer this question about the titles of some papers. The user mentioned something about day+rain, night+snow, etc., in both downtown and highway traffic conditions. Then they provided a list of datasets like KITTI, Waymo, nuScenes, and Argoverse. Each has specific details about their collection, sensors, training, evaluation metrics. The main question is, what are the titles of these papers? From the context, I think each dataset or study probably has a title that describes it. For example, KITTI mentions 2D tracking dataset with 21 videos and at 10 FPS. But wait, actually looking back, in the context provided, there's no list of datasets except the original ones mentioned. The user then lists specific papers about object tracking methods. Wait, perhaps I'm misunderstanding. Maybe each paper is associated with one of these datasets? Let me check the structure again. The data section talks about multiple datasets but doesn't provide a list of titles. Then it goes into details about each dataset: KITTI 2D, Waymo, etc. But then in the evaluation section, it lists several papers titled like &amp;quot;4.2. Evaluation Metrics&amp;quot; and others. Hmm, so maybe the user wants to know which dataset corresponds to which paper? Let me check each part again. The context starts by talking about datasets but doesn't list titles. Then under &amp;quot;Evaluation,&amp;quot; there are specific papers mentioned with titles like &amp;quot;4.2. Evaluation Metrics,&amp;quot; etc., but I don't see any explicit dataset names in that section. Wait, maybe the user is asking for a title of a specific paper related to tracking metrics or datasets. Or perhaps it's about which dataset each method is from. Since all the papers listed are being evaluated, and each has their own context, maybe the titles of these papers would be as they appear in the sections like &amp;quot;4.2. Evaluation Metrics&amp;quot; but that seems off. Alternatively, if we look at the entire data section, there's no list of dataset titles; it just describes each one. So perhaps the user wants a title for each paper under evaluation? But the user didn't ask that explicitly. They just provided context about datasets and specific papers. Wait, maybe I'm overcomplicating this. The initial query is &amp;quot;What is the title of the paper?&amp;quot; without giving more context. Since each dataset has details but no titles beyond what's explained in the data section, perhaps the intended answer isn't a list but a direct response to that question, stating that each dataset has its own set of papers with their own specific focuses. Alternatively, if the user is asking about the title from the dataset names, like which one is KITTI 2D tracking dataset... No, because in the data section it's just described as 21 training and 29 test videos. So perhaps each paper under the Evaluation section has its own title, but without explicit dataset listing. Wait, looking again: The evaluation part lists specific papers, like &amp;quot;4.2. Evaluation Metrics,&amp;quot; so maybe the user is referring to a particular one of those. But without more context, it's hard to tell which specific paper they're asking about. Perhaps the user wants all the titles from each section? Or maybe I'm supposed to infer that each dataset is associated with a set of papers. Alternatively, perhaps the user meant that there are multiple datasets (like KITTI, Waymo, etc.) and each has their own evaluation metrics, but again, without seeing which specific paper titles come up in those sections. Wait, going back: The data section doesn't list any dataset titles; it describes each one. Then under Evaluation Metrics, each of the specific papers listed are described with their details. So perhaps I need to find the title that would go with each dataset or method? But without a clear prompt, it's unclear. Since the user is asking about the titles of the paper in general (not specifying which dataset), and given that there's no list provided beyond what's in the data section, maybe they're looking for an explanation rather than listing. Alternatively, perhaps they're confused because each dataset has its own set of papers, but it's hard to pinpoint without more context. In any case, based on the information given, I think the user might be expecting a list or a specific title from one of these datasets, but without explicit data, I can't identify which one. Maybe they're confused about how each dataset relates to specific methods, and now they want the titles for those methods. &amp;lt;/think&amp;gt; The user is asking about the titles of specific papers related to tracking metrics and datasets like KITTI, Waymo, etc., but since there's no explicit dataset title listed beyond what's described in the data section, it's unclear which specific paper title they're referring to. Each dataset has its own set of methods and details, so without more context, I can't provide a specific answer. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It also gave such irrelevant answers, when I asked to give the benchmarks specified in the paper.&lt;/p&gt; &lt;p&gt;I have tried 1.5b (as in youtube video) and 8b parameter models:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;embeddings = OllamaEmbeddings(model=&amp;quot;deepseek-r1:1.5b&amp;quot;) model = OllamaLLM(model=&amp;quot;deepseek-r1:1.5b&amp;quot;) # embeddings = OllamaEmbeddings(model=&amp;quot;deepseek-r1:8b&amp;quot;) # model = OllamaLLM(model=&amp;quot;deepseek-r1:8b&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Are the models just not capable? What I am missing here? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/RajSingh9999"&gt; /u/RajSingh9999 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1ity8vn/locally_running_deepseek_model_gives_irrelevant/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1ity8vn/locally_running_deepseek_model_gives_irrelevant/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1ity8vn/locally_running_deepseek_model_gives_irrelevant/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T13:16:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1iu67r7</id>
    <title>What are some ollama models that are fast for a 12vram graphics card but balanced in quality?</title>
    <updated>2025-02-20T18:57:02+00:00</updated>
    <author>
      <name>/u/Game-Lover44</name>
      <uri>https://old.reddit.com/user/Game-Lover44</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Im looking for a general purpose model that is good for my gtx 3060. ive tried 7b models but they dont feel strong enough for messing around with. I want a speedy model. ive tried 32b models but they are slow, so i might need a model in-between that.&lt;/p&gt; &lt;p&gt;i mostly want to learn coding using ai and have it help me make a game someday, i know ai cant do all the work but i will use it as small tool.&lt;/p&gt; &lt;p&gt;Please suggest some good models that may work, also say some pros and cons of said model.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Game-Lover44"&gt; /u/Game-Lover44 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu67r7/what_are_some_ollama_models_that_are_fast_for_a/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu67r7/what_are_some_ollama_models_that_are_fast_for_a/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iu67r7/what_are_some_ollama_models_that_are_fast_for_a/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T18:57:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1iu7om9</id>
    <title>I've always been fascinated by table top RPGs. Advice on which model to get the basics down?</title>
    <updated>2025-02-20T19:56:20+00:00</updated>
    <author>
      <name>/u/TravellingBeard</name>
      <uri>https://old.reddit.com/user/TravellingBeard</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Gamifying learning is a good approach for me, and thinking of using DnD basic rules, or even a few free and simple ones such as GURPs to model characters and encounters. Thoughts on this and how much processing power will it use?&lt;/p&gt; &lt;p&gt;I have an 8gb card so I'd consider myself middle to upper middle performance wise.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TravellingBeard"&gt; /u/TravellingBeard &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu7om9/ive_always_been_fascinated_by_table_top_rpgs/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iu7om9/ive_always_been_fascinated_by_table_top_rpgs/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iu7om9/ive_always_been_fascinated_by_table_top_rpgs/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T19:56:20+00:00</published>
  </entry>
  <entry>
    <id>t3_1itm5i4</id>
    <title>A fully local, cross-platform AI chat application powered by Ollama</title>
    <updated>2025-02-20T01:07:26+00:00</updated>
    <author>
      <name>/u/rayon_io</name>
      <uri>https://old.reddit.com/user/rayon_io</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1itm5i4/a_fully_local_crossplatform_ai_chat_application/"&gt; &lt;img alt="A fully local, cross-platform AI chat application powered by Ollama" src="https://external-preview.redd.it/OTZwbzlrZnQxN2tlMakES6FH2W8yfgBPhVVYUvoYQmRIwx5RUSE0YuLVDLKW.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=da479c78d326f4b6ba4fa3fd39bd742837499c43" title="A fully local, cross-platform AI chat application powered by Ollama" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/rayon_io"&gt; /u/rayon_io &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/06vaqjft17ke1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itm5i4/a_fully_local_crossplatform_ai_chat_application/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itm5i4/a_fully_local_crossplatform_ai_chat_application/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T01:07:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1iun0ud</id>
    <title>using ollama hosted models with cline — some are super slow, some are normally fast</title>
    <updated>2025-02-21T09:30:27+00:00</updated>
    <author>
      <name>/u/avuvuvui</name>
      <uri>https://old.reddit.com/user/avuvuvui</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;normally fast = the same speed as when I'm chatting with them locally&lt;/p&gt; &lt;p&gt;super slow = when I'm in eg. cline, which has tool use, they get literally 20x slower&lt;/p&gt; &lt;p&gt;any idea what I'm doing wrong&lt;/p&gt; &lt;p&gt;newb here, apologies if too newbish, tried searching&lt;/p&gt; &lt;p&gt;edit: for context, had been lucky enough to have gotten an 128gb m3 macbook from work, that helps with 'pure' usage, ie. without any tool use&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/avuvuvui"&gt; /u/avuvuvui &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iun0ud/using_ollama_hosted_models_with_cline_some_are/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iun0ud/using_ollama_hosted_models_with_cline_some_are/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iun0ud/using_ollama_hosted_models_with_cline_some_are/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-21T09:30:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1iubwp3</id>
    <title>8x Mi50 Server (left) + 8x Mi60 Server (right)</title>
    <updated>2025-02-20T22:53:21+00:00</updated>
    <author>
      <name>/u/Any_Praline_8178</name>
      <uri>https://old.reddit.com/user/Any_Praline_8178</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1iubwp3/8x_mi50_server_left_8x_mi60_server_right/"&gt; &lt;img alt="8x Mi50 Server (left) + 8x Mi60 Server (right)" src="https://preview.redd.it/tasjsv1bidke1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=22693a611e5f5c4d40be93a1739476bd18feedaf" title="8x Mi50 Server (left) + 8x Mi60 Server (right)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any_Praline_8178"&gt; /u/Any_Praline_8178 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/tasjsv1bidke1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iubwp3/8x_mi50_server_left_8x_mi60_server_right/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iubwp3/8x_mi50_server_left_8x_mi60_server_right/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T22:53:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1iujt38</id>
    <title>How To Run Private &amp; Uncensored LLMs Offline | Dolphin Llama 3</title>
    <updated>2025-02-21T05:46:53+00:00</updated>
    <author>
      <name>/u/powerflower_khi</name>
      <uri>https://old.reddit.com/user/powerflower_khi</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1iujt38/how_to_run_private_uncensored_llms_offline/"&gt; &lt;img alt="How To Run Private &amp;amp; Uncensored LLMs Offline | Dolphin Llama 3" src="https://b.thumbs.redditmedia.com/BdwEHXyUWYg7JDHPMCmb8f44BQjJt0lQoOsNQAyimHg.jpg" title="How To Run Private &amp;amp; Uncensored LLMs Offline | Dolphin Llama 3" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Check this out. I give this 5 Star!!!!&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/l9vyzgqjmfke1.png?width=1024&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eda1b74ab28218d5b4bfc2fabab349129dfaf87e"&gt;https://preview.redd.it/l9vyzgqjmfke1.png?width=1024&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eda1b74ab28218d5b4bfc2fabab349129dfaf87e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=eiMSapoeyaU"&gt;https://www.youtube.com/watch?v=eiMSapoeyaU&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/powerflower_khi"&gt; /u/powerflower_khi &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iujt38/how_to_run_private_uncensored_llms_offline/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1iujt38/how_to_run_private_uncensored_llms_offline/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1iujt38/how_to_run_private_uncensored_llms_offline/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-21T05:46:53+00:00</published>
  </entry>
  <entry>
    <id>t3_1itzioa</id>
    <title>Less than 70b models worth running locally?</title>
    <updated>2025-02-20T14:19:16+00:00</updated>
    <author>
      <name>/u/abrandis</name>
      <uri>https://old.reddit.com/user/abrandis</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;So I've been playing with a bunch of local models but have realized that all but the most basic Q&amp;amp;A struggle with decent answers for smaller models....I just wind up going to the cloudz Claude mostly to get better coding and general Q-A results .&lt;/p&gt; &lt;p&gt;My question I guess is are any smallish models practical to run locally,or is there accuracy so poor to not be worth it ..&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/abrandis"&gt; /u/abrandis &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itzioa/less_than_70b_models_worth_running_locally/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1itzioa/less_than_70b_models_worth_running_locally/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1itzioa/less_than_70b_models_worth_running_locally/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-02-20T14:19:16+00:00</published>
  </entry>
</feed>
